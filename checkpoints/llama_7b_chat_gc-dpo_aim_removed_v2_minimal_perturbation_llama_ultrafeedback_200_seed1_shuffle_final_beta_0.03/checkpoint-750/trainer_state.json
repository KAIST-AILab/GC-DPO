{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 0.8180391326908055,
      "learning_rate": 8.695652173913044e-07,
      "logits/chosen": -0.7552716135978699,
      "logits/rejected": -0.7317023277282715,
      "logps/chosen": -191.36520385742188,
      "logps/rejected": -245.05145263671875,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.9068464092477375,
      "learning_rate": 1.7391304347826088e-06,
      "logits/chosen": -0.8284413814544678,
      "logits/rejected": -0.8899655342102051,
      "logps/chosen": -293.99176025390625,
      "logps/rejected": -214.42233276367188,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7811690479299513,
      "learning_rate": 2.6086956521739132e-06,
      "logits/chosen": -0.7953945994377136,
      "logits/rejected": -0.9679244160652161,
      "logps/chosen": -200.01651000976562,
      "logps/rejected": -169.08001708984375,
      "loss": 0.6929,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00030710219289176166,
      "rewards/margins": 0.0004110645968466997,
      "rewards/rejected": -0.00010396241123089567,
      "step": 3
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.8673856697817123,
      "learning_rate": 3.4782608695652175e-06,
      "logits/chosen": -0.7642526030540466,
      "logits/rejected": -0.9180639386177063,
      "logps/chosen": -244.04962158203125,
      "logps/rejected": -162.00051879882812,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0004603385750669986,
      "rewards/margins": -0.00017426488921046257,
      "rewards/rejected": -0.0002860736567527056,
      "step": 4
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 1.0264231106724446,
      "learning_rate": 4.347826086956522e-06,
      "logits/chosen": -1.0760046243667603,
      "logits/rejected": -0.9929749965667725,
      "logps/chosen": -322.29803466796875,
      "logps/rejected": -262.90087890625,
      "loss": 0.693,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.00028487201780080795,
      "rewards/margins": 0.0003157425089739263,
      "rewards/rejected": -0.0006006145267747343,
      "step": 5
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0969709109898038,
      "learning_rate": 5.2173913043478265e-06,
      "logits/chosen": -0.953806459903717,
      "logits/rejected": -0.8655242323875427,
      "logps/chosen": -267.17828369140625,
      "logps/rejected": -352.5185546875,
      "loss": 0.6933,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.00023829459678381681,
      "rewards/margins": -0.00038168905302882195,
      "rewards/rejected": 0.0006199836498126388,
      "step": 6
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 1.2407370682456944,
      "learning_rate": 6.086956521739132e-06,
      "logits/chosen": -0.7768223285675049,
      "logits/rejected": -1.0105282068252563,
      "logps/chosen": -433.2024230957031,
      "logps/rejected": -218.90318298339844,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.00011032105248887092,
      "rewards/margins": -9.887696796795353e-05,
      "rewards/rejected": -1.1444091796875e-05,
      "step": 7
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.8290771193209315,
      "learning_rate": 6.956521739130435e-06,
      "logits/chosen": -0.7863063216209412,
      "logits/rejected": -0.9361751079559326,
      "logps/chosen": -281.0982666015625,
      "logps/rejected": -184.645751953125,
      "loss": 0.6931,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00042700767517089844,
      "rewards/margins": 0.0001805019419407472,
      "rewards/rejected": -0.0006075095734559,
      "step": 8
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9670699225277513,
      "learning_rate": 7.82608695652174e-06,
      "logits/chosen": -0.9246686100959778,
      "logits/rejected": -0.9625620245933533,
      "logps/chosen": -289.7715759277344,
      "logps/rejected": -178.50498962402344,
      "loss": 0.6932,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 6.096839206293225e-05,
      "rewards/margins": -3.633496817201376e-05,
      "rewards/rejected": 9.730338933877647e-05,
      "step": 9
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.8696827430060421,
      "learning_rate": 8.695652173913044e-06,
      "logits/chosen": -0.6233720183372498,
      "logits/rejected": -0.7346858382225037,
      "logps/chosen": -232.45472717285156,
      "logps/rejected": -159.6055908203125,
      "loss": 0.6931,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 2.6378664188086987e-05,
      "rewards/margins": 3.888134961016476e-05,
      "rewards/rejected": -1.250267814612016e-05,
      "step": 10
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 1.023445478801347,
      "learning_rate": 9.565217391304349e-06,
      "logits/chosen": -0.8596686720848083,
      "logits/rejected": -0.9516538381576538,
      "logps/chosen": -346.64190673828125,
      "logps/rejected": -207.36859130859375,
      "loss": 0.6906,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004121789708733559,
      "rewards/margins": 0.005060477182269096,
      "rewards/rejected": -0.000938687298912555,
      "step": 11
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.045803660596203,
      "learning_rate": 1.0434782608695653e-05,
      "logits/chosen": -0.9263288378715515,
      "logits/rejected": -0.9196621179580688,
      "logps/chosen": -278.4931640625,
      "logps/rejected": -207.8740234375,
      "loss": 0.6926,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002807464450597763,
      "rewards/margins": 0.0010807228973135352,
      "rewards/rejected": 0.0017267417861148715,
      "step": 12
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 1.0767909102505433,
      "learning_rate": 1.1304347826086957e-05,
      "logits/chosen": -0.6783105731010437,
      "logits/rejected": -0.8932969570159912,
      "logps/chosen": -435.7855529785156,
      "logps/rejected": -220.92730712890625,
      "loss": 0.6904,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0066252704709768295,
      "rewards/margins": 0.005432081408798695,
      "rewards/rejected": 0.001193189644254744,
      "step": 13
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.7974368340042267,
      "learning_rate": 1.2173913043478263e-05,
      "logits/chosen": -0.9166104197502136,
      "logits/rejected": -0.9440990686416626,
      "logps/chosen": -250.1605224609375,
      "logps/rejected": -216.54638671875,
      "loss": 0.692,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00373669620603323,
      "rewards/margins": 0.0022717094980180264,
      "rewards/rejected": 0.0014649867080152035,
      "step": 14
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.187824255190888,
      "learning_rate": 1.3043478260869566e-05,
      "logits/chosen": -0.8546133637428284,
      "logits/rejected": -0.6829521059989929,
      "logps/chosen": -329.8265380859375,
      "logps/rejected": -406.47314453125,
      "loss": 0.6931,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008909139782190323,
      "rewards/margins": 0.0001753806136548519,
      "rewards/rejected": 0.008733758702874184,
      "step": 15
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.7874348159333727,
      "learning_rate": 1.391304347826087e-05,
      "logits/chosen": -0.7967454791069031,
      "logits/rejected": -0.8149887919425964,
      "logps/chosen": -202.51345825195312,
      "logps/rejected": -208.03639221191406,
      "loss": 0.6925,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004088344052433968,
      "rewards/margins": 0.0012173937866464257,
      "rewards/rejected": 0.002870950847864151,
      "step": 16
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 1.0841152902540214,
      "learning_rate": 1.4782608695652174e-05,
      "logits/chosen": -0.9838811159133911,
      "logits/rejected": -0.763305127620697,
      "logps/chosen": -175.4862060546875,
      "logps/rejected": -358.2355041503906,
      "loss": 0.6961,
      "rewards/accuracies": 0.125,
      "rewards/chosen": 0.0026037024799734354,
      "rewards/margins": -0.005912188906222582,
      "rewards/rejected": 0.008515891619026661,
      "step": 17
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9778256296390029,
      "learning_rate": 1.565217391304348e-05,
      "logits/chosen": -0.6911370158195496,
      "logits/rejected": -0.9627904295921326,
      "logps/chosen": -348.51446533203125,
      "logps/rejected": -162.555419921875,
      "loss": 0.6909,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010328121483325958,
      "rewards/margins": 0.004545449744910002,
      "rewards/rejected": 0.005782670807093382,
      "step": 18
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 0.8700842374820016,
      "learning_rate": 1.6521739130434785e-05,
      "logits/chosen": -0.8317292928695679,
      "logits/rejected": -0.9774664640426636,
      "logps/chosen": -261.25543212890625,
      "logps/rejected": -160.49888610839844,
      "loss": 0.6924,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005418920423835516,
      "rewards/margins": 0.0015271140728145838,
      "rewards/rejected": 0.003891806351020932,
      "step": 19
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.094013454860121,
      "learning_rate": 1.739130434782609e-05,
      "logits/chosen": -0.5894597768783569,
      "logits/rejected": -0.7854679822921753,
      "logps/chosen": -285.58935546875,
      "logps/rejected": -209.9482421875,
      "loss": 0.6904,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.013411445543169975,
      "rewards/margins": 0.00560222752392292,
      "rewards/rejected": 0.007809219416230917,
      "step": 20
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1810974890534551,
      "learning_rate": 1.8260869565217393e-05,
      "logits/chosen": -0.6685553789138794,
      "logits/rejected": -0.9229049682617188,
      "logps/chosen": -415.7165832519531,
      "logps/rejected": -200.74220275878906,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.027944210916757584,
      "rewards/margins": 0.01859149895608425,
      "rewards/rejected": 0.009352711960673332,
      "step": 21
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 1.5464238751653825,
      "learning_rate": 1.9130434782608697e-05,
      "logits/chosen": -0.8996107578277588,
      "logits/rejected": -1.0288773775100708,
      "logps/chosen": -310.2966613769531,
      "logps/rejected": -177.53134155273438,
      "loss": 0.6882,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.019130172207951546,
      "rewards/margins": 0.01002676971256733,
      "rewards/rejected": 0.009103402495384216,
      "step": 22
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 0.7909124990044034,
      "learning_rate": 2e-05,
      "logits/chosen": -0.825049877166748,
      "logits/rejected": -0.8877662420272827,
      "logps/chosen": -224.60205078125,
      "logps/rejected": -183.68771362304688,
      "loss": 0.6876,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.017352016642689705,
      "rewards/margins": 0.011232947930693626,
      "rewards/rejected": 0.006119069643318653,
      "step": 23
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9074222283890192,
      "learning_rate": 1.9999906631527858e-05,
      "logits/chosen": -0.9626007080078125,
      "logits/rejected": -0.9026763439178467,
      "logps/chosen": -207.48367309570312,
      "logps/rejected": -213.83743286132812,
      "loss": 0.6912,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.014780402183532715,
      "rewards/margins": 0.004030051175504923,
      "rewards/rejected": 0.01075035147368908,
      "step": 24
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.8764698421580139,
      "learning_rate": 1.9999626527854966e-05,
      "logits/chosen": -0.7648118734359741,
      "logits/rejected": -0.8110207319259644,
      "logps/chosen": -270.5499267578125,
      "logps/rejected": -218.36090087890625,
      "loss": 0.6892,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.021481819450855255,
      "rewards/margins": 0.008037243038415909,
      "rewards/rejected": 0.013444575481116772,
      "step": 25
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 1.5014047402858537,
      "learning_rate": 1.9999159694211894e-05,
      "logits/chosen": -0.5527797937393188,
      "logits/rejected": -0.852941632270813,
      "logps/chosen": -606.2940063476562,
      "logps/rejected": -427.794189453125,
      "loss": 0.6703,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.08248282968997955,
      "rewards/margins": 0.04761028289794922,
      "rewards/rejected": 0.034872546792030334,
      "step": 26
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.160954005251136,
      "learning_rate": 1.999850613931615e-05,
      "logits/chosen": -0.7304443120956421,
      "logits/rejected": -0.800957977771759,
      "logps/chosen": -444.67938232421875,
      "logps/rejected": -327.0621032714844,
      "loss": 0.6879,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.05862881615757942,
      "rewards/margins": 0.0111981937661767,
      "rewards/rejected": 0.047430623322725296,
      "step": 27
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.9115768609862611,
      "learning_rate": 1.999766587537202e-05,
      "logits/chosen": -0.7415062785148621,
      "logits/rejected": -0.8779956698417664,
      "logps/chosen": -261.6456298828125,
      "logps/rejected": -174.4284210205078,
      "loss": 0.6926,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.029852313920855522,
      "rewards/margins": 0.0013086027465760708,
      "rewards/rejected": 0.028543708845973015,
      "step": 28
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 1.1000692649188135,
      "learning_rate": 1.9996638918070336e-05,
      "logits/chosen": -0.9599727988243103,
      "logits/rejected": -1.0432417392730713,
      "logps/chosen": -357.1534423828125,
      "logps/rejected": -201.87130737304688,
      "loss": 0.6782,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.06382066756486893,
      "rewards/margins": 0.030733194202184677,
      "rewards/rejected": 0.03308746963739395,
      "step": 29
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8539354352509383,
      "learning_rate": 1.9995425286588187e-05,
      "logits/chosen": -0.8125906586647034,
      "logits/rejected": -0.8884687423706055,
      "logps/chosen": -273.1039733886719,
      "logps/rejected": -191.8961944580078,
      "loss": 0.6763,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.06138896197080612,
      "rewards/margins": 0.035407546907663345,
      "rewards/rejected": 0.025981420651078224,
      "step": 30
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 1.0562533023037723,
      "learning_rate": 1.9994025003588547e-05,
      "logits/chosen": -0.6269493699073792,
      "logits/rejected": -0.8714957237243652,
      "logps/chosen": -399.6986083984375,
      "logps/rejected": -278.3879699707031,
      "loss": 0.6706,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.09194016456604004,
      "rewards/margins": 0.04645831882953644,
      "rewards/rejected": 0.0454818531870842,
      "step": 31
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.8452197448835188,
      "learning_rate": 1.9992438095219886e-05,
      "logits/chosen": -0.559097409248352,
      "logits/rejected": -0.7745179533958435,
      "logps/chosen": -234.33291625976562,
      "logps/rejected": -182.76437377929688,
      "loss": 0.6849,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.048370253294706345,
      "rewards/margins": 0.01725262776017189,
      "rewards/rejected": 0.031117629259824753,
      "step": 32
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9141601771144907,
      "learning_rate": 1.9990664591115637e-05,
      "logits/chosen": -0.9555829167366028,
      "logits/rejected": -0.9571911692619324,
      "logps/chosen": -194.98838806152344,
      "logps/rejected": -224.12428283691406,
      "loss": 0.6886,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.05242466926574707,
      "rewards/margins": 0.010790661908686161,
      "rewards/rejected": 0.041634008288383484,
      "step": 33
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.9950722337027108,
      "learning_rate": 1.9988704524393678e-05,
      "logits/chosen": -0.718005359172821,
      "logits/rejected": -0.7511066794395447,
      "logps/chosen": -317.014404296875,
      "logps/rejected": -271.4356689453125,
      "loss": 0.685,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.07475654780864716,
      "rewards/margins": 0.01705172285437584,
      "rewards/rejected": 0.057704828679561615,
      "step": 34
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 1.1761431469761472,
      "learning_rate": 1.9986557931655688e-05,
      "logits/chosen": -0.7062736749649048,
      "logits/rejected": -0.7786477208137512,
      "logps/chosen": -310.066650390625,
      "logps/rejected": -277.772216796875,
      "loss": 0.6801,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.09996803104877472,
      "rewards/margins": 0.028502967208623886,
      "rewards/rejected": 0.07146506011486053,
      "step": 35
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2198040634467873,
      "learning_rate": 1.9984224852986494e-05,
      "logits/chosen": -0.7049310803413391,
      "logits/rejected": -0.6651148796081543,
      "logps/chosen": -277.53900146484375,
      "logps/rejected": -304.8000183105469,
      "loss": 0.6871,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.09470798075199127,
      "rewards/margins": 0.014274843037128448,
      "rewards/rejected": 0.08043313771486282,
      "step": 36
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 1.023060095702716,
      "learning_rate": 1.9981705331953295e-05,
      "logits/chosen": -0.9537251591682434,
      "logits/rejected": -0.768403947353363,
      "logps/chosen": -236.59561157226562,
      "logps/rejected": -350.631591796875,
      "loss": 0.6873,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.08569244295358658,
      "rewards/margins": 0.01371239498257637,
      "rewards/rejected": 0.07198004424571991,
      "step": 37
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.7873337948717298,
      "learning_rate": 1.9978999415604847e-05,
      "logits/chosen": -0.7339386343955994,
      "logits/rejected": -0.8563697934150696,
      "logps/chosen": -165.57461547851562,
      "logps/rejected": -169.63754272460938,
      "loss": 0.7039,
      "rewards/accuracies": 0.125,
      "rewards/chosen": 0.0400264710187912,
      "rewards/margins": -0.02071104384958744,
      "rewards/rejected": 0.06073751300573349,
      "step": 38
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9839463284516893,
      "learning_rate": 1.9976107154470613e-05,
      "logits/chosen": -0.9291843771934509,
      "logits/rejected": -0.9641396403312683,
      "logps/chosen": -174.69931030273438,
      "logps/rejected": -203.3518829345703,
      "loss": 0.7025,
      "rewards/accuracies": 0.125,
      "rewards/chosen": 0.05089044198393822,
      "rewards/margins": -0.01832488179206848,
      "rewards/rejected": 0.069215327501297,
      "step": 39
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.0655205370580982,
      "learning_rate": 1.9973028602559787e-05,
      "logits/chosen": -0.7704254984855652,
      "logits/rejected": -0.905485212802887,
      "logps/chosen": -327.8531494140625,
      "logps/rejected": -268.991943359375,
      "loss": 0.6818,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.08716896176338196,
      "rewards/margins": 0.023400304839015007,
      "rewards/rejected": 0.0637686550617218,
      "step": 40
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 1.1702960758049885,
      "learning_rate": 1.9969763817360314e-05,
      "logits/chosen": -0.6465016007423401,
      "logits/rejected": -0.7395057678222656,
      "logps/chosen": -300.1576232910156,
      "logps/rejected": -251.25357055664062,
      "loss": 0.6631,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.11963950097560883,
      "rewards/margins": 0.06464729458093643,
      "rewards/rejected": 0.054992206394672394,
      "step": 41
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9652973298090716,
      "learning_rate": 1.996631285983779e-05,
      "logits/chosen": -0.8519749641418457,
      "logits/rejected": -0.9144185781478882,
      "logps/chosen": -219.21142578125,
      "logps/rejected": -129.87306213378906,
      "loss": 0.6698,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.08820413053035736,
      "rewards/margins": 0.04780707508325577,
      "rewards/rejected": 0.04039705544710159,
      "step": 42
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 1.2884277167956166,
      "learning_rate": 1.9962675794434342e-05,
      "logits/chosen": -0.5350245237350464,
      "logits/rejected": -0.8090257048606873,
      "logps/chosen": -422.23480224609375,
      "logps/rejected": -265.66485595703125,
      "loss": 0.6672,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.1302672028541565,
      "rewards/margins": 0.056336939334869385,
      "rewards/rejected": 0.07393026351928711,
      "step": 43
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.918586360864692,
      "learning_rate": 1.9958852689067423e-05,
      "logits/chosen": -0.8907628655433655,
      "logits/rejected": -0.8016350269317627,
      "logps/chosen": -157.5399932861328,
      "logps/rejected": -199.988525390625,
      "loss": 0.6946,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.05203381925821304,
      "rewards/margins": -0.0024231146089732647,
      "rewards/rejected": 0.05445694178342819,
      "step": 44
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.051546803508901,
      "learning_rate": 1.9954843615128528e-05,
      "logits/chosen": -0.6458959579467773,
      "logits/rejected": -0.7224407196044922,
      "logps/chosen": -301.7477722167969,
      "logps/rejected": -255.53561401367188,
      "loss": 0.6795,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.11169162392616272,
      "rewards/margins": 0.03070363774895668,
      "rewards/rejected": 0.08098797500133514,
      "step": 45
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.9737556709055863,
      "learning_rate": 1.995064864748188e-05,
      "logits/chosen": -0.7714992761611938,
      "logits/rejected": -0.7487845420837402,
      "logps/chosen": -222.76318359375,
      "logps/rejected": -197.90440368652344,
      "loss": 0.6747,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.10426593571901321,
      "rewards/margins": 0.038443874567747116,
      "rewards/rejected": 0.0658220648765564,
      "step": 46
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 1.0782849842731559,
      "learning_rate": 1.9946267864463027e-05,
      "logits/chosen": -0.687117874622345,
      "logits/rejected": -0.7658860087394714,
      "logps/chosen": -331.3622131347656,
      "logps/rejected": -251.5967559814453,
      "loss": 0.6831,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.11643999814987183,
      "rewards/margins": 0.021540645509958267,
      "rewards/rejected": 0.09489935636520386,
      "step": 47
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.094300485772359,
      "learning_rate": 1.994170134787737e-05,
      "logits/chosen": -0.9163296222686768,
      "logits/rejected": -0.9575411677360535,
      "logps/chosen": -225.111572265625,
      "logps/rejected": -234.9788818359375,
      "loss": 0.6931,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.10914859175682068,
      "rewards/margins": 0.0015742885880172253,
      "rewards/rejected": 0.10757429897785187,
      "step": 48
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 1.0394510102134045,
      "learning_rate": 1.993694918299864e-05,
      "logits/chosen": -0.923121988773346,
      "logits/rejected": -0.9492089748382568,
      "logps/chosen": -236.34011840820312,
      "logps/rejected": -202.79588317871094,
      "loss": 0.6733,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.11850497126579285,
      "rewards/margins": 0.04233922064304352,
      "rewards/rejected": 0.07616575062274933,
      "step": 49
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.026722186948823,
      "learning_rate": 1.9932011458567315e-05,
      "logits/chosen": -0.7469177842140198,
      "logits/rejected": -0.7755187749862671,
      "logps/chosen": -253.6032257080078,
      "logps/rejected": -280.6402893066406,
      "loss": 0.6969,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.15397053956985474,
      "rewards/margins": -0.0055023180320858955,
      "rewards/rejected": 0.15947285294532776,
      "step": 50
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.130297163652825,
      "learning_rate": 1.9926888266788955e-05,
      "logits/chosen": -0.8060658574104309,
      "logits/rejected": -0.826591968536377,
      "logps/chosen": -362.494384765625,
      "logps/rejected": -262.9653015136719,
      "loss": 0.6474,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.2443266659975052,
      "rewards/margins": 0.10611426085233688,
      "rewards/rejected": 0.1382124125957489,
      "step": 51
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.9995880768665906,
      "learning_rate": 1.9921579703332475e-05,
      "logits/chosen": -0.8182545304298401,
      "logits/rejected": -0.8027417659759521,
      "logps/chosen": -285.31622314453125,
      "logps/rejected": -218.4213104248047,
      "loss": 0.6684,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.1486406773328781,
      "rewards/margins": 0.05620630830526352,
      "rewards/rejected": 0.0924343541264534,
      "step": 52
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 1.1573690206025318,
      "learning_rate": 1.991608586732837e-05,
      "logits/chosen": -0.8023196458816528,
      "logits/rejected": -0.7771196365356445,
      "logps/chosen": -211.75820922851562,
      "logps/rejected": -303.53924560546875,
      "loss": 0.7133,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.11284080147743225,
      "rewards/margins": -0.0377180241048336,
      "rewards/rejected": 0.15055882930755615,
      "step": 53
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0008431694654876,
      "learning_rate": 1.991040686136685e-05,
      "logits/chosen": -0.7222103476524353,
      "logits/rejected": -0.8656274676322937,
      "logps/chosen": -282.74053955078125,
      "logps/rejected": -149.0281219482422,
      "loss": 0.6451,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.17545729875564575,
      "rewards/margins": 0.10526664555072784,
      "rewards/rejected": 0.07019065320491791,
      "step": 54
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 1.1582328187889672,
      "learning_rate": 1.9904542791495938e-05,
      "logits/chosen": -0.9853249192237854,
      "logits/rejected": -0.6968746781349182,
      "logps/chosen": -125.62760925292969,
      "logps/rejected": -240.6290283203125,
      "loss": 0.7113,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.07850858569145203,
      "rewards/margins": -0.034707605838775635,
      "rewards/rejected": 0.11321619153022766,
      "step": 55
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 1.1844730447332459,
      "learning_rate": 1.9898493767219486e-05,
      "logits/chosen": -0.44324323534965515,
      "logits/rejected": -0.7543652653694153,
      "logps/chosen": -396.2115783691406,
      "logps/rejected": -188.627197265625,
      "loss": 0.6253,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.24517586827278137,
      "rewards/margins": 0.14649677276611328,
      "rewards/rejected": 0.09867911040782928,
      "step": 56
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9599888779075395,
      "learning_rate": 1.989225990149512e-05,
      "logits/chosen": -0.7925831079483032,
      "logits/rejected": -0.6307340264320374,
      "logps/chosen": -178.56036376953125,
      "logps/rejected": -198.76885986328125,
      "loss": 0.6953,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.10088653117418289,
      "rewards/margins": -0.0026945676654577255,
      "rewards/rejected": 0.10358110070228577,
      "step": 57
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 1.0209244603076566,
      "learning_rate": 1.988584131073215e-05,
      "logits/chosen": -0.5835294723510742,
      "logits/rejected": -0.8139074444770813,
      "logps/chosen": -246.12445068359375,
      "logps/rejected": -209.8968505859375,
      "loss": 0.6706,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.1775500774383545,
      "rewards/margins": 0.04727047681808472,
      "rewards/rejected": 0.13027960062026978,
      "step": 58
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 1.214702585733654,
      "learning_rate": 1.9879238114789375e-05,
      "logits/chosen": -0.8428636789321899,
      "logits/rejected": -0.9850083589553833,
      "logps/chosen": -378.1794128417969,
      "logps/rejected": -306.1431884765625,
      "loss": 0.6619,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2527366280555725,
      "rewards/margins": 0.06980723887681961,
      "rewards/rejected": 0.1829293966293335,
      "step": 59
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9851525278648832,
      "learning_rate": 1.9872450436972856e-05,
      "logits/chosen": -0.7496334910392761,
      "logits/rejected": -0.9193006753921509,
      "logps/chosen": -275.9639587402344,
      "logps/rejected": -167.81869506835938,
      "loss": 0.6538,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.15172933042049408,
      "rewards/margins": 0.08946315944194794,
      "rewards/rejected": 0.06226617097854614,
      "step": 60
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 0.9706645627872317,
      "learning_rate": 1.986547840403362e-05,
      "logits/chosen": -0.778563916683197,
      "logits/rejected": -0.8780624866485596,
      "logps/chosen": -256.2900390625,
      "logps/rejected": -199.02203369140625,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1663205325603485,
      "rewards/margins": 0.05324068292975426,
      "rewards/rejected": 0.11307984590530396,
      "step": 61
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 1.0223541349722816,
      "learning_rate": 1.9858322146165272e-05,
      "logits/chosen": -0.7433386445045471,
      "logits/rejected": -0.854266881942749,
      "logps/chosen": -185.22439575195312,
      "logps/rejected": -205.66683959960938,
      "loss": 0.7069,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.09652513265609741,
      "rewards/margins": -0.025522157549858093,
      "rewards/rejected": 0.1220472902059555,
      "step": 62
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0555244798157144,
      "learning_rate": 1.9850981797001593e-05,
      "logits/chosen": -0.632605254650116,
      "logits/rejected": -0.6926210522651672,
      "logps/chosen": -265.55908203125,
      "logps/rejected": -232.61062622070312,
      "loss": 0.6793,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.16432401537895203,
      "rewards/margins": 0.03339823707938194,
      "rewards/rejected": 0.13092578947544098,
      "step": 63
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 1.1236880918259688,
      "learning_rate": 1.9843457493614016e-05,
      "logits/chosen": -0.8039001822471619,
      "logits/rejected": -0.7930341958999634,
      "logps/chosen": -231.5921173095703,
      "logps/rejected": -256.2998046875,
      "loss": 0.6832,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.1878436803817749,
      "rewards/margins": 0.02192641980946064,
      "rewards/rejected": 0.1659172773361206,
      "step": 64
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 1.0742407779169036,
      "learning_rate": 1.9835749376509084e-05,
      "logits/chosen": -0.7702633142471313,
      "logits/rejected": -0.7070406675338745,
      "logps/chosen": -239.8311309814453,
      "logps/rejected": -285.7147216796875,
      "loss": 0.6819,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.18868660926818848,
      "rewards/margins": 0.030437104403972626,
      "rewards/rejected": 0.15824949741363525,
      "step": 65
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0963294539154378,
      "learning_rate": 1.9827857589625817e-05,
      "logits/chosen": -0.7335865497589111,
      "logits/rejected": -0.8703144192695618,
      "logps/chosen": -291.88140869140625,
      "logps/rejected": -181.103515625,
      "loss": 0.6477,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.2382352650165558,
      "rewards/margins": 0.0997040793299675,
      "rewards/rejected": 0.1385311782360077,
      "step": 66
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 0.9920681859162717,
      "learning_rate": 1.981978228033304e-05,
      "logits/chosen": -0.4278644323348999,
      "logits/rejected": -0.5564054250717163,
      "logps/chosen": -236.7459716796875,
      "logps/rejected": -173.69277954101562,
      "loss": 0.6502,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.17929556965827942,
      "rewards/margins": 0.09021909534931183,
      "rewards/rejected": 0.08907648921012878,
      "step": 67
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.1094138447582782,
      "learning_rate": 1.9811523599426604e-05,
      "logits/chosen": -0.7829894423484802,
      "logits/rejected": -0.8239808082580566,
      "logps/chosen": -220.60382080078125,
      "logps/rejected": -244.7780303955078,
      "loss": 0.66,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.1961180567741394,
      "rewards/margins": 0.08998790383338928,
      "rewards/rejected": 0.10613015294075012,
      "step": 68
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9338194761766934,
      "learning_rate": 1.980308170112659e-05,
      "logits/chosen": -0.5136446356773376,
      "logits/rejected": -0.6521229147911072,
      "logps/chosen": -239.99636840820312,
      "logps/rejected": -206.73135375976562,
      "loss": 0.6868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.15908688306808472,
      "rewards/margins": 0.017697887495160103,
      "rewards/rejected": 0.14138901233673096,
      "step": 69
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 1.2152613569088784,
      "learning_rate": 1.979445674307444e-05,
      "logits/chosen": -0.5740522742271423,
      "logits/rejected": -0.6270332932472229,
      "logps/chosen": -363.7169189453125,
      "logps/rejected": -398.113037109375,
      "loss": 0.6604,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.32486292719841003,
      "rewards/margins": 0.07584745436906815,
      "rewards/rejected": 0.2490154504776001,
      "step": 70
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 1.1236814082919604,
      "learning_rate": 1.9785648886329974e-05,
      "logits/chosen": -0.9517292380332947,
      "logits/rejected": -0.8546236753463745,
      "logps/chosen": -182.50003051757812,
      "logps/rejected": -199.0479736328125,
      "loss": 0.678,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.17101693153381348,
      "rewards/margins": 0.03762395307421684,
      "rewards/rejected": 0.13339295983314514,
      "step": 71
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4504955661657262,
      "learning_rate": 1.977665829536842e-05,
      "logits/chosen": -0.6936554312705994,
      "logits/rejected": -0.6463832259178162,
      "logps/chosen": -176.00816345214844,
      "logps/rejected": -309.819580078125,
      "loss": 0.7052,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.14157643914222717,
      "rewards/margins": -0.0136091448366642,
      "rewards/rejected": 0.15518558025360107,
      "step": 72
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 1.034100782574021,
      "learning_rate": 1.9767485138077327e-05,
      "logits/chosen": -0.7907066345214844,
      "logits/rejected": -0.7657495737075806,
      "logps/chosen": -172.4555206298828,
      "logps/rejected": -215.3202362060547,
      "loss": 0.687,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.17144270241260529,
      "rewards/margins": 0.013923968188464642,
      "rewards/rejected": 0.15751874446868896,
      "step": 73
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 1.0898649699015048,
      "learning_rate": 1.9758129585753433e-05,
      "logits/chosen": -0.746091902256012,
      "logits/rejected": -0.7587730288505554,
      "logps/chosen": -212.34718322753906,
      "logps/rejected": -230.6079559326172,
      "loss": 0.6716,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.2140113115310669,
      "rewards/margins": 0.04804539680480957,
      "rewards/rejected": 0.16596591472625732,
      "step": 74
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0667538478112317,
      "learning_rate": 1.9748591813099457e-05,
      "logits/chosen": -0.5073329210281372,
      "logits/rejected": -0.7968188524246216,
      "logps/chosen": -337.48614501953125,
      "logps/rejected": -216.8482208251953,
      "loss": 0.6174,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3387640118598938,
      "rewards/margins": 0.18815088272094727,
      "rewards/rejected": 0.15061315894126892,
      "step": 75
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1.1433136488069842,
      "learning_rate": 1.9738871998220857e-05,
      "logits/chosen": -0.9010915160179138,
      "logits/rejected": -0.8795827031135559,
      "logps/chosen": -262.4130859375,
      "logps/rejected": -271.01715087890625,
      "loss": 0.7053,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.17778648436069489,
      "rewards/margins": -0.021287482231855392,
      "rewards/rejected": 0.19907397031784058,
      "step": 76
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 1.0427063458271628,
      "learning_rate": 1.9728970322622485e-05,
      "logits/chosen": -0.7031775712966919,
      "logits/rejected": -0.7411277890205383,
      "logps/chosen": -193.88453674316406,
      "logps/rejected": -206.69717407226562,
      "loss": 0.7022,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.14540807902812958,
      "rewards/margins": -0.01670001819729805,
      "rewards/rejected": 0.16210810840129852,
      "step": 77
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5805951417250015,
      "learning_rate": 1.9718886971205206e-05,
      "logits/chosen": -0.7437899708747864,
      "logits/rejected": -0.7988364696502686,
      "logps/chosen": -192.1591796875,
      "logps/rejected": -267.96624755859375,
      "loss": 0.7082,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.17499475181102753,
      "rewards/margins": -0.01750439777970314,
      "rewards/rejected": 0.19249914586544037,
      "step": 78
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 1.621625918627536,
      "learning_rate": 1.970862213226244e-05,
      "logits/chosen": -0.7469302415847778,
      "logits/rejected": -0.7896249294281006,
      "logps/chosen": -282.3143310546875,
      "logps/rejected": -313.4967956542969,
      "loss": 0.6896,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.29359132051467896,
      "rewards/margins": 0.011758549138903618,
      "rewards/rejected": 0.2818327844142914,
      "step": 79
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.1173969419266487,
      "learning_rate": 1.9698175997476657e-05,
      "logits/chosen": -0.6974039077758789,
      "logits/rejected": -0.7964087724685669,
      "logps/chosen": -247.0044403076172,
      "logps/rejected": -212.37408447265625,
      "loss": 0.6827,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.2257152795791626,
      "rewards/margins": 0.033821407705545425,
      "rewards/rejected": 0.19189387559890747,
      "step": 80
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0669806194708296,
      "learning_rate": 1.968754876191578e-05,
      "logits/chosen": -0.9016672968864441,
      "logits/rejected": -1.0475850105285645,
      "logps/chosen": -315.45367431640625,
      "logps/rejected": -192.37515258789062,
      "loss": 0.6211,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.3037004768848419,
      "rewards/margins": 0.20748130977153778,
      "rewards/rejected": 0.09621918201446533,
      "step": 81
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.8862693757063085,
      "learning_rate": 1.9676740624029566e-05,
      "logits/chosen": -0.7899274826049805,
      "logits/rejected": -0.9021250009536743,
      "logps/chosen": -161.0811309814453,
      "logps/rejected": -179.509521484375,
      "loss": 0.7146,
      "rewards/accuracies": 0.125,
      "rewards/chosen": 0.10204997658729553,
      "rewards/margins": -0.041605181992053986,
      "rewards/rejected": 0.14365516602993011,
      "step": 82
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 1.0445237016084128,
      "learning_rate": 1.9665751785645874e-05,
      "logits/chosen": -0.8707171678543091,
      "logits/rejected": -0.9341558218002319,
      "logps/chosen": -259.30731201171875,
      "logps/rejected": -222.85598754882812,
      "loss": 0.6797,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.17315301299095154,
      "rewards/margins": 0.03391824662685394,
      "rewards/rejected": 0.1392347514629364,
      "step": 83
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.65389314339066,
      "learning_rate": 1.9654582451966915e-05,
      "logits/chosen": -0.7290840744972229,
      "logits/rejected": -0.6193615794181824,
      "logps/chosen": -200.16268920898438,
      "logps/rejected": -398.64031982421875,
      "loss": 0.7138,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.24242888391017914,
      "rewards/margins": -0.029829028993844986,
      "rewards/rejected": 0.272257924079895,
      "step": 84
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 1.1532268696269568,
      "learning_rate": 1.9643232831565417e-05,
      "logits/chosen": -0.7403106093406677,
      "logits/rejected": -0.7697539329528809,
      "logps/chosen": -337.5404052734375,
      "logps/rejected": -203.9202880859375,
      "loss": 0.6881,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.20558631420135498,
      "rewards/margins": 0.024092305451631546,
      "rewards/rejected": 0.18149401247501373,
      "step": 85
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 1.0433162724579783,
      "learning_rate": 1.9631703136380716e-05,
      "logits/chosen": -0.8269760012626648,
      "logits/rejected": -0.8973485231399536,
      "logps/chosen": -132.91908264160156,
      "logps/rejected": -163.84120178222656,
      "loss": 0.6679,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.14569222927093506,
      "rewards/margins": 0.0561646893620491,
      "rewards/rejected": 0.08952754735946655,
      "step": 86
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2132554050893471,
      "learning_rate": 1.961999358171482e-05,
      "logits/chosen": -0.7564542889595032,
      "logits/rejected": -0.8849428296089172,
      "logps/chosen": -233.04556274414062,
      "logps/rejected": -123.58810424804688,
      "loss": 0.6487,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.1819319874048233,
      "rewards/margins": 0.09273045510053635,
      "rewards/rejected": 0.08920153230428696,
      "step": 87
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.142868500678641,
      "learning_rate": 1.960810438622838e-05,
      "logits/chosen": -0.8611340522766113,
      "logits/rejected": -0.7907325625419617,
      "logps/chosen": -276.313720703125,
      "logps/rejected": -250.32394409179688,
      "loss": 0.6363,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.30038654804229736,
      "rewards/margins": 0.12351736426353455,
      "rewards/rejected": 0.17686918377876282,
      "step": 88
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 1.0067670263911441,
      "learning_rate": 1.959603577193659e-05,
      "logits/chosen": -0.5316515564918518,
      "logits/rejected": -0.656502366065979,
      "logps/chosen": -293.1531066894531,
      "logps/rejected": -222.18026733398438,
      "loss": 0.6703,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.21175935864448547,
      "rewards/margins": 0.049889806658029556,
      "rewards/rejected": 0.16186955571174622,
      "step": 89
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3349490161689954,
      "learning_rate": 1.9583787964205073e-05,
      "logits/chosen": -0.8293623924255371,
      "logits/rejected": -0.843344509601593,
      "logps/chosen": -254.80218505859375,
      "logps/rejected": -345.1720886230469,
      "loss": 0.681,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.27770212292671204,
      "rewards/margins": 0.03485392406582832,
      "rewards/rejected": 0.2428482174873352,
      "step": 90
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 1.148183677806102,
      "learning_rate": 1.9571361191745647e-05,
      "logits/chosen": -0.7116189002990723,
      "logits/rejected": -0.7676888704299927,
      "logps/chosen": -153.96107482910156,
      "logps/rejected": -221.95150756835938,
      "loss": 0.6828,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.16341927647590637,
      "rewards/margins": 0.023462075740098953,
      "rewards/rejected": 0.13995720446109772,
      "step": 91
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.279563677972309,
      "learning_rate": 1.955875568661206e-05,
      "logits/chosen": -0.7679170966148376,
      "logits/rejected": -0.8104420900344849,
      "logps/chosen": -383.68115234375,
      "logps/rejected": -303.35003662109375,
      "loss": 0.6285,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4500585198402405,
      "rewards/margins": 0.1438441276550293,
      "rewards/rejected": 0.3062143921852112,
      "step": 92
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1652543795457704,
      "learning_rate": 1.9545971684195664e-05,
      "logits/chosen": -0.7264024019241333,
      "logits/rejected": -0.8835350871086121,
      "logps/chosen": -198.02926635742188,
      "logps/rejected": -188.9057159423828,
      "loss": 0.7086,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.1586226373910904,
      "rewards/margins": -0.02732669562101364,
      "rewards/rejected": 0.18594935536384583,
      "step": 93
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.9186438168259423,
      "learning_rate": 1.9533009423221014e-05,
      "logits/chosen": -0.6127186417579651,
      "logits/rejected": -0.5122901201248169,
      "logps/chosen": -160.90919494628906,
      "logps/rejected": -217.99935913085938,
      "loss": 0.6946,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.1465466320514679,
      "rewards/margins": -0.0017370404675602913,
      "rewards/rejected": 0.14828366041183472,
      "step": 94
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 0.9291240683799454,
      "learning_rate": 1.951986914574141e-05,
      "logits/chosen": -0.6040874123573303,
      "logits/rejected": -0.621811032295227,
      "logps/chosen": -177.1776580810547,
      "logps/rejected": -195.1343231201172,
      "loss": 0.6972,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.1461208015680313,
      "rewards/margins": -0.007121598348021507,
      "rewards/rejected": 0.15324239432811737,
      "step": 95
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8731353388829695,
      "learning_rate": 1.9506551097134384e-05,
      "logits/chosen": -0.44564443826675415,
      "logits/rejected": -0.7276003956794739,
      "logps/chosen": -251.49395751953125,
      "logps/rejected": -177.58267211914062,
      "loss": 0.7019,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.14614765346050262,
      "rewards/margins": -0.015956027433276176,
      "rewards/rejected": 0.16210368275642395,
      "step": 96
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 1.122867948127557,
      "learning_rate": 1.94930555260971e-05,
      "logits/chosen": -0.7400148510932922,
      "logits/rejected": -0.6137272119522095,
      "logps/chosen": -143.67758178710938,
      "logps/rejected": -203.25277709960938,
      "loss": 0.6904,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.12537552416324615,
      "rewards/margins": 0.006480389274656773,
      "rewards/rejected": 0.11889512836933136,
      "step": 97
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 1.6834120508553716,
      "learning_rate": 1.947938268464173e-05,
      "logits/chosen": -0.9527689218521118,
      "logits/rejected": -0.8962512016296387,
      "logps/chosen": -321.7964782714844,
      "logps/rejected": -270.6646728515625,
      "loss": 0.6893,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.26785507798194885,
      "rewards/margins": 0.014093130826950073,
      "rewards/rejected": 0.2537619471549988,
      "step": 98
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1215388780063582,
      "learning_rate": 1.9465532828090735e-05,
      "logits/chosen": -0.5237336158752441,
      "logits/rejected": -0.6190329790115356,
      "logps/chosen": -233.57589721679688,
      "logps/rejected": -140.541748046875,
      "loss": 0.6716,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.16546061635017395,
      "rewards/margins": 0.04592159390449524,
      "rewards/rejected": 0.11953902244567871,
      "step": 99
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.9391887078551933,
      "learning_rate": 1.9451506215072106e-05,
      "logits/chosen": -0.6384422183036804,
      "logits/rejected": -0.5955289006233215,
      "logps/chosen": -204.77505493164062,
      "logps/rejected": -187.25376892089844,
      "loss": 0.6702,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.17933389544487,
      "rewards/margins": 0.048850566148757935,
      "rewards/rejected": 0.13048332929611206,
      "step": 100
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 0.9750610100168899,
      "learning_rate": 1.943730310751453e-05,
      "logits/chosen": -0.7456374764442444,
      "logits/rejected": -0.8448228240013123,
      "logps/chosen": -271.6822509765625,
      "logps/rejected": -177.87753295898438,
      "loss": 0.6181,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.32293519377708435,
      "rewards/margins": 0.20907963812351227,
      "rewards/rejected": 0.11385554820299149,
      "step": 101
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2375825661752395,
      "learning_rate": 1.9422923770642494e-05,
      "logits/chosen": -0.8233010768890381,
      "logits/rejected": -0.5577080845832825,
      "logps/chosen": -167.47726440429688,
      "logps/rejected": -245.3667755126953,
      "loss": 0.6837,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.1307487189769745,
      "rewards/margins": 0.020395662635564804,
      "rewards/rejected": 0.11035305261611938,
      "step": 102
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 1.1790611675951537,
      "learning_rate": 1.9408368472971344e-05,
      "logits/chosen": -0.7429320216178894,
      "logits/rejected": -0.8860034942626953,
      "logps/chosen": -382.5369873046875,
      "logps/rejected": -233.20863342285156,
      "loss": 0.6498,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.31130191683769226,
      "rewards/margins": 0.1055060625076294,
      "rewards/rejected": 0.20579586923122406,
      "step": 103
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.213336954600481,
      "learning_rate": 1.9393637486302257e-05,
      "logits/chosen": -0.8045426607131958,
      "logits/rejected": -0.9052605032920837,
      "logps/chosen": -298.6385498046875,
      "logps/rejected": -211.51998901367188,
      "loss": 0.6076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3501095175743103,
      "rewards/margins": 0.1882217675447464,
      "rewards/rejected": 0.16188772022724152,
      "step": 104
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2144332143010914,
      "learning_rate": 1.937873108571718e-05,
      "logits/chosen": -0.5766074061393738,
      "logits/rejected": -0.6279776692390442,
      "logps/chosen": -300.28948974609375,
      "logps/rejected": -267.4771423339844,
      "loss": 0.6149,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.3364766240119934,
      "rewards/margins": 0.19002816081047058,
      "rewards/rejected": 0.14644843339920044,
      "step": 105
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 1.2054674703575161,
      "learning_rate": 1.936364954957368e-05,
      "logits/chosen": -0.6943568587303162,
      "logits/rejected": -0.8877598643302917,
      "logps/chosen": -368.1730651855469,
      "logps/rejected": -286.0557556152344,
      "loss": 0.6008,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4311867952346802,
      "rewards/margins": 0.24325264990329742,
      "rewards/rejected": 0.18793416023254395,
      "step": 106
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 1.3132962127867962,
      "learning_rate": 1.934839315949976e-05,
      "logits/chosen": -0.6699625253677368,
      "logits/rejected": -0.7616907954216003,
      "logps/chosen": -477.056884765625,
      "logps/rejected": -444.65301513671875,
      "loss": 0.5856,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4421803653240204,
      "rewards/margins": 0.26851412653923035,
      "rewards/rejected": 0.17366626858711243,
      "step": 107
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.184003954014104,
      "learning_rate": 1.933296220038858e-05,
      "logits/chosen": -0.795508861541748,
      "logits/rejected": -1.0085328817367554,
      "logps/chosen": -330.99945068359375,
      "logps/rejected": -180.03489685058594,
      "loss": 0.5944,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3750373125076294,
      "rewards/margins": 0.24583998322486877,
      "rewards/rejected": 0.12919732928276062,
      "step": 108
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 1.1402370890643552,
      "learning_rate": 1.9317356960393158e-05,
      "logits/chosen": -0.6576420068740845,
      "logits/rejected": -0.7475578188896179,
      "logps/chosen": -392.26904296875,
      "logps/rejected": -292.04608154296875,
      "loss": 0.6304,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.3801758289337158,
      "rewards/margins": 0.14978176355361938,
      "rewards/rejected": 0.23039408028125763,
      "step": 109
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.983077480819246,
      "learning_rate": 1.9301577730920975e-05,
      "logits/chosen": -0.49774864315986633,
      "logits/rejected": -0.7072737812995911,
      "logps/chosen": -237.2951202392578,
      "logps/rejected": -165.5612335205078,
      "loss": 0.6548,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.22642844915390015,
      "rewards/margins": 0.09097582846879959,
      "rewards/rejected": 0.13545259833335876,
      "step": 110
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9944844129250917,
      "learning_rate": 1.9285624806628543e-05,
      "logits/chosen": -0.7661413550376892,
      "logits/rejected": -0.8770818114280701,
      "logps/chosen": -313.616943359375,
      "logps/rejected": -210.67852783203125,
      "loss": 0.6352,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.28489771485328674,
      "rewards/margins": 0.13736510276794434,
      "rewards/rejected": 0.1475325971841812,
      "step": 111
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.3527116686033094,
      "learning_rate": 1.9269498485415897e-05,
      "logits/chosen": -0.6945568323135376,
      "logits/rejected": -0.7348389625549316,
      "logps/chosen": -268.7799987792969,
      "logps/rejected": -344.41748046875,
      "loss": 0.6444,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.341846764087677,
      "rewards/margins": 0.10972509533166885,
      "rewards/rejected": 0.23212167620658875,
      "step": 112
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 1.3782880223878375,
      "learning_rate": 1.925319906842103e-05,
      "logits/chosen": -0.699766218662262,
      "logits/rejected": -0.728407621383667,
      "logps/chosen": -291.69683837890625,
      "logps/rejected": -238.67715454101562,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.3699530363082886,
      "rewards/margins": 0.025833118706941605,
      "rewards/rejected": 0.34411993622779846,
      "step": 113
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.463775000745544,
      "learning_rate": 1.923672686001427e-05,
      "logits/chosen": -0.4958619475364685,
      "logits/rejected": -0.7000864148139954,
      "logps/chosen": -312.8466491699219,
      "logps/rejected": -170.20184326171875,
      "loss": 0.5879,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3807123899459839,
      "rewards/margins": 0.23220157623291016,
      "rewards/rejected": 0.14851081371307373,
      "step": 114
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 1.068803098820717,
      "learning_rate": 1.922008216779261e-05,
      "logits/chosen": -0.7438568472862244,
      "logits/rejected": -0.8282009363174438,
      "logps/chosen": -280.8074645996094,
      "logps/rejected": -219.53164672851562,
      "loss": 0.6126,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3725665211677551,
      "rewards/margins": 0.20841357111930847,
      "rewards/rejected": 0.16415296494960785,
      "step": 115
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 1.255500801593581,
      "learning_rate": 1.920326530257394e-05,
      "logits/chosen": -0.9807776808738708,
      "logits/rejected": -0.9147565960884094,
      "logps/chosen": -206.34860229492188,
      "logps/rejected": -240.5369873046875,
      "loss": 0.6335,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3049001693725586,
      "rewards/margins": 0.12927864491939545,
      "rewards/rejected": 0.17562153935432434,
      "step": 116
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3257718051625678,
      "learning_rate": 1.9186276578391268e-05,
      "logits/chosen": -0.6736062169075012,
      "logits/rejected": -0.7527647614479065,
      "logps/chosen": -260.3569641113281,
      "logps/rejected": -170.51876831054688,
      "loss": 0.6467,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.27582159638404846,
      "rewards/margins": 0.15163354575634003,
      "rewards/rejected": 0.12418806552886963,
      "step": 117
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 0.9562943716288648,
      "learning_rate": 1.9169116312486835e-05,
      "logits/chosen": -0.6653448343276978,
      "logits/rejected": -0.6594663858413696,
      "logps/chosen": -183.03280639648438,
      "logps/rejected": -163.51373291015625,
      "loss": 0.6687,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.18303069472312927,
      "rewards/margins": 0.056074108928442,
      "rewards/rejected": 0.12695656716823578,
      "step": 118
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 1.3844063404402083,
      "learning_rate": 1.9151784825306205e-05,
      "logits/chosen": -0.9126242995262146,
      "logits/rejected": -0.5394100546836853,
      "logps/chosen": -127.39032745361328,
      "logps/rejected": -302.9576110839844,
      "loss": 0.7084,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.1687244325876236,
      "rewards/margins": -0.023064959794282913,
      "rewards/rejected": 0.1917893886566162,
      "step": 119
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.171624169526314,
      "learning_rate": 1.9134282440492272e-05,
      "logits/chosen": -0.5746673345565796,
      "logits/rejected": -0.814100980758667,
      "logps/chosen": -259.16082763671875,
      "logps/rejected": -137.68963623046875,
      "loss": 0.6437,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.22922451794147491,
      "rewards/margins": 0.10463012754917145,
      "rewards/rejected": 0.12459439784288406,
      "step": 120
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 1.0384538057914254,
      "learning_rate": 1.911660948487922e-05,
      "logits/chosen": -0.531108021736145,
      "logits/rejected": -0.5573870539665222,
      "logps/chosen": -192.93252563476562,
      "logps/rejected": -245.25634765625,
      "loss": 0.6948,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.19724580645561218,
      "rewards/margins": 0.008957583457231522,
      "rewards/rejected": 0.18828824162483215,
      "step": 121
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 1.1840251476349366,
      "learning_rate": 1.9098766288486426e-05,
      "logits/chosen": -0.8735395669937134,
      "logits/rejected": -0.6966314911842346,
      "logps/chosen": -217.8902587890625,
      "logps/rejected": -231.37277221679688,
      "loss": 0.6538,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.2721586227416992,
      "rewards/margins": 0.09719905257225037,
      "rewards/rejected": 0.17495959997177124,
      "step": 122
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3682229616827721,
      "learning_rate": 1.9080753184512284e-05,
      "logits/chosen": -0.898307740688324,
      "logits/rejected": -0.9768824577331543,
      "logps/chosen": -296.33953857421875,
      "logps/rejected": -191.0133514404297,
      "loss": 0.6169,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.34641656279563904,
      "rewards/margins": 0.18677806854248047,
      "rewards/rejected": 0.15963846445083618,
      "step": 123
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 1.3540355129796842,
      "learning_rate": 1.9062570509327993e-05,
      "logits/chosen": -0.5242950320243835,
      "logits/rejected": -0.6750625371932983,
      "logps/chosen": -269.9512023925781,
      "logps/rejected": -172.1424560546875,
      "loss": 0.6286,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3771114945411682,
      "rewards/margins": 0.14527636766433716,
      "rewards/rejected": 0.23183512687683105,
      "step": 124
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1.3406962360227097,
      "learning_rate": 1.9044218602471275e-05,
      "logits/chosen": -0.45604223012924194,
      "logits/rejected": -0.7269304990768433,
      "logps/chosen": -343.02471923828125,
      "logps/rejected": -282.67388916015625,
      "loss": 0.6024,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.49495989084243774,
      "rewards/margins": 0.2372477501630783,
      "rewards/rejected": 0.25771215558052063,
      "step": 125
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2621849781227465,
      "learning_rate": 1.9025697806640035e-05,
      "logits/chosen": -0.7084760665893555,
      "logits/rejected": -0.6864144206047058,
      "logps/chosen": -214.0308837890625,
      "logps/rejected": -182.98983764648438,
      "loss": 0.6608,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.2292732149362564,
      "rewards/margins": 0.06902334839105606,
      "rewards/rejected": 0.16024987399578094,
      "step": 126
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 0.9487007203201611,
      "learning_rate": 1.9007008467685947e-05,
      "logits/chosen": -0.8033277988433838,
      "logits/rejected": -0.8971207141876221,
      "logps/chosen": -342.0579528808594,
      "logps/rejected": -202.02099609375,
      "loss": 0.6103,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4374983608722687,
      "rewards/margins": 0.26605719327926636,
      "rewards/rejected": 0.1714411824941635,
      "step": 127
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 1.2131093882952066,
      "learning_rate": 1.8988150934608014e-05,
      "logits/chosen": -0.7749898433685303,
      "logits/rejected": -0.6841121912002563,
      "logps/chosen": -213.01507568359375,
      "logps/rejected": -251.4747314453125,
      "loss": 0.6932,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.28922054171562195,
      "rewards/margins": 0.016942098736763,
      "rewards/rejected": 0.27227842807769775,
      "step": 128
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2995790074993876,
      "learning_rate": 1.8969125559546054e-05,
      "logits/chosen": -0.7440186142921448,
      "logits/rejected": -0.5765056610107422,
      "logps/chosen": -135.2701416015625,
      "logps/rejected": -173.50045776367188,
      "loss": 0.6787,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.19876796007156372,
      "rewards/margins": 0.038196317851543427,
      "rewards/rejected": 0.16057166457176208,
      "step": 129
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 1.2119065375943612,
      "learning_rate": 1.894993269777411e-05,
      "logits/chosen": -0.8279611468315125,
      "logits/rejected": -0.8812400102615356,
      "logps/chosen": -232.7667236328125,
      "logps/rejected": -165.70233154296875,
      "loss": 0.6282,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.25830042362213135,
      "rewards/margins": 0.14047564566135406,
      "rewards/rejected": 0.11782475560903549,
      "step": 130
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 1.418979253185782,
      "learning_rate": 1.893057270769381e-05,
      "logits/chosen": -0.6338487863540649,
      "logits/rejected": -0.5992584228515625,
      "logps/chosen": -204.00633239746094,
      "logps/rejected": -215.63963317871094,
      "loss": 0.7166,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.23993395268917084,
      "rewards/margins": -0.03377516195178032,
      "rewards/rejected": 0.27370911836624146,
      "step": 131
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2380214863947825,
      "learning_rate": 1.8911045950827693e-05,
      "logits/chosen": -0.7258996367454529,
      "logits/rejected": -0.5910700559616089,
      "logps/chosen": -229.07913208007812,
      "logps/rejected": -231.41534423828125,
      "loss": 0.6597,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.30070579051971436,
      "rewards/margins": 0.08207230269908905,
      "rewards/rejected": 0.2186334729194641,
      "step": 132
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 1.0901585606204294,
      "learning_rate": 1.8891352791812452e-05,
      "logits/chosen": -0.7285498380661011,
      "logits/rejected": -0.8028004169464111,
      "logps/chosen": -245.0622100830078,
      "logps/rejected": -259.7438659667969,
      "loss": 0.6354,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.33273187279701233,
      "rewards/margins": 0.1525079756975174,
      "rewards/rejected": 0.18022389709949493,
      "step": 133
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 1.6011556713422528,
      "learning_rate": 1.8871493598392122e-05,
      "logits/chosen": -0.5403958559036255,
      "logits/rejected": -0.8463615775108337,
      "logps/chosen": -363.9878845214844,
      "logps/rejected": -188.833740234375,
      "loss": 0.6182,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.35672786831855774,
      "rewards/margins": 0.1702512949705124,
      "rewards/rejected": 0.18647658824920654,
      "step": 134
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1114634346003256,
      "learning_rate": 1.885146874141121e-05,
      "logits/chosen": -1.0651538372039795,
      "logits/rejected": -1.0022578239440918,
      "logps/chosen": -172.48638916015625,
      "logps/rejected": -203.9729766845703,
      "loss": 0.6896,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.1571962833404541,
      "rewards/margins": 0.012391779571771622,
      "rewards/rejected": 0.14480450749397278,
      "step": 135
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 1.4347882608382783,
      "learning_rate": 1.8831278594807783e-05,
      "logits/chosen": -1.0440313816070557,
      "logits/rejected": -1.018298864364624,
      "logps/chosen": -192.80935668945312,
      "logps/rejected": -256.10675048828125,
      "loss": 0.6663,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.21928295493125916,
      "rewards/margins": 0.07680673152208328,
      "rewards/rejected": 0.14247621595859528,
      "step": 136
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 2.546136854426668,
      "learning_rate": 1.881092353560646e-05,
      "logits/chosen": -0.8675659894943237,
      "logits/rejected": -0.8180983066558838,
      "logps/chosen": -324.65869140625,
      "logps/rejected": -344.9883728027344,
      "loss": 0.6799,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.3935297131538391,
      "rewards/margins": 0.04752519726753235,
      "rewards/rejected": 0.34600454568862915,
      "step": 137
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1025052196353178,
      "learning_rate": 1.8790403943911403e-05,
      "logits/chosen": -0.68061763048172,
      "logits/rejected": -0.7050638198852539,
      "logps/chosen": -243.19056701660156,
      "logps/rejected": -248.35133361816406,
      "loss": 0.6342,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.35095566511154175,
      "rewards/margins": 0.13964280486106873,
      "rewards/rejected": 0.21131286025047302,
      "step": 138
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 1.427902608371289,
      "learning_rate": 1.8769720202899196e-05,
      "logits/chosen": -0.5366867780685425,
      "logits/rejected": -0.8396612405776978,
      "logps/chosen": -367.08404541015625,
      "logps/rejected": -190.29428100585938,
      "loss": 0.5675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.556442141532898,
      "rewards/margins": 0.28160560131073,
      "rewards/rejected": 0.27483654022216797,
      "step": 139
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.214555025288828,
      "learning_rate": 1.8748872698811695e-05,
      "logits/chosen": -0.5171796679496765,
      "logits/rejected": -0.6888562440872192,
      "logps/chosen": -284.84912109375,
      "logps/rejected": -177.67947387695312,
      "loss": 0.6046,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.29535478353500366,
      "rewards/margins": 0.2027711123228073,
      "rewards/rejected": 0.09258370101451874,
      "step": 140
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3507426868094599,
      "learning_rate": 1.872786182094882e-05,
      "logits/chosen": -0.765378475189209,
      "logits/rejected": -0.7541460990905762,
      "logps/chosen": -213.05271911621094,
      "logps/rejected": -220.12176513671875,
      "loss": 0.6701,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.30059707164764404,
      "rewards/margins": 0.13095617294311523,
      "rewards/rejected": 0.1696409285068512,
      "step": 141
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 1.2833428386649977,
      "learning_rate": 1.870668796166129e-05,
      "logits/chosen": -0.7246178984642029,
      "logits/rejected": -0.6598215699195862,
      "logps/chosen": -226.03160095214844,
      "logps/rejected": -212.98898315429688,
      "loss": 0.6228,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.3651866316795349,
      "rewards/margins": 0.21240104734897614,
      "rewards/rejected": 0.15278559923171997,
      "step": 142
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 1.6294915407891186,
      "learning_rate": 1.8685351516343277e-05,
      "logits/chosen": -0.8665141463279724,
      "logits/rejected": -0.8033522963523865,
      "logps/chosen": -347.4326477050781,
      "logps/rejected": -300.4802551269531,
      "loss": 0.6358,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.45428466796875,
      "rewards/margins": 0.14015763998031616,
      "rewards/rejected": 0.31412702798843384,
      "step": 143
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9426424630650871,
      "learning_rate": 1.8663852883425045e-05,
      "logits/chosen": -0.7744112610816956,
      "logits/rejected": -0.5550143122673035,
      "logps/chosen": -147.87872314453125,
      "logps/rejected": -261.14227294921875,
      "loss": 0.6959,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.1746859848499298,
      "rewards/margins": -0.000726703554391861,
      "rewards/rejected": 0.17541268467903137,
      "step": 144
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 1.158097157768976,
      "learning_rate": 1.86421924643655e-05,
      "logits/chosen": -0.7010321617126465,
      "logits/rejected": -0.7830922603607178,
      "logps/chosen": -157.5899200439453,
      "logps/rejected": -158.13021850585938,
      "loss": 0.6665,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.15684351325035095,
      "rewards/margins": 0.06185295432806015,
      "rewards/rejected": 0.0949905514717102,
      "step": 145
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 1.2122251002357864,
      "learning_rate": 1.8620370663644676e-05,
      "logits/chosen": -0.9009883999824524,
      "logits/rejected": -0.9221879839897156,
      "logps/chosen": -225.3656768798828,
      "logps/rejected": -247.2025909423828,
      "loss": 0.6479,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.2667481601238251,
      "rewards/margins": 0.10366366803646088,
      "rewards/rejected": 0.163084477186203,
      "step": 146
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7789662762726781,
      "learning_rate": 1.8598387888756224e-05,
      "logits/chosen": -0.850508451461792,
      "logits/rejected": -0.9315414428710938,
      "logps/chosen": -389.2134704589844,
      "logps/rejected": -244.39015197753906,
      "loss": 0.5884,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.5478103160858154,
      "rewards/margins": 0.24644379317760468,
      "rewards/rejected": 0.30136656761169434,
      "step": 147
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 1.487216919321239,
      "learning_rate": 1.857624455019976e-05,
      "logits/chosen": -0.7325104475021362,
      "logits/rejected": -0.9018292427062988,
      "logps/chosen": -288.3155517578125,
      "logps/rejected": -195.68441772460938,
      "loss": 0.603,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3607851266860962,
      "rewards/margins": 0.22496575117111206,
      "rewards/rejected": 0.13581940531730652,
      "step": 148
    },
    {
      "epoch": 0.9933333333333333,
      "grad_norm": 1.4419627368890002,
      "learning_rate": 1.855394106147322e-05,
      "logits/chosen": -0.8336827754974365,
      "logits/rejected": -0.7632896900177002,
      "logps/chosen": -256.520263671875,
      "logps/rejected": -372.56060791015625,
      "loss": 0.6269,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.32446277141571045,
      "rewards/margins": 0.16492173075675964,
      "rewards/rejected": 0.1595410406589508,
      "step": 149
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.526584055815737,
      "learning_rate": 1.853147783906514e-05,
      "logits/chosen": -0.983122706413269,
      "logits/rejected": -0.8806900978088379,
      "logps/chosen": -153.28726196289062,
      "logps/rejected": -246.43365478515625,
      "loss": 0.6583,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.23541703820228577,
      "rewards/margins": 0.08181224018335342,
      "rewards/rejected": 0.15360479056835175,
      "step": 150
    },
    {
      "epoch": 1.0066666666666666,
      "grad_norm": 1.0988766005557227,
      "learning_rate": 1.8508855302446868e-05,
      "logits/chosen": -0.8423429131507874,
      "logits/rejected": -0.7044411897659302,
      "logps/chosen": -162.46627807617188,
      "logps/rejected": -226.3737335205078,
      "loss": 0.6507,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.18367579579353333,
      "rewards/margins": 0.09221842885017395,
      "rewards/rejected": 0.09145735949277878,
      "step": 151
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1.262056949037858,
      "learning_rate": 1.8486073874064745e-05,
      "logits/chosen": -0.6845166087150574,
      "logits/rejected": -0.8599939346313477,
      "logps/chosen": -270.4088439941406,
      "logps/rejected": -277.5988464355469,
      "loss": 0.5743,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.42428648471832275,
      "rewards/margins": 0.27722954750061035,
      "rewards/rejected": 0.1470569521188736,
      "step": 152
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.506055608844834,
      "learning_rate": 1.84631339793322e-05,
      "logits/chosen": -0.8065060377120972,
      "logits/rejected": -0.8220964074134827,
      "logps/chosen": -234.79791259765625,
      "logps/rejected": -271.4470520019531,
      "loss": 0.5681,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4499865472316742,
      "rewards/margins": 0.3016831874847412,
      "rewards/rejected": 0.14830335974693298,
      "step": 153
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 1.2665594913080802,
      "learning_rate": 1.8440036046621816e-05,
      "logits/chosen": -0.5702605843544006,
      "logits/rejected": -0.6629225611686707,
      "logps/chosen": -284.3936462402344,
      "logps/rejected": -229.77793884277344,
      "loss": 0.5542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4358865022659302,
      "rewards/margins": 0.308943510055542,
      "rewards/rejected": 0.12694299221038818,
      "step": 154
    },
    {
      "epoch": 1.0333333333333334,
      "grad_norm": 1.2944993009981616,
      "learning_rate": 1.8416780507257334e-05,
      "logits/chosen": -0.9217891097068787,
      "logits/rejected": -0.8125755786895752,
      "logps/chosen": -199.3885498046875,
      "logps/rejected": -202.36895751953125,
      "loss": 0.6007,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.32055166363716125,
      "rewards/margins": 0.21369411051273346,
      "rewards/rejected": 0.1068575382232666,
      "step": 155
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.211038597562847,
      "learning_rate": 1.8393367795505587e-05,
      "logits/chosen": -0.7430174350738525,
      "logits/rejected": -0.6903871297836304,
      "logps/chosen": -199.57017517089844,
      "logps/rejected": -197.25021362304688,
      "loss": 0.5625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26778680086135864,
      "rewards/margins": 0.2921735346317291,
      "rewards/rejected": -0.024386722594499588,
      "step": 156
    },
    {
      "epoch": 1.0466666666666666,
      "grad_norm": 1.4119848088238862,
      "learning_rate": 1.8369798348568403e-05,
      "logits/chosen": -0.7566803693771362,
      "logits/rejected": -0.7723872065544128,
      "logps/chosen": -172.1080322265625,
      "logps/rejected": -195.34547424316406,
      "loss": 0.6228,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.23544493317604065,
      "rewards/margins": 0.15213094651699066,
      "rewards/rejected": 0.08331398665904999,
      "step": 157
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 1.4069011028618705,
      "learning_rate": 1.834607260657443e-05,
      "logits/chosen": -0.9349197149276733,
      "logits/rejected": -0.8502047061920166,
      "logps/chosen": -141.3337860107422,
      "logps/rejected": -223.3170166015625,
      "loss": 0.6231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1833478808403015,
      "rewards/margins": 0.14906169474124908,
      "rewards/rejected": 0.03428618609905243,
      "step": 158
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.3503430990165595,
      "learning_rate": 1.832219101257092e-05,
      "logits/chosen": -0.684035062789917,
      "logits/rejected": -0.7520215511322021,
      "logps/chosen": -265.8523254394531,
      "logps/rejected": -234.0042266845703,
      "loss": 0.4975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4868091940879822,
      "rewards/margins": 0.48521363735198975,
      "rewards/rejected": 0.0015955343842506409,
      "step": 159
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.9999300216985524,
      "learning_rate": 1.829815401251547e-05,
      "logits/chosen": -0.7051874995231628,
      "logits/rejected": -0.9269221425056458,
      "logps/chosen": -379.5652770996094,
      "logps/rejected": -141.80142211914062,
      "loss": 0.5372,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4916360676288605,
      "rewards/margins": 0.4569774270057678,
      "rewards/rejected": 0.03465861827135086,
      "step": 160
    },
    {
      "epoch": 1.0733333333333333,
      "grad_norm": 1.2269784015722545,
      "learning_rate": 1.8273962055267667e-05,
      "logits/chosen": -0.7873159050941467,
      "logits/rejected": -0.8309124708175659,
      "logps/chosen": -312.65130615234375,
      "logps/rejected": -185.05288696289062,
      "loss": 0.5972,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.34113991260528564,
      "rewards/margins": 0.23558412492275238,
      "rewards/rejected": 0.10555578768253326,
      "step": 161
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.463826143937624,
      "learning_rate": 1.8249615592580733e-05,
      "logits/chosen": -0.491449236869812,
      "logits/rejected": -0.6955943703651428,
      "logps/chosen": -293.7156982421875,
      "logps/rejected": -254.1416473388672,
      "loss": 0.6236,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.28146490454673767,
      "rewards/margins": 0.1712327003479004,
      "rewards/rejected": 0.11023221164941788,
      "step": 162
    },
    {
      "epoch": 1.0866666666666667,
      "grad_norm": 1.901663907433842,
      "learning_rate": 1.822511507909307e-05,
      "logits/chosen": -0.7843979597091675,
      "logits/rejected": -0.7320147752761841,
      "logps/chosen": -225.84283447265625,
      "logps/rejected": -318.46368408203125,
      "loss": 0.6062,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.318915992975235,
      "rewards/margins": 0.24551966786384583,
      "rewards/rejected": 0.07339630275964737,
      "step": 163
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 1.3887339818186908,
      "learning_rate": 1.8200460972319786e-05,
      "logits/chosen": -0.6534218788146973,
      "logits/rejected": -0.8801662921905518,
      "logps/chosen": -309.7647705078125,
      "logps/rejected": -251.08956909179688,
      "loss": 0.5425,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.40595436096191406,
      "rewards/margins": 0.40385082364082336,
      "rewards/rejected": 0.002103538252413273,
      "step": 164
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3750184664786682,
      "learning_rate": 1.817565373264413e-05,
      "logits/chosen": -0.46945324540138245,
      "logits/rejected": -0.5542582869529724,
      "logps/chosen": -221.2484588623047,
      "logps/rejected": -207.56976318359375,
      "loss": 0.6191,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3046283721923828,
      "rewards/margins": 0.17431747913360596,
      "rewards/rejected": 0.13031092286109924,
      "step": 165
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 1.5389322913223895,
      "learning_rate": 1.8150693823308913e-05,
      "logits/chosen": -0.7164161801338196,
      "logits/rejected": -0.7055826783180237,
      "logps/chosen": -146.62249755859375,
      "logps/rejected": -249.0409698486328,
      "loss": 0.6053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2188996970653534,
      "rewards/margins": 0.19597329199314117,
      "rewards/rejected": 0.02292640507221222,
      "step": 166
    },
    {
      "epoch": 1.1133333333333333,
      "grad_norm": 1.5625101470617784,
      "learning_rate": 1.8125581710407864e-05,
      "logits/chosen": -0.7513598799705505,
      "logits/rejected": -0.9585473537445068,
      "logps/chosen": -462.2280578613281,
      "logps/rejected": -307.6104736328125,
      "loss": 0.5106,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5562593340873718,
      "rewards/margins": 0.4296593964099884,
      "rewards/rejected": 0.1265999674797058,
      "step": 167
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2256887932281806,
      "learning_rate": 1.8100317862876902e-05,
      "logits/chosen": -0.4559353291988373,
      "logits/rejected": -0.6999550461769104,
      "logps/chosen": -227.39083862304688,
      "logps/rejected": -149.10446166992188,
      "loss": 0.5288,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3910258412361145,
      "rewards/margins": 0.40273517370224,
      "rewards/rejected": -0.01170935109257698,
      "step": 168
    },
    {
      "epoch": 1.1266666666666667,
      "grad_norm": 1.4247882049841267,
      "learning_rate": 1.8074902752485392e-05,
      "logits/chosen": -0.5949307084083557,
      "logits/rejected": -0.650799036026001,
      "logps/chosen": -129.14398193359375,
      "logps/rejected": -192.1744384765625,
      "loss": 0.7524,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.026545986533164978,
      "rewards/margins": -0.08700595051050186,
      "rewards/rejected": 0.06045995280146599,
      "step": 169
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 1.3487666765937352,
      "learning_rate": 1.8049336853827343e-05,
      "logits/chosen": -0.9593423008918762,
      "logits/rejected": -0.9732873439788818,
      "logps/chosen": -181.9266357421875,
      "logps/rejected": -221.83058166503906,
      "loss": 0.5708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27108079195022583,
      "rewards/margins": 0.27276724576950073,
      "rewards/rejected": -0.0016864575445652008,
      "step": 170
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 1.2513394332006103,
      "learning_rate": 1.8023620644312538e-05,
      "logits/chosen": -0.7101105451583862,
      "logits/rejected": -0.6214427351951599,
      "logps/chosen": -200.12863159179688,
      "logps/rejected": -200.39486694335938,
      "loss": 0.5515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3392416834831238,
      "rewards/margins": 0.3275148570537567,
      "rewards/rejected": 0.01172678917646408,
      "step": 171
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 2.013724088685633,
      "learning_rate": 1.7997754604157607e-05,
      "logits/chosen": -0.7017194628715515,
      "logits/rejected": -0.6327720880508423,
      "logps/chosen": -181.68017578125,
      "logps/rejected": -251.26841735839844,
      "loss": 0.6198,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.15508678555488586,
      "rewards/margins": 0.1648014485836029,
      "rewards/rejected": -0.009714659303426743,
      "step": 172
    },
    {
      "epoch": 1.1533333333333333,
      "grad_norm": 1.914183507714306,
      "learning_rate": 1.797173921637709e-05,
      "logits/chosen": -0.9979398846626282,
      "logits/rejected": -0.8820595145225525,
      "logps/chosen": -195.167724609375,
      "logps/rejected": -227.66104125976562,
      "loss": 0.6153,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.2713977098464966,
      "rewards/margins": 0.20920048654079437,
      "rewards/rejected": 0.062197234481573105,
      "step": 173
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.4169101599330183,
      "learning_rate": 1.794557496677438e-05,
      "logits/chosen": -0.6040856838226318,
      "logits/rejected": -0.8699166774749756,
      "logps/chosen": -367.2673645019531,
      "logps/rejected": -167.80441284179688,
      "loss": 0.5267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43785151839256287,
      "rewards/margins": 0.3743181824684143,
      "rewards/rejected": 0.06353333592414856,
      "step": 174
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 1.7469061342034178,
      "learning_rate": 1.791926234393268e-05,
      "logits/chosen": -0.7616602182388306,
      "logits/rejected": -0.5724701881408691,
      "logps/chosen": -198.7806396484375,
      "logps/rejected": -245.79281616210938,
      "loss": 0.6782,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.1753632128238678,
      "rewards/margins": 0.06624807417392731,
      "rewards/rejected": 0.10911515355110168,
      "step": 175
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 1.5978256173120466,
      "learning_rate": 1.7892801839205867e-05,
      "logits/chosen": -0.732404887676239,
      "logits/rejected": -0.8210093379020691,
      "logps/chosen": -208.96151733398438,
      "logps/rejected": -317.6075134277344,
      "loss": 0.6139,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.22411347925662994,
      "rewards/margins": 0.1882796287536621,
      "rewards/rejected": 0.03583385795354843,
      "step": 176
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.3511058057836334,
      "learning_rate": 1.786619394670933e-05,
      "logits/chosen": -0.7727534174919128,
      "logits/rejected": -0.9067674875259399,
      "logps/chosen": -249.7386016845703,
      "logps/rejected": -211.38287353515625,
      "loss": 0.4685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47799843549728394,
      "rewards/margins": 0.5712608098983765,
      "rewards/rejected": -0.09326232969760895,
      "step": 177
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 1.5096947183280491,
      "learning_rate": 1.7839439163310714e-05,
      "logits/chosen": -0.5941063761711121,
      "logits/rejected": -0.6711114645004272,
      "logps/chosen": -289.5123291015625,
      "logps/rejected": -285.4654846191406,
      "loss": 0.5007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4969428479671478,
      "rewards/margins": 0.46888357400894165,
      "rewards/rejected": 0.028059281408786774,
      "step": 178
    },
    {
      "epoch": 1.1933333333333334,
      "grad_norm": 1.2237495190129488,
      "learning_rate": 1.7812537988620678e-05,
      "logits/chosen": -0.812147855758667,
      "logits/rejected": -0.7183445692062378,
      "logps/chosen": -163.20936584472656,
      "logps/rejected": -141.5373077392578,
      "loss": 0.5456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2457602322101593,
      "rewards/margins": 0.3274083733558655,
      "rewards/rejected": -0.08164815604686737,
      "step": 179
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.4803428898358064,
      "learning_rate": 1.7785490924983526e-05,
      "logits/chosen": -0.6499910950660706,
      "logits/rejected": -0.8409144878387451,
      "logps/chosen": -246.31292724609375,
      "logps/rejected": -172.39022827148438,
      "loss": 0.5324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33173078298568726,
      "rewards/margins": 0.3551711440086365,
      "rewards/rejected": -0.02344036102294922,
      "step": 180
    },
    {
      "epoch": 1.2066666666666666,
      "grad_norm": 1.7272755803080089,
      "learning_rate": 1.7758298477467865e-05,
      "logits/chosen": -0.8321029543876648,
      "logits/rejected": -0.6642022728919983,
      "logps/chosen": -133.46218872070312,
      "logps/rejected": -248.74685668945312,
      "loss": 0.5785,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.20516036450862885,
      "rewards/margins": 0.25962817668914795,
      "rewards/rejected": -0.05446783825755119,
      "step": 181
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 1.2857300193520271,
      "learning_rate": 1.7730961153857155e-05,
      "logits/chosen": -0.7246720790863037,
      "logits/rejected": -0.6599438786506653,
      "logps/chosen": -203.00856018066406,
      "logps/rejected": -197.48794555664062,
      "loss": 0.5031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3393508791923523,
      "rewards/margins": 0.432028591632843,
      "rewards/rejected": -0.09267771244049072,
      "step": 182
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.5951260628703814,
      "learning_rate": 1.7703479464640218e-05,
      "logits/chosen": -0.6231208443641663,
      "logits/rejected": -0.8347310423851013,
      "logps/chosen": -234.24185180664062,
      "logps/rejected": -143.54820251464844,
      "loss": 0.5058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4832701086997986,
      "rewards/margins": 0.43700486421585083,
      "rewards/rejected": 0.04626528546214104,
      "step": 183
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 1.4103799996429842,
      "learning_rate": 1.767585392300172e-05,
      "logits/chosen": -0.6719621419906616,
      "logits/rejected": -0.7951651811599731,
      "logps/chosen": -278.6383361816406,
      "logps/rejected": -275.0706787109375,
      "loss": 0.4916,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4917713403701782,
      "rewards/margins": 0.4649195075035095,
      "rewards/rejected": 0.026851840317249298,
      "step": 184
    },
    {
      "epoch": 1.2333333333333334,
      "grad_norm": 1.2207609361310647,
      "learning_rate": 1.764808504481259e-05,
      "logits/chosen": -0.8302322030067444,
      "logits/rejected": -0.6870806217193604,
      "logps/chosen": -157.1146697998047,
      "logps/rejected": -179.44564819335938,
      "loss": 0.536,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2859915494918823,
      "rewards/margins": 0.3608208894729614,
      "rewards/rejected": -0.0748293325304985,
      "step": 185
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.627502934677361,
      "learning_rate": 1.7620173348620368e-05,
      "logits/chosen": -0.890252947807312,
      "logits/rejected": -0.8100996613502502,
      "logps/chosen": -214.278076171875,
      "logps/rejected": -234.63278198242188,
      "loss": 0.5161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32752734422683716,
      "rewards/margins": 0.4057392179965973,
      "rewards/rejected": -0.07821186631917953,
      "step": 186
    },
    {
      "epoch": 1.2466666666666666,
      "grad_norm": 1.9432779726395097,
      "learning_rate": 1.7592119355639545e-05,
      "logits/chosen": -0.7133431434631348,
      "logits/rejected": -0.7609682083129883,
      "logps/chosen": -218.36830139160156,
      "logps/rejected": -237.963134765625,
      "loss": 0.5734,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.20885781943798065,
      "rewards/margins": 0.2755282521247864,
      "rewards/rejected": -0.06667041778564453,
      "step": 187
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 1.712103946859087,
      "learning_rate": 1.7563923589741806e-05,
      "logits/chosen": -0.8060213923454285,
      "logits/rejected": -0.8366204500198364,
      "logps/chosen": -292.5189208984375,
      "logps/rejected": -256.25701904296875,
      "loss": 0.4544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4496366083621979,
      "rewards/margins": 0.5825991630554199,
      "rewards/rejected": -0.13296258449554443,
      "step": 188
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.9468035517971918,
      "learning_rate": 1.7535586577446274e-05,
      "logits/chosen": -0.7794644236564636,
      "logits/rejected": -0.6705242991447449,
      "logps/chosen": -187.58258056640625,
      "logps/rejected": -303.82269287109375,
      "loss": 0.4789,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3094135820865631,
      "rewards/margins": 0.5089620351791382,
      "rewards/rejected": -0.19954842329025269,
      "step": 189
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 1.9068778833138051,
      "learning_rate": 1.7507108847909656e-05,
      "logits/chosen": -0.7921702861785889,
      "logits/rejected": -0.7354428172111511,
      "logps/chosen": -229.96267700195312,
      "logps/rejected": -227.04437255859375,
      "loss": 0.6129,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.17639100551605225,
      "rewards/margins": 0.24282366037368774,
      "rewards/rejected": -0.0664326548576355,
      "step": 190
    },
    {
      "epoch": 1.2733333333333334,
      "grad_norm": 1.4955227312447643,
      "learning_rate": 1.7478490932916374e-05,
      "logits/chosen": -0.9182727932929993,
      "logits/rejected": -0.8594573140144348,
      "logps/chosen": -144.66114807128906,
      "logps/rejected": -189.4753875732422,
      "loss": 0.4886,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2659247815608978,
      "rewards/margins": 0.4818364381790161,
      "rewards/rejected": -0.2159116417169571,
      "step": 191
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5017213481356284,
      "learning_rate": 1.744973336686862e-05,
      "logits/chosen": -0.7918977737426758,
      "logits/rejected": -0.8785242438316345,
      "logps/chosen": -252.97869873046875,
      "logps/rejected": -322.3228759765625,
      "loss": 0.4145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4768044948577881,
      "rewards/margins": 0.7015703916549683,
      "rewards/rejected": -0.22476588189601898,
      "step": 192
    },
    {
      "epoch": 1.2866666666666666,
      "grad_norm": 1.670940672866266,
      "learning_rate": 1.74208366867764e-05,
      "logits/chosen": -0.620567798614502,
      "logits/rejected": -0.6635115742683411,
      "logps/chosen": -311.4356994628906,
      "logps/rejected": -278.7603759765625,
      "loss": 0.4604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31313198804855347,
      "rewards/margins": 0.5591820478439331,
      "rewards/rejected": -0.24605008959770203,
      "step": 193
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 1.392766225558364,
      "learning_rate": 1.7391801432247487e-05,
      "logits/chosen": -0.8194816708564758,
      "logits/rejected": -0.8140673041343689,
      "logps/chosen": -258.8111877441406,
      "logps/rejected": -233.49871826171875,
      "loss": 0.4926,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5103768110275269,
      "rewards/margins": 0.4674360454082489,
      "rewards/rejected": 0.04294077679514885,
      "step": 194
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.867601037617957,
      "learning_rate": 1.7362628145477355e-05,
      "logits/chosen": -0.8327200412750244,
      "logits/rejected": -0.7255422472953796,
      "logps/chosen": -205.50906372070312,
      "logps/rejected": -270.7362060546875,
      "loss": 0.4873,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3893736004829407,
      "rewards/margins": 0.48024579882621765,
      "rewards/rejected": -0.09087224304676056,
      "step": 195
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 1.9987681886991702,
      "learning_rate": 1.7333317371239046e-05,
      "logits/chosen": -0.7580033540725708,
      "logits/rejected": -0.6875736117362976,
      "logps/chosen": -163.66574096679688,
      "logps/rejected": -304.2438659667969,
      "loss": 0.4768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.273124098777771,
      "rewards/margins": 0.5136944055557251,
      "rewards/rejected": -0.24057024717330933,
      "step": 196
    },
    {
      "epoch": 1.3133333333333335,
      "grad_norm": 1.4139795437079046,
      "learning_rate": 1.7303869656872994e-05,
      "logits/chosen": -0.6971063017845154,
      "logits/rejected": -0.901021420955658,
      "logps/chosen": -285.20074462890625,
      "logps/rejected": -235.37545776367188,
      "loss": 0.457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40055564045906067,
      "rewards/margins": 0.5722916722297668,
      "rewards/rejected": -0.1717360019683838,
      "step": 197
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.8102474026702846,
      "learning_rate": 1.727428555227683e-05,
      "logits/chosen": -0.6281791925430298,
      "logits/rejected": -0.779381275177002,
      "logps/chosen": -270.13140869140625,
      "logps/rejected": -217.38670349121094,
      "loss": 0.489,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3497578203678131,
      "rewards/margins": 0.5763704776763916,
      "rewards/rejected": -0.2266126275062561,
      "step": 198
    },
    {
      "epoch": 1.3266666666666667,
      "grad_norm": 1.508929219572262,
      "learning_rate": 1.7244565609895074e-05,
      "logits/chosen": -0.8563704490661621,
      "logits/rejected": -0.9517927169799805,
      "logps/chosen": -350.7771911621094,
      "logps/rejected": -224.78689575195312,
      "loss": 0.4459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6347553730010986,
      "rewards/margins": 0.6244825124740601,
      "rewards/rejected": 0.01027284562587738,
      "step": 199
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.6013347184627575,
      "learning_rate": 1.721471038470885e-05,
      "logits/chosen": -0.8174902200698853,
      "logits/rejected": -0.8942040801048279,
      "logps/chosen": -347.33758544921875,
      "logps/rejected": -293.65869140625,
      "loss": 0.4122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6033804416656494,
      "rewards/margins": 0.8114217519760132,
      "rewards/rejected": -0.20804128050804138,
      "step": 200
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.818460135940975,
      "learning_rate": 1.7184720434225518e-05,
      "logits/chosen": -0.7144252061843872,
      "logits/rejected": -0.9414876103401184,
      "logps/chosen": -478.9552001953125,
      "logps/rejected": -291.63519287109375,
      "loss": 0.3968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7193373441696167,
      "rewards/margins": 0.8325726985931396,
      "rewards/rejected": -0.11323532462120056,
      "step": 201
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 1.4655261268694555,
      "learning_rate": 1.715459631846824e-05,
      "logits/chosen": -0.7993276119232178,
      "logits/rejected": -0.9021291136741638,
      "logps/chosen": -345.84503173828125,
      "logps/rejected": -192.83572387695312,
      "loss": 0.3859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4778147339820862,
      "rewards/margins": 0.9189317226409912,
      "rewards/rejected": -0.44111698865890503,
      "step": 202
    },
    {
      "epoch": 1.3533333333333333,
      "grad_norm": 1.3948275895035585,
      "learning_rate": 1.712433859996555e-05,
      "logits/chosen": -0.8383694291114807,
      "logits/rejected": -0.7656568884849548,
      "logps/chosen": -197.77944946289062,
      "logps/rejected": -238.46786499023438,
      "loss": 0.4162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39339032769203186,
      "rewards/margins": 0.6828770041465759,
      "rewards/rejected": -0.2894866466522217,
      "step": 203
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.6484176851500885,
      "learning_rate": 1.7093947843740843e-05,
      "logits/chosen": -0.8976625800132751,
      "logits/rejected": -0.688299834728241,
      "logps/chosen": -134.8816680908203,
      "logps/rejected": -265.9594421386719,
      "loss": 0.5237,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.18193256855010986,
      "rewards/margins": 0.4356999397277832,
      "rewards/rejected": -0.25376737117767334,
      "step": 204
    },
    {
      "epoch": 1.3666666666666667,
      "grad_norm": 1.8224903225739923,
      "learning_rate": 1.706342461730181e-05,
      "logits/chosen": -0.7731389403343201,
      "logits/rejected": -0.8189367055892944,
      "logps/chosen": -258.19927978515625,
      "logps/rejected": -266.4605712890625,
      "loss": 0.3891,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.30780285596847534,
      "rewards/margins": 0.8866984844207764,
      "rewards/rejected": -0.578895628452301,
      "step": 205
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 1.3475717269265228,
      "learning_rate": 1.703276949062985e-05,
      "logits/chosen": -0.9244558215141296,
      "logits/rejected": -0.9277265667915344,
      "logps/chosen": -276.1062927246094,
      "logps/rejected": -277.93328857421875,
      "loss": 0.383,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.41625410318374634,
      "rewards/margins": 0.8687231540679932,
      "rewards/rejected": -0.4524690806865692,
      "step": 206
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.406689195060782,
      "learning_rate": 1.700198303616944e-05,
      "logits/chosen": -0.7749630212783813,
      "logits/rejected": -0.9133215546607971,
      "logps/chosen": -287.4111633300781,
      "logps/rejected": -186.67611694335938,
      "loss": 0.577,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.15347690880298615,
      "rewards/margins": 0.27216655015945435,
      "rewards/rejected": -0.118689626455307,
      "step": 207
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 2.2836756939171097,
      "learning_rate": 1.6971065828817424e-05,
      "logits/chosen": -0.9284738898277283,
      "logits/rejected": -0.8895972967147827,
      "logps/chosen": -255.878173828125,
      "logps/rejected": -212.2436981201172,
      "loss": 0.5058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3721080422401428,
      "rewards/margins": 0.45627400279045105,
      "rewards/rejected": -0.08416594564914703,
      "step": 208
    },
    {
      "epoch": 1.3933333333333333,
      "grad_norm": 1.8573618015719169,
      "learning_rate": 1.6940018445912275e-05,
      "logits/chosen": -0.8647984266281128,
      "logits/rejected": -0.795199990272522,
      "logps/chosen": -206.90797424316406,
      "logps/rejected": -333.26324462890625,
      "loss": 0.3959,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41635096073150635,
      "rewards/margins": 0.8868894577026367,
      "rewards/rejected": -0.47053855657577515,
      "step": 209
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.635015142761475,
      "learning_rate": 1.690884146722334e-05,
      "logits/chosen": -0.638786256313324,
      "logits/rejected": -0.6696586608886719,
      "logps/chosen": -264.4073486328125,
      "logps/rejected": -207.40452575683594,
      "loss": 0.5062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28210967779159546,
      "rewards/margins": 0.44176313281059265,
      "rewards/rejected": -0.1596534550189972,
      "step": 210
    },
    {
      "epoch": 1.4066666666666667,
      "grad_norm": 2.027583877954526,
      "learning_rate": 1.687753547493999e-05,
      "logits/chosen": -0.7808162569999695,
      "logits/rejected": -0.8380283117294312,
      "logps/chosen": -164.90020751953125,
      "logps/rejected": -216.88265991210938,
      "loss": 0.5335,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.1632283329963684,
      "rewards/margins": 0.4714556038379669,
      "rewards/rejected": -0.3082272708415985,
      "step": 211
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 2.2009350870171485,
      "learning_rate": 1.684610105366076e-05,
      "logits/chosen": -0.8190779685974121,
      "logits/rejected": -0.8265432119369507,
      "logps/chosen": -267.15386962890625,
      "logps/rejected": -234.2521209716797,
      "loss": 0.5707,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.306739866733551,
      "rewards/margins": 0.38349834084510803,
      "rewards/rejected": -0.07675851881504059,
      "step": 212
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.7593409018320618,
      "learning_rate": 1.6814538790382432e-05,
      "logits/chosen": -0.7579501271247864,
      "logits/rejected": -0.9018110632896423,
      "logps/chosen": -321.221923828125,
      "logps/rejected": -220.75616455078125,
      "loss": 0.3928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37802132964134216,
      "rewards/margins": 0.8038508892059326,
      "rewards/rejected": -0.42582958936691284,
      "step": 213
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 1.8633352467772202,
      "learning_rate": 1.6782849274489055e-05,
      "logits/chosen": -0.7263532280921936,
      "logits/rejected": -0.8209120631217957,
      "logps/chosen": -251.70091247558594,
      "logps/rejected": -224.729248046875,
      "loss": 0.4914,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.45320743322372437,
      "rewards/margins": 0.5337786674499512,
      "rewards/rejected": -0.08057118207216263,
      "step": 214
    },
    {
      "epoch": 1.4333333333333333,
      "grad_norm": 2.38066339351173,
      "learning_rate": 1.6751033097740978e-05,
      "logits/chosen": -0.819765031337738,
      "logits/rejected": -0.738406240940094,
      "logps/chosen": -260.1151428222656,
      "logps/rejected": -302.343017578125,
      "loss": 0.4883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4040551781654358,
      "rewards/margins": 0.519302487373352,
      "rewards/rejected": -0.11524736136198044,
      "step": 215
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.5397248367852308,
      "learning_rate": 1.6719090854263752e-05,
      "logits/chosen": -0.7287606596946716,
      "logits/rejected": -0.732322096824646,
      "logps/chosen": -253.39691162109375,
      "logps/rejected": -229.84275817871094,
      "loss": 0.383,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6318936347961426,
      "rewards/margins": 0.8984948396682739,
      "rewards/rejected": -0.26660120487213135,
      "step": 216
    },
    {
      "epoch": 1.4466666666666668,
      "grad_norm": 2.232820730547888,
      "learning_rate": 1.6687023140537082e-05,
      "logits/chosen": -0.7618679404258728,
      "logits/rejected": -0.9132136106491089,
      "logps/chosen": -228.86557006835938,
      "logps/rejected": -161.73548889160156,
      "loss": 0.3599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5286000967025757,
      "rewards/margins": 0.934658408164978,
      "rewards/rejected": -0.4060583710670471,
      "step": 217
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 1.8787893151835249,
      "learning_rate": 1.6654830555383648e-05,
      "logits/chosen": -0.6066255569458008,
      "logits/rejected": -0.628933846950531,
      "logps/chosen": -283.63226318359375,
      "logps/rejected": -269.25537109375,
      "loss": 0.3995,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5841385126113892,
      "rewards/margins": 0.8271452784538269,
      "rewards/rejected": -0.24300673604011536,
      "step": 218
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.4453113452803665,
      "learning_rate": 1.662251369995795e-05,
      "logits/chosen": -0.9770060777664185,
      "logits/rejected": -1.0395396947860718,
      "logps/chosen": -208.4849853515625,
      "logps/rejected": -243.3521728515625,
      "loss": 0.3008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5378032922744751,
      "rewards/margins": 1.0692777633666992,
      "rewards/rejected": -0.5314745903015137,
      "step": 219
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 2.78778508528952,
      "learning_rate": 1.6590073177735066e-05,
      "logits/chosen": -0.6823221445083618,
      "logits/rejected": -0.8352454900741577,
      "logps/chosen": -331.49224853515625,
      "logps/rejected": -272.4534912109375,
      "loss": 0.5517,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.38709962368011475,
      "rewards/margins": 0.42360979318618774,
      "rewards/rejected": -0.036510169506073,
      "step": 220
    },
    {
      "epoch": 1.4733333333333334,
      "grad_norm": 1.6679186489612172,
      "learning_rate": 1.6557509594499405e-05,
      "logits/chosen": -0.7919696569442749,
      "logits/rejected": -0.8640267252922058,
      "logps/chosen": -161.11849975585938,
      "logps/rejected": -193.7095184326172,
      "loss": 0.476,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.29973435401916504,
      "rewards/margins": 0.6783468723297119,
      "rewards/rejected": -0.3786125183105469,
      "step": 221
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.006957113129942,
      "learning_rate": 1.6524823558333362e-05,
      "logits/chosen": -0.7993523478507996,
      "logits/rejected": -0.8051933646202087,
      "logps/chosen": -258.0792236328125,
      "logps/rejected": -403.2257995605469,
      "loss": 0.3578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5207136273384094,
      "rewards/margins": 0.8973872661590576,
      "rewards/rejected": -0.3766736388206482,
      "step": 222
    },
    {
      "epoch": 1.4866666666666668,
      "grad_norm": 1.6186446107705552,
      "learning_rate": 1.6492015679605994e-05,
      "logits/chosen": -0.9944407939910889,
      "logits/rejected": -1.0347379446029663,
      "logps/chosen": -360.4809875488281,
      "logps/rejected": -219.892333984375,
      "loss": 0.3539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5245392918586731,
      "rewards/margins": 0.9683557152748108,
      "rewards/rejected": -0.4438163936138153,
      "step": 223
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 1.7613507412972602,
      "learning_rate": 1.6459086570961594e-05,
      "logits/chosen": -0.8614411950111389,
      "logits/rejected": -0.9315679669380188,
      "logps/chosen": -189.77957153320312,
      "logps/rejected": -186.96884155273438,
      "loss": 0.4066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3843209147453308,
      "rewards/margins": 0.7651441097259521,
      "rewards/rejected": -0.3808232247829437,
      "step": 224
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.9579840680059646,
      "learning_rate": 1.6426036847308287e-05,
      "logits/chosen": -0.9741081595420837,
      "logits/rejected": -0.9412724375724792,
      "logps/chosen": -237.7136993408203,
      "logps/rejected": -245.9569549560547,
      "loss": 0.474,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5406414866447449,
      "rewards/margins": 0.5795080661773682,
      "rewards/rejected": -0.038866594433784485,
      "step": 225
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 2.8302568862301567,
      "learning_rate": 1.6392867125806504e-05,
      "logits/chosen": -0.804617166519165,
      "logits/rejected": -0.7774171829223633,
      "logps/chosen": -344.39654541015625,
      "logps/rejected": -387.7764892578125,
      "loss": 0.4527,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.452853798866272,
      "rewards/margins": 0.6783065795898438,
      "rewards/rejected": -0.22545276582241058,
      "step": 226
    },
    {
      "epoch": 1.5133333333333332,
      "grad_norm": 2.024901813905314,
      "learning_rate": 1.6359578025857495e-05,
      "logits/chosen": -0.7355515956878662,
      "logits/rejected": -0.9942168593406677,
      "logps/chosen": -231.99807739257812,
      "logps/rejected": -156.62490844726562,
      "loss": 0.4964,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.26349109411239624,
      "rewards/margins": 0.5077023506164551,
      "rewards/rejected": -0.24421125650405884,
      "step": 227
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.089501126448124,
      "learning_rate": 1.6326170169091735e-05,
      "logits/chosen": -0.8086773157119751,
      "logits/rejected": -0.8715277910232544,
      "logps/chosen": -197.58810424804688,
      "logps/rejected": -135.59849548339844,
      "loss": 0.5395,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2472836673259735,
      "rewards/margins": 0.4010307490825653,
      "rewards/rejected": -0.1537470817565918,
      "step": 228
    },
    {
      "epoch": 1.5266666666666666,
      "grad_norm": 1.459790029058912,
      "learning_rate": 1.6292644179357337e-05,
      "logits/chosen": -0.8536837100982666,
      "logits/rejected": -0.9538642168045044,
      "logps/chosen": -224.45225524902344,
      "logps/rejected": -234.68350219726562,
      "loss": 0.367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36707472801208496,
      "rewards/margins": 0.9026826620101929,
      "rewards/rejected": -0.5356079339981079,
      "step": 229
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.304621574883471,
      "learning_rate": 1.6259000682708384e-05,
      "logits/chosen": -0.8643391132354736,
      "logits/rejected": -0.8738679885864258,
      "logps/chosen": -174.6906280517578,
      "logps/rejected": -221.08773803710938,
      "loss": 0.3036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5077379941940308,
      "rewards/margins": 1.2159528732299805,
      "rewards/rejected": -0.7082148790359497,
      "step": 230
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.3609890501098834,
      "learning_rate": 1.622524030739326e-05,
      "logits/chosen": -0.7394368052482605,
      "logits/rejected": -0.7655255198478699,
      "logps/chosen": -302.83154296875,
      "logps/rejected": -232.23529052734375,
      "loss": 0.5139,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3592297434806824,
      "rewards/margins": 0.5339628458023071,
      "rewards/rejected": -0.17473314702510834,
      "step": 231
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 1.603822927266332,
      "learning_rate": 1.6191363683842883e-05,
      "logits/chosen": -1.0324405431747437,
      "logits/rejected": -1.1246354579925537,
      "logps/chosen": -268.73114013671875,
      "logps/rejected": -150.78390502929688,
      "loss": 0.4005,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.41750389337539673,
      "rewards/margins": 0.7645971775054932,
      "rewards/rejected": -0.3470933139324188,
      "step": 232
    },
    {
      "epoch": 1.5533333333333332,
      "grad_norm": 1.671311399349134,
      "learning_rate": 1.615737144465898e-05,
      "logits/chosen": -0.8924543857574463,
      "logits/rejected": -0.9031264781951904,
      "logps/chosen": -205.92181396484375,
      "logps/rejected": -212.40817260742188,
      "loss": 0.3699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23677468299865723,
      "rewards/margins": 0.8371267318725586,
      "rewards/rejected": -0.6003520488739014,
      "step": 233
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.1237604228320213,
      "learning_rate": 1.6123264224602245e-05,
      "logits/chosen": -0.9020024538040161,
      "logits/rejected": -0.9574487805366516,
      "logps/chosen": -207.49252319335938,
      "logps/rejected": -243.2890625,
      "loss": 0.462,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.18470440804958344,
      "rewards/margins": 0.6863976716995239,
      "rewards/rejected": -0.5016931891441345,
      "step": 234
    },
    {
      "epoch": 1.5666666666666667,
      "grad_norm": 1.7333110260750675,
      "learning_rate": 1.608904266058047e-05,
      "logits/chosen": -0.7506160736083984,
      "logits/rejected": -0.9124056100845337,
      "logps/chosen": -388.35711669921875,
      "logps/rejected": -278.48321533203125,
      "loss": 0.4042,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7214086651802063,
      "rewards/margins": 0.9103132486343384,
      "rewards/rejected": -0.18890461325645447,
      "step": 235
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 1.6977451994581887,
      "learning_rate": 1.605470739163669e-05,
      "logits/chosen": -0.6741140484809875,
      "logits/rejected": -0.7018690705299377,
      "logps/chosen": -211.989013671875,
      "logps/rejected": -256.323974609375,
      "loss": 0.3523,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.46038350462913513,
      "rewards/margins": 0.9709472060203552,
      "rewards/rejected": -0.5105637311935425,
      "step": 236
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.370704660879532,
      "learning_rate": 1.6020259058937228e-05,
      "logits/chosen": -1.0162832736968994,
      "logits/rejected": -0.9982099533081055,
      "logps/chosen": -159.6552734375,
      "logps/rejected": -234.82232666015625,
      "loss": 0.2799,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4504088759422302,
      "rewards/margins": 1.3154709339141846,
      "rewards/rejected": -0.8650619983673096,
      "step": 237
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 2.2410388090900293,
      "learning_rate": 1.5985698305759713e-05,
      "logits/chosen": -0.7668032646179199,
      "logits/rejected": -0.8350152373313904,
      "logps/chosen": -333.79351806640625,
      "logps/rejected": -288.26092529296875,
      "loss": 0.3834,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.33814945816993713,
      "rewards/margins": 0.978868842124939,
      "rewards/rejected": -0.6407193541526794,
      "step": 238
    },
    {
      "epoch": 1.5933333333333333,
      "grad_norm": 1.5479372789012582,
      "learning_rate": 1.59510257774811e-05,
      "logits/chosen": -0.6882136464118958,
      "logits/rejected": -0.8452655076980591,
      "logps/chosen": -429.8079528808594,
      "logps/rejected": -305.2591552734375,
      "loss": 0.2784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9014792442321777,
      "rewards/margins": 1.2602059841156006,
      "rewards/rejected": -0.35872673988342285,
      "step": 239
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4003554676276742,
      "learning_rate": 1.591624212156558e-05,
      "logits/chosen": -1.0680361986160278,
      "logits/rejected": -0.9544186592102051,
      "logps/chosen": -315.12255859375,
      "logps/rejected": -234.13150024414062,
      "loss": 0.2408,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8440573811531067,
      "rewards/margins": 1.3523247241973877,
      "rewards/rejected": -0.5082674026489258,
      "step": 240
    },
    {
      "epoch": 1.6066666666666667,
      "grad_norm": 2.1407587608257037,
      "learning_rate": 1.5881347987552517e-05,
      "logits/chosen": -0.33027851581573486,
      "logits/rejected": -0.7810418009757996,
      "logps/chosen": -611.781494140625,
      "logps/rejected": -395.7563781738281,
      "loss": 0.3766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0253846645355225,
      "rewards/margins": 0.8887811899185181,
      "rewards/rejected": 0.1366034597158432,
      "step": 241
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 1.8112842823519895,
      "learning_rate": 1.5846344027044307e-05,
      "logits/chosen": -0.6997851133346558,
      "logits/rejected": -0.8375272154808044,
      "logps/chosen": -269.71044921875,
      "logps/rejected": -253.4558563232422,
      "loss": 0.3075,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4117818772792816,
      "rewards/margins": 1.1351631879806519,
      "rewards/rejected": -0.7233812808990479,
      "step": 242
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.5554241179764563,
      "learning_rate": 1.5811230893694214e-05,
      "logits/chosen": -0.8768133521080017,
      "logits/rejected": -0.8709684610366821,
      "logps/chosen": -241.61790466308594,
      "logps/rejected": -206.02395629882812,
      "loss": 0.3225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35726064443588257,
      "rewards/margins": 1.0953140258789062,
      "rewards/rejected": -0.7380533814430237,
      "step": 243
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 1.8184306359182014,
      "learning_rate": 1.5776009243194158e-05,
      "logits/chosen": -0.7613734006881714,
      "logits/rejected": -0.9002806544303894,
      "logps/chosen": -174.61538696289062,
      "logps/rejected": -207.99459838867188,
      "loss": 0.4038,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3440173268318176,
      "rewards/margins": 0.846009373664856,
      "rewards/rejected": -0.5019919872283936,
      "step": 244
    },
    {
      "epoch": 1.6333333333333333,
      "grad_norm": 1.4997850899919325,
      "learning_rate": 1.574067973326248e-05,
      "logits/chosen": -0.9702059030532837,
      "logits/rejected": -0.7234102487564087,
      "logps/chosen": -135.57655334472656,
      "logps/rejected": -201.81637573242188,
      "loss": 0.3655,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.47989192605018616,
      "rewards/margins": 0.983625590801239,
      "rewards/rejected": -0.5037336945533752,
      "step": 245
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.6927758149609762,
      "learning_rate": 1.570524302363165e-05,
      "logits/chosen": -0.9472751021385193,
      "logits/rejected": -1.0157173871994019,
      "logps/chosen": -251.29969787597656,
      "logps/rejected": -271.095947265625,
      "loss": 0.3204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37743163108825684,
      "rewards/margins": 1.0537277460098267,
      "rewards/rejected": -0.6762961149215698,
      "step": 246
    },
    {
      "epoch": 1.6466666666666665,
      "grad_norm": 1.4121501489348067,
      "learning_rate": 1.5669699776035958e-05,
      "logits/chosen": -0.8795787692070007,
      "logits/rejected": -0.6952474117279053,
      "logps/chosen": -204.1941680908203,
      "logps/rejected": -239.61033630371094,
      "loss": 0.3115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39634159207344055,
      "rewards/margins": 1.234084129333496,
      "rewards/rejected": -0.8377425670623779,
      "step": 247
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 1.8380741753372598,
      "learning_rate": 1.5634050654199147e-05,
      "logits/chosen": -0.9177889227867126,
      "logits/rejected": -0.6756101846694946,
      "logps/chosen": -183.18115234375,
      "logps/rejected": -348.1979675292969,
      "loss": 0.4122,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4065427780151367,
      "rewards/margins": 1.1315727233886719,
      "rewards/rejected": -0.7250298261642456,
      "step": 248
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 1.858408444287956,
      "learning_rate": 1.5598296323822026e-05,
      "logits/chosen": -0.9322398900985718,
      "logits/rejected": -0.9875479936599731,
      "logps/chosen": -244.38748168945312,
      "logps/rejected": -162.09521484375,
      "loss": 0.363,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4977497160434723,
      "rewards/margins": 1.137398600578308,
      "rewards/rejected": -0.639648973941803,
      "step": 249
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.8453229886111409,
      "learning_rate": 1.556243745257003e-05,
      "logits/chosen": -0.7233873009681702,
      "logits/rejected": -0.9474321007728577,
      "logps/chosen": -366.7100830078125,
      "logps/rejected": -175.3851776123047,
      "loss": 0.364,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5586103796958923,
      "rewards/margins": 0.956148624420166,
      "rewards/rejected": -0.39753827452659607,
      "step": 250
    },
    {
      "epoch": 1.6733333333333333,
      "grad_norm": 1.5256005214804291,
      "learning_rate": 1.5526474710060767e-05,
      "logits/chosen": -0.8405922055244446,
      "logits/rejected": -0.7759765386581421,
      "logps/chosen": -193.96359252929688,
      "logps/rejected": -220.12896728515625,
      "loss": 0.3246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.557327389717102,
      "rewards/margins": 1.1657625436782837,
      "rewards/rejected": -0.6084352135658264,
      "step": 251
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.5607879414282744,
      "learning_rate": 1.5490408767851506e-05,
      "logits/chosen": -0.8017247915267944,
      "logits/rejected": -0.8295936584472656,
      "logps/chosen": -246.41595458984375,
      "logps/rejected": -186.87840270996094,
      "loss": 0.3035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5984470844268799,
      "rewards/margins": 1.2143371105194092,
      "rewards/rejected": -0.6158900260925293,
      "step": 252
    },
    {
      "epoch": 1.6866666666666665,
      "grad_norm": 1.454136814076982,
      "learning_rate": 1.5454240299426626e-05,
      "logits/chosen": -0.978694498538971,
      "logits/rejected": -0.7828431725502014,
      "logps/chosen": -139.80523681640625,
      "logps/rejected": -233.45957946777344,
      "loss": 0.244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.372032105922699,
      "rewards/margins": 1.4659719467163086,
      "rewards/rejected": -1.0939397811889648,
      "step": 253
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 1.4264625071382844,
      "learning_rate": 1.5417969980185055e-05,
      "logits/chosen": -0.8138079047203064,
      "logits/rejected": -0.8267276287078857,
      "logps/chosen": -302.3232421875,
      "logps/rejected": -298.519287109375,
      "loss": 0.2399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9357280731201172,
      "rewards/margins": 1.4260859489440918,
      "rewards/rejected": -0.4903579354286194,
      "step": 254
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.4329640515297948,
      "learning_rate": 1.538159848742765e-05,
      "logits/chosen": -0.6640478372573853,
      "logits/rejected": -0.8342497944831848,
      "logps/chosen": -277.595703125,
      "logps/rejected": -237.17628479003906,
      "loss": 0.2994,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40300148725509644,
      "rewards/margins": 1.2388828992843628,
      "rewards/rejected": -0.8358814120292664,
      "step": 255
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 2.4478998602973325,
      "learning_rate": 1.5345126500344555e-05,
      "logits/chosen": -1.007594108581543,
      "logits/rejected": -1.15011727809906,
      "logps/chosen": -261.5295104980469,
      "logps/rejected": -200.46356201171875,
      "loss": 0.4294,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.36997276544570923,
      "rewards/margins": 1.1851606369018555,
      "rewards/rejected": -0.8151878118515015,
      "step": 256
    },
    {
      "epoch": 1.7133333333333334,
      "grad_norm": 2.6824572070744472,
      "learning_rate": 1.530855470000251e-05,
      "logits/chosen": -0.9673040509223938,
      "logits/rejected": -0.8145002722740173,
      "logps/chosen": -219.36715698242188,
      "logps/rejected": -463.70526123046875,
      "loss": 0.2696,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.45018649101257324,
      "rewards/margins": 1.6195571422576904,
      "rewards/rejected": -1.1693705320358276,
      "step": 257
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.0450937222593755,
      "learning_rate": 1.5271883769332144e-05,
      "logits/chosen": -0.6526773571968079,
      "logits/rejected": -0.8981446027755737,
      "logps/chosen": -264.1617126464844,
      "logps/rejected": -232.07525634765625,
      "loss": 0.3691,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.22269919514656067,
      "rewards/margins": 1.0297220945358276,
      "rewards/rejected": -0.8070230484008789,
      "step": 258
    },
    {
      "epoch": 1.7266666666666666,
      "grad_norm": 3.2718544275316552,
      "learning_rate": 1.5235114393115202e-05,
      "logits/chosen": -0.9403198957443237,
      "logits/rejected": -1.0727005004882812,
      "logps/chosen": -293.3144226074219,
      "logps/rejected": -268.4676208496094,
      "loss": 0.5136,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.13040773570537567,
      "rewards/margins": 1.1809988021850586,
      "rewards/rejected": -1.050590991973877,
      "step": 259
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 1.4941949572688829,
      "learning_rate": 1.5198247257971788e-05,
      "logits/chosen": -0.9325324892997742,
      "logits/rejected": -0.783992350101471,
      "logps/chosen": -160.04803466796875,
      "logps/rejected": -225.78912353515625,
      "loss": 0.2643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6309290528297424,
      "rewards/margins": 1.4204078912734985,
      "rewards/rejected": -0.7894787788391113,
      "step": 260
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.3921140349556482,
      "learning_rate": 1.5161283052347516e-05,
      "logits/chosen": -0.882022500038147,
      "logits/rejected": -0.98207026720047,
      "logps/chosen": -223.99017333984375,
      "logps/rejected": -170.260986328125,
      "loss": 0.3152,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6685442328453064,
      "rewards/margins": 1.2529633045196533,
      "rewards/rejected": -0.5844191312789917,
      "step": 261
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 4.66851379532383,
      "learning_rate": 1.5124222466500665e-05,
      "logits/chosen": -0.7726691365242004,
      "logits/rejected": -0.6756588816642761,
      "logps/chosen": -248.71205139160156,
      "logps/rejected": -334.5860290527344,
      "loss": 0.5455,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.17211554944515228,
      "rewards/margins": 0.8605080842971802,
      "rewards/rejected": -0.6883925795555115,
      "step": 262
    },
    {
      "epoch": 1.7533333333333334,
      "grad_norm": 1.1715091388523398,
      "learning_rate": 1.5087066192489288e-05,
      "logits/chosen": -0.8524599075317383,
      "logits/rejected": -0.925661027431488,
      "logps/chosen": -248.5928955078125,
      "logps/rejected": -250.2828826904297,
      "loss": 0.1691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8215921521186829,
      "rewards/margins": 1.8744277954101562,
      "rewards/rejected": -1.0528355836868286,
      "step": 263
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.5822839605743557,
      "learning_rate": 1.5049814924158298e-05,
      "logits/chosen": -0.885331928730011,
      "logits/rejected": -0.8387802839279175,
      "logps/chosen": -309.43109130859375,
      "logps/rejected": -357.81085205078125,
      "loss": 0.1902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7509140372276306,
      "rewards/margins": 2.1306052207946777,
      "rewards/rejected": -1.3796911239624023,
      "step": 264
    },
    {
      "epoch": 1.7666666666666666,
      "grad_norm": 2.158420299805576,
      "learning_rate": 1.5012469357126496e-05,
      "logits/chosen": -0.8340965509414673,
      "logits/rejected": -0.9321473240852356,
      "logps/chosen": -290.41082763671875,
      "logps/rejected": -249.9208221435547,
      "loss": 0.3003,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.37155333161354065,
      "rewards/margins": 1.4309523105621338,
      "rewards/rejected": -1.0593990087509155,
      "step": 265
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 1.4961305618737315,
      "learning_rate": 1.4975030188773585e-05,
      "logits/chosen": -0.9181448817253113,
      "logits/rejected": -0.8187313675880432,
      "logps/chosen": -287.0393981933594,
      "logps/rejected": -361.0282287597656,
      "loss": 0.2273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49584174156188965,
      "rewards/margins": 1.7271310091018677,
      "rewards/rejected": -1.231289267539978,
      "step": 266
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2062310093783197,
      "learning_rate": 1.4937498118227156e-05,
      "logits/chosen": -0.8366146683692932,
      "logits/rejected": -0.7998788356781006,
      "logps/chosen": -183.083984375,
      "logps/rejected": -224.2565460205078,
      "loss": 0.1473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7956281900405884,
      "rewards/margins": 2.013604164123535,
      "rewards/rejected": -1.2179759740829468,
      "step": 267
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 1.9183336209988262,
      "learning_rate": 1.4899873846349626e-05,
      "logits/chosen": -0.8907594680786133,
      "logits/rejected": -0.9758501648902893,
      "logps/chosen": -331.4830627441406,
      "logps/rejected": -218.19424438476562,
      "loss": 0.3222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6289503574371338,
      "rewards/margins": 1.0674962997436523,
      "rewards/rejected": -0.43854594230651855,
      "step": 268
    },
    {
      "epoch": 1.7933333333333334,
      "grad_norm": 2.097953107631648,
      "learning_rate": 1.486215807572515e-05,
      "logits/chosen": -0.7323464751243591,
      "logits/rejected": -0.8216506838798523,
      "logps/chosen": -317.9136657714844,
      "logps/rejected": -359.25872802734375,
      "loss": 0.3207,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7484101057052612,
      "rewards/margins": 1.2328519821166992,
      "rewards/rejected": -0.4844418466091156,
      "step": 269
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.3324911664037056,
      "learning_rate": 1.4824351510646508e-05,
      "logits/chosen": -0.5076476335525513,
      "logits/rejected": -0.7327809929847717,
      "logps/chosen": -293.4898376464844,
      "logps/rejected": -215.40606689453125,
      "loss": 0.3525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5690383911132812,
      "rewards/margins": 1.0343999862670898,
      "rewards/rejected": -0.4653615653514862,
      "step": 270
    },
    {
      "epoch": 1.8066666666666666,
      "grad_norm": 2.6900797150723252,
      "learning_rate": 1.478645485710194e-05,
      "logits/chosen": -0.9134845733642578,
      "logits/rejected": -0.7285479307174683,
      "logps/chosen": -343.3610534667969,
      "logps/rejected": -398.0596923828125,
      "loss": 0.4137,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.34307241439819336,
      "rewards/margins": 0.9300752878189087,
      "rewards/rejected": -0.5870029330253601,
      "step": 271
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 1.8625408116932038,
      "learning_rate": 1.4748468822761974e-05,
      "logits/chosen": -0.7873282432556152,
      "logits/rejected": -1.0610164403915405,
      "logps/chosen": -424.3177185058594,
      "logps/rejected": -176.48199462890625,
      "loss": 0.2575,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8731250762939453,
      "rewards/margins": 1.4147746562957764,
      "rewards/rejected": -0.5416496396064758,
      "step": 272
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.244550038467199,
      "learning_rate": 1.4710394116966206e-05,
      "logits/chosen": -0.7464823722839355,
      "logits/rejected": -0.9835959672927856,
      "logps/chosen": -283.0467224121094,
      "logps/rejected": -204.25006103515625,
      "loss": 0.3754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16023999452590942,
      "rewards/margins": 0.9048906564712524,
      "rewards/rejected": -0.7446507215499878,
      "step": 273
    },
    {
      "epoch": 1.8266666666666667,
      "grad_norm": 1.6258234725228173,
      "learning_rate": 1.4672231450710066e-05,
      "logits/chosen": -0.5822653770446777,
      "logits/rejected": -0.754677414894104,
      "logps/chosen": -355.29803466796875,
      "logps/rejected": -231.1827392578125,
      "loss": 0.2736,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6864690780639648,
      "rewards/margins": 1.2544701099395752,
      "rewards/rejected": -0.5680010318756104,
      "step": 274
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 2.4265382233711468,
      "learning_rate": 1.4633981536631514e-05,
      "logits/chosen": -0.9750176072120667,
      "logits/rejected": -0.9829651713371277,
      "logps/chosen": -335.02337646484375,
      "logps/rejected": -301.6689453125,
      "loss": 0.3185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6570816040039062,
      "rewards/margins": 1.2664635181427002,
      "rewards/rejected": -0.6093819737434387,
      "step": 275
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.857755516724756,
      "learning_rate": 1.4595645088997758e-05,
      "logits/chosen": -0.6067758798599243,
      "logits/rejected": -0.7320312261581421,
      "logps/chosen": -356.1424560546875,
      "logps/rejected": -298.0546569824219,
      "loss": 0.3103,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.9247682690620422,
      "rewards/margins": 1.3628811836242676,
      "rewards/rejected": -0.43811285495758057,
      "step": 276
    },
    {
      "epoch": 1.8466666666666667,
      "grad_norm": 1.6539772562633532,
      "learning_rate": 1.4557222823691913e-05,
      "logits/chosen": -0.8451669216156006,
      "logits/rejected": -0.853065013885498,
      "logps/chosen": -152.73104858398438,
      "logps/rejected": -254.81256103515625,
      "loss": 0.2315,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5875165462493896,
      "rewards/margins": 1.6904585361480713,
      "rewards/rejected": -1.1029419898986816,
      "step": 277
    },
    {
      "epoch": 1.8533333333333335,
      "grad_norm": 1.232977740257784,
      "learning_rate": 1.451871545819961e-05,
      "logits/chosen": -0.7084604501724243,
      "logits/rejected": -0.8638991117477417,
      "logps/chosen": -209.56707763671875,
      "logps/rejected": -197.75885009765625,
      "loss": 0.1569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8978688716888428,
      "rewards/margins": 1.9033178091049194,
      "rewards/rejected": -1.005448818206787,
      "step": 278
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 1.4956261125585146,
      "learning_rate": 1.4480123711595637e-05,
      "logits/chosen": -0.7736629843711853,
      "logits/rejected": -0.758381724357605,
      "logps/chosen": -286.74078369140625,
      "logps/rejected": -271.5732727050781,
      "loss": 0.245,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.582718014717102,
      "rewards/margins": 1.660423994064331,
      "rewards/rejected": -1.077705979347229,
      "step": 279
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.5461080942746268,
      "learning_rate": 1.4441448304530467e-05,
      "logits/chosen": -0.6860623359680176,
      "logits/rejected": -0.8906334042549133,
      "logps/chosen": -339.54443359375,
      "logps/rejected": -333.4295654296875,
      "loss": 0.2346,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5101935267448425,
      "rewards/margins": 1.802942156791687,
      "rewards/rejected": -1.2927485704421997,
      "step": 280
    },
    {
      "epoch": 1.8733333333333333,
      "grad_norm": 2.0616087866480806,
      "learning_rate": 1.4402689959216845e-05,
      "logits/chosen": -0.7103676199913025,
      "logits/rejected": -0.7109839916229248,
      "logps/chosen": -318.2856140136719,
      "logps/rejected": -335.2659912109375,
      "loss": 0.2959,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.36959290504455566,
      "rewards/margins": 1.4353020191192627,
      "rewards/rejected": -1.0657089948654175,
      "step": 281
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.7156120786197648,
      "learning_rate": 1.4363849399416254e-05,
      "logits/chosen": -0.7990913391113281,
      "logits/rejected": -0.8875870704650879,
      "logps/chosen": -342.6923828125,
      "logps/rejected": -248.20826721191406,
      "loss": 0.2476,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8934634923934937,
      "rewards/margins": 1.5317435264587402,
      "rewards/rejected": -0.6382800340652466,
      "step": 282
    },
    {
      "epoch": 1.8866666666666667,
      "grad_norm": 1.4255023840352772,
      "learning_rate": 1.4324927350425451e-05,
      "logits/chosen": -0.7383981943130493,
      "logits/rejected": -0.8150214552879333,
      "logps/chosen": -333.6275939941406,
      "logps/rejected": -294.39715576171875,
      "loss": 0.2058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9588331580162048,
      "rewards/margins": 2.0010311603546143,
      "rewards/rejected": -1.0421979427337646,
      "step": 283
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 1.620239768239779,
      "learning_rate": 1.4285924539062878e-05,
      "logits/chosen": -0.9663683176040649,
      "logits/rejected": -0.9409217834472656,
      "logps/chosen": -420.41552734375,
      "logps/rejected": -396.2726135253906,
      "loss": 0.2082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9195561408996582,
      "rewards/margins": 1.8782954216003418,
      "rewards/rejected": -0.9587392210960388,
      "step": 284
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.4761141141647887,
      "learning_rate": 1.424684169365512e-05,
      "logits/chosen": -0.8470095992088318,
      "logits/rejected": -0.975596010684967,
      "logps/chosen": -292.8736267089844,
      "logps/rejected": -260.09674072265625,
      "loss": 0.2045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5430917739868164,
      "rewards/margins": 1.6840029954910278,
      "rewards/rejected": -1.1409112215042114,
      "step": 285
    },
    {
      "epoch": 1.9066666666666667,
      "grad_norm": 1.4830041277179133,
      "learning_rate": 1.4207679544023289e-05,
      "logits/chosen": -0.8092164993286133,
      "logits/rejected": -0.8450993299484253,
      "logps/chosen": -242.9757537841797,
      "logps/rejected": -319.699951171875,
      "loss": 0.2038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4977938234806061,
      "rewards/margins": 1.9933100938796997,
      "rewards/rejected": -1.495516300201416,
      "step": 286
    },
    {
      "epoch": 1.9133333333333333,
      "grad_norm": 1.2935555040050788,
      "learning_rate": 1.4168438821469402e-05,
      "logits/chosen": -0.8339681029319763,
      "logits/rejected": -0.9184002876281738,
      "logps/chosen": -193.39039611816406,
      "logps/rejected": -228.6640167236328,
      "loss": 0.1665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8566218614578247,
      "rewards/margins": 2.0432496070861816,
      "rewards/rejected": -1.1866276264190674,
      "step": 287
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.320872537862779,
      "learning_rate": 1.4129120258762719e-05,
      "logits/chosen": -0.9952560067176819,
      "logits/rejected": -0.8355525732040405,
      "logps/chosen": -150.06466674804688,
      "logps/rejected": -438.06488037109375,
      "loss": 0.3774,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.19608736038208008,
      "rewards/margins": 1.6749727725982666,
      "rewards/rejected": -1.4788856506347656,
      "step": 288
    },
    {
      "epoch": 1.9266666666666667,
      "grad_norm": 2.2830855418423615,
      "learning_rate": 1.4089724590126061e-05,
      "logits/chosen": -0.9675279855728149,
      "logits/rejected": -0.9969059228897095,
      "logps/chosen": -179.27227783203125,
      "logps/rejected": -188.57537841796875,
      "loss": 0.302,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5216190814971924,
      "rewards/margins": 1.4018073081970215,
      "rewards/rejected": -0.8801882266998291,
      "step": 289
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 1.7300257406359418,
      "learning_rate": 1.4050252551222115e-05,
      "logits/chosen": -0.8218981027603149,
      "logits/rejected": -0.8280680179595947,
      "logps/chosen": -202.20315551757812,
      "logps/rejected": -258.0555419921875,
      "loss": 0.2172,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5189920663833618,
      "rewards/margins": 1.8811211585998535,
      "rewards/rejected": -1.3621289730072021,
      "step": 290
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.2163767571570363,
      "learning_rate": 1.4010704879139669e-05,
      "logits/chosen": -0.8842124342918396,
      "logits/rejected": -1.0921432971954346,
      "logps/chosen": -322.60601806640625,
      "logps/rejected": -260.0932922363281,
      "loss": 0.1865,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7752830982208252,
      "rewards/margins": 2.14343523979187,
      "rewards/rejected": -1.368152141571045,
      "step": 291
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 1.3501728830194812,
      "learning_rate": 1.3971082312379864e-05,
      "logits/chosen": -0.8641313910484314,
      "logits/rejected": -0.5174150466918945,
      "logps/chosen": -197.65634155273438,
      "logps/rejected": -322.480224609375,
      "loss": 0.1744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3772880434989929,
      "rewards/margins": 2.4713165760040283,
      "rewards/rejected": -2.0940284729003906,
      "step": 292
    },
    {
      "epoch": 1.9533333333333334,
      "grad_norm": 2.4720044474700624,
      "learning_rate": 1.3931385590842412e-05,
      "logits/chosen": -0.7830979824066162,
      "logits/rejected": -0.8622887134552002,
      "logps/chosen": -373.04833984375,
      "logps/rejected": -369.0801086425781,
      "loss": 0.2987,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.7140645980834961,
      "rewards/margins": 1.8168699741363525,
      "rewards/rejected": -1.102805256843567,
      "step": 293
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.3073642249571054,
      "learning_rate": 1.3891615455811751e-05,
      "logits/chosen": -0.8792242407798767,
      "logits/rejected": -0.9957505464553833,
      "logps/chosen": -202.95135498046875,
      "logps/rejected": -155.69439697265625,
      "loss": 0.2976,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.659839391708374,
      "rewards/margins": 1.439584732055664,
      "rewards/rejected": -0.7797452211380005,
      "step": 294
    },
    {
      "epoch": 1.9666666666666668,
      "grad_norm": 1.15726544922467,
      "learning_rate": 1.3851772649943238e-05,
      "logits/chosen": -0.8726381063461304,
      "logits/rejected": -0.8449326753616333,
      "logps/chosen": -224.97434997558594,
      "logps/rejected": -372.7260437011719,
      "loss": 0.0986,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7259159684181213,
      "rewards/margins": 2.7729644775390625,
      "rewards/rejected": -2.047048330307007,
      "step": 295
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 1.1575481756578476,
      "learning_rate": 1.3811857917249254e-05,
      "logits/chosen": -0.9990265965461731,
      "logits/rejected": -0.7466692328453064,
      "logps/chosen": -143.2536163330078,
      "logps/rejected": -304.2793884277344,
      "loss": 0.1032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5464481115341187,
      "rewards/margins": 2.559908390045166,
      "rewards/rejected": -2.013460159301758,
      "step": 296
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.9324775950831372,
      "learning_rate": 1.3771872003085315e-05,
      "logits/chosen": -0.9603700637817383,
      "logits/rejected": -0.9386076927185059,
      "logps/chosen": -303.86236572265625,
      "logps/rejected": -324.75335693359375,
      "loss": 0.0955,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8452094197273254,
      "rewards/margins": 2.8942556381225586,
      "rewards/rejected": -2.049046277999878,
      "step": 297
    },
    {
      "epoch": 1.9866666666666668,
      "grad_norm": 1.1694670797821864,
      "learning_rate": 1.373181565413617e-05,
      "logits/chosen": -0.872261643409729,
      "logits/rejected": -0.7853923439979553,
      "logps/chosen": -221.66294860839844,
      "logps/rejected": -351.52252197265625,
      "loss": 0.0831,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7225265502929688,
      "rewards/margins": 2.9258346557617188,
      "rewards/rejected": -2.20330810546875,
      "step": 298
    },
    {
      "epoch": 1.9933333333333332,
      "grad_norm": 1.3645187488831996,
      "learning_rate": 1.3691689618401836e-05,
      "logits/chosen": -0.7253598570823669,
      "logits/rejected": -0.801845133304596,
      "logps/chosen": -294.4317321777344,
      "logps/rejected": -261.6510009765625,
      "loss": 0.1433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9942775964736938,
      "rewards/margins": 2.3380613327026367,
      "rewards/rejected": -1.3437836170196533,
      "step": 299
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.3362281438540626,
      "learning_rate": 1.365149464518364e-05,
      "logits/chosen": -0.738997757434845,
      "logits/rejected": -0.8104124665260315,
      "logps/chosen": -239.12020874023438,
      "logps/rejected": -299.1810302734375,
      "loss": 0.1416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7775257229804993,
      "rewards/margins": 2.4256818294525146,
      "rewards/rejected": -1.6481561660766602,
      "step": 300
    },
    {
      "epoch": 2.006666666666667,
      "grad_norm": 1.6638132544458093,
      "learning_rate": 1.3611231485070233e-05,
      "logits/chosen": -0.8782002925872803,
      "logits/rejected": -0.901211142539978,
      "logps/chosen": -222.883544921875,
      "logps/rejected": -180.29409790039062,
      "loss": 0.1986,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8444104790687561,
      "rewards/margins": 2.1446821689605713,
      "rewards/rejected": -1.3002716302871704,
      "step": 301
    },
    {
      "epoch": 2.013333333333333,
      "grad_norm": 0.7665358594206607,
      "learning_rate": 1.3570900889923566e-05,
      "logits/chosen": -0.9402202367782593,
      "logits/rejected": -0.915145754814148,
      "logps/chosen": -213.9524688720703,
      "logps/rejected": -275.71685791015625,
      "loss": 0.0611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7916244864463806,
      "rewards/margins": 3.2881996631622314,
      "rewards/rejected": -2.496575355529785,
      "step": 302
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.9949088135825352,
      "learning_rate": 1.3530503612864846e-05,
      "logits/chosen": -0.8108059763908386,
      "logits/rejected": -0.9782513380050659,
      "logps/chosen": -302.07135009765625,
      "logps/rejected": -211.4249725341797,
      "loss": 0.1236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.030906319618225,
      "rewards/margins": 2.318080425262451,
      "rewards/rejected": -1.2871739864349365,
      "step": 303
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 1.702853469901819,
      "learning_rate": 1.3490040408260481e-05,
      "logits/chosen": -0.9768657684326172,
      "logits/rejected": -0.8528873324394226,
      "logps/chosen": -212.48153686523438,
      "logps/rejected": -233.30087280273438,
      "loss": 0.1903,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6354472637176514,
      "rewards/margins": 2.2675421237945557,
      "rewards/rejected": -1.6320948600769043,
      "step": 304
    },
    {
      "epoch": 2.033333333333333,
      "grad_norm": 1.897503281541482,
      "learning_rate": 1.3449512031707987e-05,
      "logits/chosen": -0.7233088612556458,
      "logits/rejected": -0.90321284532547,
      "logps/chosen": -331.90191650390625,
      "logps/rejected": -226.15382385253906,
      "loss": 0.2819,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.866217851638794,
      "rewards/margins": 1.6142990589141846,
      "rewards/rejected": -0.748081386089325,
      "step": 305
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.250625358554802,
      "learning_rate": 1.340891924002189e-05,
      "logits/chosen": -0.8373299837112427,
      "logits/rejected": -0.8431822061538696,
      "logps/chosen": -203.61801147460938,
      "logps/rejected": -192.74642944335938,
      "loss": 0.214,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8339101076126099,
      "rewards/margins": 2.254425048828125,
      "rewards/rejected": -1.4205149412155151,
      "step": 306
    },
    {
      "epoch": 2.046666666666667,
      "grad_norm": 2.2579760640702786,
      "learning_rate": 1.3368262791219568e-05,
      "logits/chosen": -0.9818437695503235,
      "logits/rejected": -0.8988125920295715,
      "logps/chosen": -298.9974365234375,
      "logps/rejected": -316.5133056640625,
      "loss": 0.2254,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.9892539978027344,
      "rewards/margins": 1.7954981327056885,
      "rewards/rejected": -0.8062441349029541,
      "step": 307
    },
    {
      "epoch": 2.0533333333333332,
      "grad_norm": 2.2787520436556594,
      "learning_rate": 1.3327543444507134e-05,
      "logits/chosen": -0.8788636922836304,
      "logits/rejected": -1.0213536024093628,
      "logps/chosen": -286.7440490722656,
      "logps/rejected": -198.9272003173828,
      "loss": 0.2812,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6373982429504395,
      "rewards/margins": 2.086566209793091,
      "rewards/rejected": -1.4491679668426514,
      "step": 308
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.2691841002978699,
      "learning_rate": 1.3286761960265216e-05,
      "logits/chosen": -0.7102282047271729,
      "logits/rejected": -0.8985265493392944,
      "logps/chosen": -234.11611938476562,
      "logps/rejected": -288.0072021484375,
      "loss": 0.1922,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.48719894886016846,
      "rewards/margins": 2.4150049686431885,
      "rewards/rejected": -1.9278059005737305,
      "step": 309
    },
    {
      "epoch": 2.066666666666667,
      "grad_norm": 2.957786796123622,
      "learning_rate": 1.3245919100034794e-05,
      "logits/chosen": -0.8506312966346741,
      "logits/rejected": -0.7188311815261841,
      "logps/chosen": -264.27178955078125,
      "logps/rejected": -407.9838562011719,
      "loss": 0.2857,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8668776154518127,
      "rewards/margins": 2.0649819374084473,
      "rewards/rejected": -1.1981042623519897,
      "step": 310
    },
    {
      "epoch": 2.0733333333333333,
      "grad_norm": 1.6684174481330327,
      "learning_rate": 1.3205015626502957e-05,
      "logits/chosen": -0.7626814246177673,
      "logits/rejected": -0.9561392664909363,
      "logps/chosen": -508.3310852050781,
      "logps/rejected": -230.98973083496094,
      "loss": 0.1362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.012651801109314,
      "rewards/margins": 2.2682995796203613,
      "rewards/rejected": -1.255647897720337,
      "step": 311
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.5186294193829932,
      "learning_rate": 1.3164052303488673e-05,
      "logits/chosen": -0.7694410681724548,
      "logits/rejected": -0.895256757736206,
      "logps/chosen": -409.9284973144531,
      "logps/rejected": -386.64678955078125,
      "loss": 0.1491,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.762904942035675,
      "rewards/margins": 2.6249122619628906,
      "rewards/rejected": -1.8620073795318604,
      "step": 312
    },
    {
      "epoch": 2.086666666666667,
      "grad_norm": 2.639553507270296,
      "learning_rate": 1.3123029895928516e-05,
      "logits/chosen": -0.8131571412086487,
      "logits/rejected": -0.9298397302627563,
      "logps/chosen": -261.425048828125,
      "logps/rejected": -242.98031616210938,
      "loss": 0.3377,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6046216487884521,
      "rewards/margins": 1.8691023588180542,
      "rewards/rejected": -1.2644808292388916,
      "step": 313
    },
    {
      "epoch": 2.0933333333333333,
      "grad_norm": 3.8385157728766788,
      "learning_rate": 1.3081949169862398e-05,
      "logits/chosen": -0.8014262914657593,
      "logits/rejected": -0.9272924065589905,
      "logps/chosen": -252.68545532226562,
      "logps/rejected": -328.8497009277344,
      "loss": 0.2384,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6032874584197998,
      "rewards/margins": 2.682903528213501,
      "rewards/rejected": -2.079616069793701,
      "step": 314
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.0556103624592272,
      "learning_rate": 1.304081089241923e-05,
      "logits/chosen": -0.6104832291603088,
      "logits/rejected": -0.9007381796836853,
      "logps/chosen": -257.739013671875,
      "logps/rejected": -237.4656982421875,
      "loss": 0.3175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3475857973098755,
      "rewards/margins": 1.491917610168457,
      "rewards/rejected": -1.144331932067871,
      "step": 315
    },
    {
      "epoch": 2.1066666666666665,
      "grad_norm": 1.6825894150348748,
      "learning_rate": 1.2999615831802647e-05,
      "logits/chosen": -0.8757680058479309,
      "logits/rejected": -0.8251895904541016,
      "logps/chosen": -245.5990447998047,
      "logps/rejected": -329.309326171875,
      "loss": 0.2012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5229383707046509,
      "rewards/margins": 2.6755824089050293,
      "rewards/rejected": -2.152644157409668,
      "step": 316
    },
    {
      "epoch": 2.1133333333333333,
      "grad_norm": 1.0355086392567678,
      "learning_rate": 1.2958364757276616e-05,
      "logits/chosen": -1.0034457445144653,
      "logits/rejected": -1.0193177461624146,
      "logps/chosen": -223.04087829589844,
      "logps/rejected": -238.69345092773438,
      "loss": 0.1023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7053809762001038,
      "rewards/margins": 2.540299892425537,
      "rewards/rejected": -1.8349190950393677,
      "step": 317
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.1383260263866601,
      "learning_rate": 1.2917058439151101e-05,
      "logits/chosen": -1.0821267366409302,
      "logits/rejected": -1.0902007818222046,
      "logps/chosen": -213.83094787597656,
      "logps/rejected": -271.9195556640625,
      "loss": 0.0875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6824873685836792,
      "rewards/margins": 2.970181941986084,
      "rewards/rejected": -2.2876944541931152,
      "step": 318
    },
    {
      "epoch": 2.1266666666666665,
      "grad_norm": 0.659897567357347,
      "learning_rate": 1.2875697648767664e-05,
      "logits/chosen": -1.0662230253219604,
      "logits/rejected": -0.8660102486610413,
      "logps/chosen": -145.19822692871094,
      "logps/rejected": -347.5029296875,
      "loss": 0.0454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7120856046676636,
      "rewards/margins": 3.372035026550293,
      "rewards/rejected": -2.6599490642547607,
      "step": 319
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 3.1968745584944402,
      "learning_rate": 1.2834283158485064e-05,
      "logits/chosen": -1.0119667053222656,
      "logits/rejected": -1.1116855144500732,
      "logps/chosen": -286.41845703125,
      "logps/rejected": -308.2527770996094,
      "loss": 0.3206,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.25760817527770996,
      "rewards/margins": 2.36975359916687,
      "rewards/rejected": -2.11214542388916,
      "step": 320
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.0264691012786609,
      "learning_rate": 1.2792815741664839e-05,
      "logits/chosen": -0.9486507177352905,
      "logits/rejected": -0.9104301333427429,
      "logps/chosen": -160.2264862060547,
      "logps/rejected": -232.99530029296875,
      "loss": 0.1054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6672132611274719,
      "rewards/margins": 2.6556148529052734,
      "rewards/rejected": -1.9884016513824463,
      "step": 321
    },
    {
      "epoch": 2.1466666666666665,
      "grad_norm": 2.0301528315022472,
      "learning_rate": 1.2751296172656862e-05,
      "logits/chosen": -0.7570664882659912,
      "logits/rejected": -0.8606870174407959,
      "logps/chosen": -251.24551391601562,
      "logps/rejected": -230.49087524414062,
      "loss": 0.3166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5246801376342773,
      "rewards/margins": 1.3795628547668457,
      "rewards/rejected": -0.8548827171325684,
      "step": 322
    },
    {
      "epoch": 2.1533333333333333,
      "grad_norm": 1.5561441469769612,
      "learning_rate": 1.2709725226784872e-05,
      "logits/chosen": -0.9565631151199341,
      "logits/rejected": -0.8438339829444885,
      "logps/chosen": -177.14071655273438,
      "logps/rejected": -289.1068115234375,
      "loss": 0.2346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.499439537525177,
      "rewards/margins": 2.064845085144043,
      "rewards/rejected": -1.5654056072235107,
      "step": 323
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.0122140386387628,
      "learning_rate": 1.2668103680332011e-05,
      "logits/chosen": -0.8846950531005859,
      "logits/rejected": -0.8238999843597412,
      "logps/chosen": -160.15951538085938,
      "logps/rejected": -309.49169921875,
      "loss": 0.1102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4749904274940491,
      "rewards/margins": 3.481942653656006,
      "rewards/rejected": -3.0069522857666016,
      "step": 324
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 0.7698299389841629,
      "learning_rate": 1.2626432310526321e-05,
      "logits/chosen": -0.9928423762321472,
      "logits/rejected": -0.8161426186561584,
      "logps/chosen": -283.8841552734375,
      "logps/rejected": -349.10260009765625,
      "loss": 0.0578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6151427626609802,
      "rewards/margins": 3.36845326423645,
      "rewards/rejected": -2.753310441970825,
      "step": 325
    },
    {
      "epoch": 2.1733333333333333,
      "grad_norm": 1.545584785996464,
      "learning_rate": 1.2584711895526227e-05,
      "logits/chosen": -0.9423928260803223,
      "logits/rejected": -1.0407747030258179,
      "logps/chosen": -284.02264404296875,
      "logps/rejected": -268.2419738769531,
      "loss": 0.1931,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6371287107467651,
      "rewards/margins": 2.221820116043091,
      "rewards/rejected": -1.5846915245056152,
      "step": 326
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.8376535289160206,
      "learning_rate": 1.2542943214406012e-05,
      "logits/chosen": -0.7548066973686218,
      "logits/rejected": -0.8455557823181152,
      "logps/chosen": -132.41064453125,
      "logps/rejected": -289.62884521484375,
      "loss": 0.0855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6761460304260254,
      "rewards/margins": 3.380556583404541,
      "rewards/rejected": -2.7044105529785156,
      "step": 327
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 1.573608961867978,
      "learning_rate": 1.250112704714126e-05,
      "logits/chosen": -0.8065895438194275,
      "logits/rejected": -0.8724543452262878,
      "logps/chosen": -235.63711547851562,
      "logps/rejected": -319.0549621582031,
      "loss": 0.1808,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.9595576524734497,
      "rewards/margins": 2.9958150386810303,
      "rewards/rejected": -2.036257266998291,
      "step": 328
    },
    {
      "epoch": 2.1933333333333334,
      "grad_norm": 1.392253522238623,
      "learning_rate": 1.2459264174594303e-05,
      "logits/chosen": -0.6729357838630676,
      "logits/rejected": -0.7607260942459106,
      "logps/chosen": -214.8284912109375,
      "logps/rejected": -350.6668395996094,
      "loss": 0.1314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6273626089096069,
      "rewards/margins": 3.127631425857544,
      "rewards/rejected": -2.5002689361572266,
      "step": 329
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.9240983957124065,
      "learning_rate": 1.2417355378499631e-05,
      "logits/chosen": -1.0775372982025146,
      "logits/rejected": -0.9568934440612793,
      "logps/chosen": -141.64251708984375,
      "logps/rejected": -288.1838684082031,
      "loss": 0.1896,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2553848624229431,
      "rewards/margins": 2.518681049346924,
      "rewards/rejected": -2.263296127319336,
      "step": 330
    },
    {
      "epoch": 2.2066666666666666,
      "grad_norm": 2.6942243508007104,
      "learning_rate": 1.2375401441449296e-05,
      "logits/chosen": -0.7708355784416199,
      "logits/rejected": -0.9432570934295654,
      "logps/chosen": -234.99105834960938,
      "logps/rejected": -268.3041076660156,
      "loss": 0.3261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19666969776153564,
      "rewards/margins": 1.813530445098877,
      "rewards/rejected": -1.6168606281280518,
      "step": 331
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 0.9410926644795438,
      "learning_rate": 1.23334031468783e-05,
      "logits/chosen": -0.815015435218811,
      "logits/rejected": -0.9250872135162354,
      "logps/chosen": -277.8316955566406,
      "logps/rejected": -386.05999755859375,
      "loss": 0.088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8987622261047363,
      "rewards/margins": 3.207886219024658,
      "rewards/rejected": -2.309123992919922,
      "step": 332
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.3748474072073624,
      "learning_rate": 1.229136127904996e-05,
      "logits/chosen": -0.7656213641166687,
      "logits/rejected": -0.9075092077255249,
      "logps/chosen": -309.031494140625,
      "logps/rejected": -285.7887878417969,
      "loss": 0.2317,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7004117369651794,
      "rewards/margins": 2.0413427352905273,
      "rewards/rejected": -1.3409309387207031,
      "step": 333
    },
    {
      "epoch": 2.2266666666666666,
      "grad_norm": 1.8843633192722031,
      "learning_rate": 1.2249276623041268e-05,
      "logits/chosen": -1.0017380714416504,
      "logits/rejected": -1.0344552993774414,
      "logps/chosen": -256.3252868652344,
      "logps/rejected": -264.7196044921875,
      "loss": 0.2148,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8980406522750854,
      "rewards/margins": 2.643099546432495,
      "rewards/rejected": -1.7450587749481201,
      "step": 334
    },
    {
      "epoch": 2.2333333333333334,
      "grad_norm": 2.7732346151584237,
      "learning_rate": 1.2207149964728236e-05,
      "logits/chosen": -0.9682257771492004,
      "logits/rejected": -0.9744876623153687,
      "logps/chosen": -216.99496459960938,
      "logps/rejected": -276.6458740234375,
      "loss": 0.2228,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5780712366104126,
      "rewards/margins": 2.44878888130188,
      "rewards/rejected": -1.8707176446914673,
      "step": 335
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.2811382989341114,
      "learning_rate": 1.2164982090771202e-05,
      "logits/chosen": -0.9564799070358276,
      "logits/rejected": -1.0829896926879883,
      "logps/chosen": -343.0408020019531,
      "logps/rejected": -263.24468994140625,
      "loss": 0.129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9824480414390564,
      "rewards/margins": 2.2657618522644043,
      "rewards/rejected": -1.2833138704299927,
      "step": 336
    },
    {
      "epoch": 2.2466666666666666,
      "grad_norm": 1.675158404930742,
      "learning_rate": 1.2122773788600164e-05,
      "logits/chosen": -0.9511580467224121,
      "logits/rejected": -0.7695413827896118,
      "logps/chosen": -131.3765106201172,
      "logps/rejected": -322.14471435546875,
      "loss": 0.2255,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4337460994720459,
      "rewards/margins": 2.631105422973633,
      "rewards/rejected": -2.197359323501587,
      "step": 337
    },
    {
      "epoch": 2.2533333333333334,
      "grad_norm": 0.988649141494146,
      "learning_rate": 1.2080525846400055e-05,
      "logits/chosen": -0.9137081503868103,
      "logits/rejected": -0.894892692565918,
      "logps/chosen": -155.49566650390625,
      "logps/rejected": -270.6893310546875,
      "loss": 0.0857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7877323031425476,
      "rewards/margins": 3.4619030952453613,
      "rewards/rejected": -2.674170970916748,
      "step": 338
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.029319080161537,
      "learning_rate": 1.203823905309604e-05,
      "logits/chosen": -1.0152276754379272,
      "logits/rejected": -0.9316146373748779,
      "logps/chosen": -226.01467895507812,
      "logps/rejected": -289.0743408203125,
      "loss": 0.232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4024650454521179,
      "rewards/margins": 2.1191649436950684,
      "rewards/rejected": -1.7166998386383057,
      "step": 339
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 2.069404604511958,
      "learning_rate": 1.1995914198338777e-05,
      "logits/chosen": -0.9740725159645081,
      "logits/rejected": -0.7416127324104309,
      "logps/chosen": -132.4644775390625,
      "logps/rejected": -360.13104248046875,
      "loss": 0.2665,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5200208425521851,
      "rewards/margins": 2.847414970397949,
      "rewards/rejected": -2.3273940086364746,
      "step": 340
    },
    {
      "epoch": 2.2733333333333334,
      "grad_norm": 2.4937727618792023,
      "learning_rate": 1.1953552072489666e-05,
      "logits/chosen": -0.789279043674469,
      "logits/rejected": -0.8438570499420166,
      "logps/chosen": -324.44580078125,
      "logps/rejected": -329.280029296875,
      "loss": 0.2451,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5900331735610962,
      "rewards/margins": 2.0585596561431885,
      "rewards/rejected": -1.4685266017913818,
      "step": 341
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 2.7776696809292787,
      "learning_rate": 1.1911153466606105e-05,
      "logits/chosen": -0.853666365146637,
      "logits/rejected": -0.8508706092834473,
      "logps/chosen": -326.4543762207031,
      "logps/rejected": -394.1425476074219,
      "loss": 0.2863,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4260365962982178,
      "rewards/margins": 2.1335623264312744,
      "rewards/rejected": -1.7075258493423462,
      "step": 342
    },
    {
      "epoch": 2.2866666666666666,
      "grad_norm": 1.8661645617030136,
      "learning_rate": 1.1868719172426703e-05,
      "logits/chosen": -0.8587285280227661,
      "logits/rejected": -0.8186866641044617,
      "logps/chosen": -166.85049438476562,
      "logps/rejected": -309.8215026855469,
      "loss": 0.2186,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2188369184732437,
      "rewards/margins": 2.6645877361297607,
      "rewards/rejected": -2.4457507133483887,
      "step": 343
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 2.3870270025853872,
      "learning_rate": 1.18262499823565e-05,
      "logits/chosen": -1.0062289237976074,
      "logits/rejected": -0.8569756150245667,
      "logps/chosen": -155.10598754882812,
      "logps/rejected": -297.44500732421875,
      "loss": 0.3102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.026463188230991364,
      "rewards/margins": 1.777817964553833,
      "rewards/rejected": -1.804281234741211,
      "step": 344
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.575432498498318,
      "learning_rate": 1.1783746689452177e-05,
      "logits/chosen": -0.7181874513626099,
      "logits/rejected": -1.0265496969223022,
      "logps/chosen": -320.7652587890625,
      "logps/rejected": -223.92681884765625,
      "loss": 0.2832,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5058485269546509,
      "rewards/margins": 1.773970365524292,
      "rewards/rejected": -1.2681218385696411,
      "step": 345
    },
    {
      "epoch": 2.3066666666666666,
      "grad_norm": 2.2025640328113125,
      "learning_rate": 1.174121008740724e-05,
      "logits/chosen": -0.7873474955558777,
      "logits/rejected": -0.8477332592010498,
      "logps/chosen": -292.2174987792969,
      "logps/rejected": -348.1324462890625,
      "loss": 0.2304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.694650411605835,
      "rewards/margins": 2.150317668914795,
      "rewards/rejected": -1.45566725730896,
      "step": 346
    },
    {
      "epoch": 2.3133333333333335,
      "grad_norm": 1.893284778923819,
      "learning_rate": 1.1698640970537195e-05,
      "logits/chosen": -0.7564904093742371,
      "logits/rejected": -1.000728726387024,
      "logps/chosen": -277.65216064453125,
      "logps/rejected": -292.55999755859375,
      "loss": 0.1463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4762077331542969,
      "rewards/margins": 2.8209192752838135,
      "rewards/rejected": -2.3447115421295166,
      "step": 347
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.073862278654003,
      "learning_rate": 1.1656040133764721e-05,
      "logits/chosen": -0.7714805006980896,
      "logits/rejected": -1.0338737964630127,
      "logps/chosen": -404.38641357421875,
      "logps/rejected": -308.96221923828125,
      "loss": 0.2961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8841803073883057,
      "rewards/margins": 1.4579195976257324,
      "rewards/rejected": -0.5737392902374268,
      "step": 348
    },
    {
      "epoch": 2.3266666666666667,
      "grad_norm": 2.6413328587632554,
      "learning_rate": 1.1613408372604826e-05,
      "logits/chosen": -0.7635979056358337,
      "logits/rejected": -0.879447340965271,
      "logps/chosen": -345.8099365234375,
      "logps/rejected": -365.5805969238281,
      "loss": 0.234,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5160819888114929,
      "rewards/margins": 2.8758177757263184,
      "rewards/rejected": -2.3597357273101807,
      "step": 349
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 2.538556796845272,
      "learning_rate": 1.1570746483149997e-05,
      "logits/chosen": -1.0730671882629395,
      "logits/rejected": -0.8362227082252502,
      "logps/chosen": -205.34033203125,
      "logps/rejected": -515.1322021484375,
      "loss": 0.1304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47211241722106934,
      "rewards/margins": 3.495206117630005,
      "rewards/rejected": -3.0230934619903564,
      "step": 350
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.4513874946275227,
      "learning_rate": 1.1528055262055318e-05,
      "logits/chosen": -0.9494019150733948,
      "logits/rejected": -0.9658594727516174,
      "logps/chosen": -180.02630615234375,
      "logps/rejected": -272.69708251953125,
      "loss": 0.1318,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6434905529022217,
      "rewards/margins": 3.383740186691284,
      "rewards/rejected": -2.7402496337890625,
      "step": 351
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 2.45026799896545,
      "learning_rate": 1.14853355065236e-05,
      "logits/chosen": -0.7463385462760925,
      "logits/rejected": -0.8385521769523621,
      "logps/chosen": -295.7869873046875,
      "logps/rejected": -365.41534423828125,
      "loss": 0.2166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4280170202255249,
      "rewards/margins": 2.969404697418213,
      "rewards/rejected": -2.5413877964019775,
      "step": 352
    },
    {
      "epoch": 2.3533333333333335,
      "grad_norm": 3.2135498112720096,
      "learning_rate": 1.1442588014290511e-05,
      "logits/chosen": -1.0824179649353027,
      "logits/rejected": -1.0889687538146973,
      "logps/chosen": -232.27586364746094,
      "logps/rejected": -226.80718994140625,
      "loss": 0.1718,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6188715696334839,
      "rewards/margins": 2.4058213233947754,
      "rewards/rejected": -1.786949872970581,
      "step": 353
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.8119676019425338,
      "learning_rate": 1.139981358360966e-05,
      "logits/chosen": -0.9302562475204468,
      "logits/rejected": -1.0740962028503418,
      "logps/chosen": -285.2736511230469,
      "logps/rejected": -255.86770629882812,
      "loss": 0.1496,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7343610525131226,
      "rewards/margins": 2.7014527320861816,
      "rewards/rejected": -1.967091679573059,
      "step": 354
    },
    {
      "epoch": 2.3666666666666667,
      "grad_norm": 0.9291446286882374,
      "learning_rate": 1.135701301323769e-05,
      "logits/chosen": -1.0165348052978516,
      "logits/rejected": -1.011796474456787,
      "logps/chosen": -377.4631652832031,
      "logps/rejected": -365.26800537109375,
      "loss": 0.0721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8224170207977295,
      "rewards/margins": 3.6255927085876465,
      "rewards/rejected": -2.803175687789917,
      "step": 355
    },
    {
      "epoch": 2.3733333333333335,
      "grad_norm": 0.6809329975219159,
      "learning_rate": 1.1314187102419374e-05,
      "logits/chosen": -1.0124715566635132,
      "logits/rejected": -0.9668525457382202,
      "logps/chosen": -251.01608276367188,
      "logps/rejected": -385.2898254394531,
      "loss": 0.0514,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7148380279541016,
      "rewards/margins": 3.9345126152038574,
      "rewards/rejected": -3.219674587249756,
      "step": 356
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6396776498428451,
      "learning_rate": 1.1271336650872687e-05,
      "logits/chosen": -0.9153236150741577,
      "logits/rejected": -1.0503321886062622,
      "logps/chosen": -289.4726257324219,
      "logps/rejected": -275.592529296875,
      "loss": 0.0479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0279736518859863,
      "rewards/margins": 3.2395551204681396,
      "rewards/rejected": -2.2115814685821533,
      "step": 357
    },
    {
      "epoch": 2.3866666666666667,
      "grad_norm": 2.0514957600158565,
      "learning_rate": 1.1228462458773866e-05,
      "logits/chosen": -0.9760253429412842,
      "logits/rejected": -0.9232168197631836,
      "logps/chosen": -220.8638916015625,
      "logps/rejected": -398.1495056152344,
      "loss": 0.0966,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0143048763275146,
      "rewards/margins": 3.1734020709991455,
      "rewards/rejected": -2.159097194671631,
      "step": 358
    },
    {
      "epoch": 2.3933333333333335,
      "grad_norm": 0.9972749475804678,
      "learning_rate": 1.1185565326742474e-05,
      "logits/chosen": -0.9245871305465698,
      "logits/rejected": -1.0113883018493652,
      "logps/chosen": -206.7606964111328,
      "logps/rejected": -270.4143981933594,
      "loss": 0.1019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5286558866500854,
      "rewards/margins": 3.0899930000305176,
      "rewards/rejected": -2.5613369941711426,
      "step": 359
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.9689660332240966,
      "learning_rate": 1.1142646055826442e-05,
      "logits/chosen": -1.0049793720245361,
      "logits/rejected": -1.0085492134094238,
      "logps/chosen": -181.9356689453125,
      "logps/rejected": -402.09478759765625,
      "loss": 0.1715,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8795055150985718,
      "rewards/margins": 3.6079788208007812,
      "rewards/rejected": -2.72847318649292,
      "step": 360
    },
    {
      "epoch": 2.4066666666666667,
      "grad_norm": 3.4763765092453958,
      "learning_rate": 1.1099705447487128e-05,
      "logits/chosen": -0.8744741678237915,
      "logits/rejected": -0.8138709664344788,
      "logps/chosen": -294.85980224609375,
      "logps/rejected": -416.4947204589844,
      "loss": 0.3098,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6815324425697327,
      "rewards/margins": 2.477078676223755,
      "rewards/rejected": -1.7955461740493774,
      "step": 361
    },
    {
      "epoch": 2.413333333333333,
      "grad_norm": 1.0497083894786658,
      "learning_rate": 1.1056744303584322e-05,
      "logits/chosen": -0.7895945906639099,
      "logits/rejected": -0.7822720408439636,
      "logps/chosen": -274.47003173828125,
      "logps/rejected": -410.2197570800781,
      "loss": 0.0923,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5339678525924683,
      "rewards/margins": 3.3150196075439453,
      "rewards/rejected": -2.7810516357421875,
      "step": 362
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.071762773071515,
      "learning_rate": 1.1013763426361303e-05,
      "logits/chosen": -0.9639907479286194,
      "logits/rejected": -1.0141032934188843,
      "logps/chosen": -210.38232421875,
      "logps/rejected": -309.2707824707031,
      "loss": 0.0645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.654245913028717,
      "rewards/margins": 3.693821668624878,
      "rewards/rejected": -3.0395755767822266,
      "step": 363
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 0.31978335519897505,
      "learning_rate": 1.0970763618429841e-05,
      "logits/chosen": -1.0221561193466187,
      "logits/rejected": -0.9776602983474731,
      "logps/chosen": -171.1649627685547,
      "logps/rejected": -363.8953857421875,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5150004029273987,
      "rewards/margins": 4.509116172790527,
      "rewards/rejected": -3.9941158294677734,
      "step": 364
    },
    {
      "epoch": 2.4333333333333336,
      "grad_norm": 1.0758769605691199,
      "learning_rate": 1.0927745682755202e-05,
      "logits/chosen": -0.8976797461509705,
      "logits/rejected": -0.976919412612915,
      "logps/chosen": -336.64373779296875,
      "logps/rejected": -306.8141174316406,
      "loss": 0.0766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.134989857673645,
      "rewards/margins": 3.0539145469665527,
      "rewards/rejected": -1.9189245700836182,
      "step": 365
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.9842927383685939,
      "learning_rate": 1.088471042264118e-05,
      "logits/chosen": -0.8489106893539429,
      "logits/rejected": -0.9775548577308655,
      "logps/chosen": -302.3208312988281,
      "logps/rejected": -306.89501953125,
      "loss": 0.0679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8505501747131348,
      "rewards/margins": 3.000025987625122,
      "rewards/rejected": -2.149475574493408,
      "step": 366
    },
    {
      "epoch": 2.4466666666666668,
      "grad_norm": 1.3044628932203546,
      "learning_rate": 1.0841658641715064e-05,
      "logits/chosen": -0.9142965078353882,
      "logits/rejected": -0.9876168370246887,
      "logps/chosen": -402.482666015625,
      "logps/rejected": -354.0062255859375,
      "loss": 0.1591,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6796364784240723,
      "rewards/margins": 2.7945051193237305,
      "rewards/rejected": -2.114868640899658,
      "step": 367
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 1.7184117070974934,
      "learning_rate": 1.079859114391266e-05,
      "logits/chosen": -0.9634231328964233,
      "logits/rejected": -0.8817489743232727,
      "logps/chosen": -206.27587890625,
      "logps/rejected": -384.4016418457031,
      "loss": 0.1385,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3906950056552887,
      "rewards/margins": 3.3813462257385254,
      "rewards/rejected": -2.9906511306762695,
      "step": 368
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.2942280199890024,
      "learning_rate": 1.0755508733463265e-05,
      "logits/chosen": -0.992695152759552,
      "logits/rejected": -0.976265549659729,
      "logps/chosen": -229.24331665039062,
      "logps/rejected": -359.78363037109375,
      "loss": 0.2374,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7314164638519287,
      "rewards/margins": 2.739412784576416,
      "rewards/rejected": -2.007996082305908,
      "step": 369
    },
    {
      "epoch": 2.466666666666667,
      "grad_norm": 2.3698172990579476,
      "learning_rate": 1.071241221487464e-05,
      "logits/chosen": -0.9421104192733765,
      "logits/rejected": -0.9447489976882935,
      "logps/chosen": -236.99630737304688,
      "logps/rejected": -275.27313232421875,
      "loss": 0.1507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4637582302093506,
      "rewards/margins": 3.0409493446350098,
      "rewards/rejected": -2.5771913528442383,
      "step": 370
    },
    {
      "epoch": 2.473333333333333,
      "grad_norm": 2.684438247734915,
      "learning_rate": 1.0669302392918007e-05,
      "logits/chosen": -0.9045164585113525,
      "logits/rejected": -1.121405839920044,
      "logps/chosen": -266.9633483886719,
      "logps/rejected": -166.47821044921875,
      "loss": 0.366,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.8166289329528809,
      "rewards/margins": 1.6914759874343872,
      "rewards/rejected": -0.8748471140861511,
      "step": 371
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.0569625269286558,
      "learning_rate": 1.0626180072613011e-05,
      "logits/chosen": -1.0155513286590576,
      "logits/rejected": -0.9894346594810486,
      "logps/chosen": -231.46495056152344,
      "logps/rejected": -344.98016357421875,
      "loss": 0.1641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.24135422706604,
      "rewards/margins": 3.2078986167907715,
      "rewards/rejected": -1.9665443897247314,
      "step": 372
    },
    {
      "epoch": 2.486666666666667,
      "grad_norm": 2.479866303101057,
      "learning_rate": 1.0583046059212678e-05,
      "logits/chosen": -0.756096363067627,
      "logits/rejected": -0.831856369972229,
      "logps/chosen": -227.82752990722656,
      "logps/rejected": -291.12518310546875,
      "loss": 0.2105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.622143030166626,
      "rewards/margins": 2.599792003631592,
      "rewards/rejected": -1.9776489734649658,
      "step": 373
    },
    {
      "epoch": 2.493333333333333,
      "grad_norm": 3.6142163855366953,
      "learning_rate": 1.0539901158188399e-05,
      "logits/chosen": -0.8260821104049683,
      "logits/rejected": -1.0116932392120361,
      "logps/chosen": -382.9761962890625,
      "logps/rejected": -248.429931640625,
      "loss": 0.4552,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.15226152539253235,
      "rewards/margins": 1.3317497968673706,
      "rewards/rejected": -1.179488182067871,
      "step": 374
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.5683713843620997,
      "learning_rate": 1.0496746175214869e-05,
      "logits/chosen": -0.9762291312217712,
      "logits/rejected": -1.0205620527267456,
      "logps/chosen": -324.19537353515625,
      "logps/rejected": -227.956787109375,
      "loss": 0.1346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9113471508026123,
      "rewards/margins": 2.5871968269348145,
      "rewards/rejected": -1.6758496761322021,
      "step": 375
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 1.8317494124771745,
      "learning_rate": 1.045358191615506e-05,
      "logits/chosen": -1.0151050090789795,
      "logits/rejected": -0.9185094237327576,
      "logps/chosen": -196.87979125976562,
      "logps/rejected": -260.8968811035156,
      "loss": 0.1812,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4319351613521576,
      "rewards/margins": 3.138587474822998,
      "rewards/rejected": -2.7066526412963867,
      "step": 376
    },
    {
      "epoch": 2.513333333333333,
      "grad_norm": 2.02642942769625,
      "learning_rate": 1.0410409187045145e-05,
      "logits/chosen": -1.069665789604187,
      "logits/rejected": -1.0381380319595337,
      "logps/chosen": -197.67356872558594,
      "logps/rejected": -323.3134765625,
      "loss": 0.1484,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2678681015968323,
      "rewards/margins": 2.9275717735290527,
      "rewards/rejected": -2.6597037315368652,
      "step": 377
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.3911123340021354,
      "learning_rate": 1.0367228794079483e-05,
      "logits/chosen": -0.9753778576850891,
      "logits/rejected": -1.0372297763824463,
      "logps/chosen": -136.28143310546875,
      "logps/rejected": -295.16888427734375,
      "loss": 0.2385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4744616150856018,
      "rewards/margins": 3.913167953491211,
      "rewards/rejected": -3.438706398010254,
      "step": 378
    },
    {
      "epoch": 2.5266666666666664,
      "grad_norm": 0.7014526187681704,
      "learning_rate": 1.0324041543595536e-05,
      "logits/chosen": -0.9577669501304626,
      "logits/rejected": -0.871855616569519,
      "logps/chosen": -233.44735717773438,
      "logps/rejected": -366.24432373046875,
      "loss": 0.0459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6741132140159607,
      "rewards/margins": 4.011249542236328,
      "rewards/rejected": -3.3371362686157227,
      "step": 379
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 2.0844812917988436,
      "learning_rate": 1.0280848242058819e-05,
      "logits/chosen": -1.0617998838424683,
      "logits/rejected": -0.7664554119110107,
      "logps/chosen": -162.39988708496094,
      "logps/rejected": -395.6639709472656,
      "loss": 0.0765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.353028267621994,
      "rewards/margins": 4.073342323303223,
      "rewards/rejected": -3.720313787460327,
      "step": 380
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.8080492950952036,
      "learning_rate": 1.0237649696047851e-05,
      "logits/chosen": -0.8337103724479675,
      "logits/rejected": -1.0078405141830444,
      "logps/chosen": -260.7111511230469,
      "logps/rejected": -279.969482421875,
      "loss": 0.1339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6024622917175293,
      "rewards/margins": 3.116560935974121,
      "rewards/rejected": -2.514098644256592,
      "step": 381
    },
    {
      "epoch": 2.546666666666667,
      "grad_norm": 1.4820872294743228,
      "learning_rate": 1.0194446712239076e-05,
      "logits/chosen": -0.9470610022544861,
      "logits/rejected": -0.9176713228225708,
      "logps/chosen": -220.39151000976562,
      "logps/rejected": -356.46124267578125,
      "loss": 0.1309,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2785922586917877,
      "rewards/margins": 3.388587474822998,
      "rewards/rejected": -3.109995126724243,
      "step": 382
    },
    {
      "epoch": 2.5533333333333332,
      "grad_norm": 1.3494983853800084,
      "learning_rate": 1.015124009739182e-05,
      "logits/chosen": -0.8214843273162842,
      "logits/rejected": -0.7793687582015991,
      "logps/chosen": -246.6525421142578,
      "logps/rejected": -322.5936279296875,
      "loss": 0.0862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7262314558029175,
      "rewards/margins": 3.5517752170562744,
      "rewards/rejected": -2.8255436420440674,
      "step": 383
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.998444667681023,
      "learning_rate": 1.0108030658333193e-05,
      "logits/chosen": -0.9963762164115906,
      "logits/rejected": -0.9694483280181885,
      "logps/chosen": -205.055419921875,
      "logps/rejected": -290.19317626953125,
      "loss": 0.2157,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6562072038650513,
      "rewards/margins": 3.0067973136901855,
      "rewards/rejected": -2.350590229034424,
      "step": 384
    },
    {
      "epoch": 2.5666666666666664,
      "grad_norm": 2.129631492902644,
      "learning_rate": 1.0064819201943066e-05,
      "logits/chosen": -0.9831619262695312,
      "logits/rejected": -0.9177066683769226,
      "logps/chosen": -228.42779541015625,
      "logps/rejected": -322.2542724609375,
      "loss": 0.1681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3487333357334137,
      "rewards/margins": 3.1981210708618164,
      "rewards/rejected": -2.8493881225585938,
      "step": 385
    },
    {
      "epoch": 2.5733333333333333,
      "grad_norm": 1.5394921647033821,
      "learning_rate": 1.0021606535138965e-05,
      "logits/chosen": -1.014589548110962,
      "logits/rejected": -1.0641909837722778,
      "logps/chosen": -219.46945190429688,
      "logps/rejected": -308.22686767578125,
      "loss": 0.1209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08589525520801544,
      "rewards/margins": 3.1119909286499023,
      "rewards/rejected": -3.0260956287384033,
      "step": 386
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.0515191194897104,
      "learning_rate": 9.978393464861036e-06,
      "logits/chosen": -0.8161193132400513,
      "logits/rejected": -1.007947564125061,
      "logps/chosen": -363.14495849609375,
      "logps/rejected": -255.33839416503906,
      "loss": 0.1447,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3003349304199219,
      "rewards/margins": 2.74924373626709,
      "rewards/rejected": -2.448908805847168,
      "step": 387
    },
    {
      "epoch": 2.586666666666667,
      "grad_norm": 1.857199799010549,
      "learning_rate": 9.935180798056936e-06,
      "logits/chosen": -0.9873940944671631,
      "logits/rejected": -1.095393180847168,
      "logps/chosen": -214.63699340820312,
      "logps/rejected": -247.3231658935547,
      "loss": 0.1701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5061282515525818,
      "rewards/margins": 3.2348098754882812,
      "rewards/rejected": -2.728681802749634,
      "step": 388
    },
    {
      "epoch": 2.5933333333333333,
      "grad_norm": 1.170189268094853,
      "learning_rate": 9.891969341666809e-06,
      "logits/chosen": -0.725154459476471,
      "logits/rejected": -0.9415475726127625,
      "logps/chosen": -466.7278747558594,
      "logps/rejected": -525.914306640625,
      "loss": 0.0774,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0715827941894531,
      "rewards/margins": 3.487220287322998,
      "rewards/rejected": -2.415637493133545,
      "step": 389
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.2594163735217085,
      "learning_rate": 9.848759902608188e-06,
      "logits/chosen": -1.0643930435180664,
      "logits/rejected": -1.1413897275924683,
      "logps/chosen": -169.53033447265625,
      "logps/rejected": -194.8593292236328,
      "loss": 0.26,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3409108817577362,
      "rewards/margins": 2.3562731742858887,
      "rewards/rejected": -2.01536226272583,
      "step": 390
    },
    {
      "epoch": 2.6066666666666665,
      "grad_norm": 5.756720223206221,
      "learning_rate": 9.805553287760922e-06,
      "logits/chosen": -0.9204111099243164,
      "logits/rejected": -1.1418943405151367,
      "logps/chosen": -258.0260009765625,
      "logps/rejected": -226.72518920898438,
      "loss": 0.6128,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.05200314521789551,
      "rewards/margins": 2.3705716133117676,
      "rewards/rejected": -2.318568229675293,
      "step": 391
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 2.2300792026567287,
      "learning_rate": 9.76235030395215e-06,
      "logits/chosen": -1.0214985609054565,
      "logits/rejected": -0.9431214332580566,
      "logps/chosen": -280.765869140625,
      "logps/rejected": -439.13812255859375,
      "loss": 0.1183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5482485294342041,
      "rewards/margins": 3.651524543762207,
      "rewards/rejected": -3.1032755374908447,
      "step": 392
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.6062722404134804,
      "learning_rate": 9.719151757941184e-06,
      "logits/chosen": -0.870642900466919,
      "logits/rejected": -1.0499951839447021,
      "logps/chosen": -270.1461486816406,
      "logps/rejected": -264.3882751464844,
      "loss": 0.1909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30582737922668457,
      "rewards/margins": 2.9508018493652344,
      "rewards/rejected": -2.64497447013855,
      "step": 393
    },
    {
      "epoch": 2.626666666666667,
      "grad_norm": 1.9302986814212095,
      "learning_rate": 9.675958456404468e-06,
      "logits/chosen": -0.9397842884063721,
      "logits/rejected": -0.8815112113952637,
      "logps/chosen": -220.27537536621094,
      "logps/rejected": -451.63470458984375,
      "loss": 0.1788,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24434228241443634,
      "rewards/margins": 2.749063014984131,
      "rewards/rejected": -2.504720449447632,
      "step": 394
    },
    {
      "epoch": 2.6333333333333333,
      "grad_norm": 2.6359381982681445,
      "learning_rate": 9.63277120592052e-06,
      "logits/chosen": -0.8130136132240295,
      "logits/rejected": -0.9907501935958862,
      "logps/chosen": -315.4137878417969,
      "logps/rejected": -328.6106872558594,
      "loss": 0.299,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6292760372161865,
      "rewards/margins": 2.615246295928955,
      "rewards/rejected": -1.9859702587127686,
      "step": 395
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.519083619071968,
      "learning_rate": 9.589590812954858e-06,
      "logits/chosen": -0.97301185131073,
      "logits/rejected": -1.008999228477478,
      "logps/chosen": -297.53076171875,
      "logps/rejected": -374.61328125,
      "loss": 0.1462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7271218299865723,
      "rewards/margins": 3.4632601737976074,
      "rewards/rejected": -2.736138343811035,
      "step": 396
    },
    {
      "epoch": 2.6466666666666665,
      "grad_norm": 2.907160462540046,
      "learning_rate": 9.546418083844944e-06,
      "logits/chosen": -0.9139471054077148,
      "logits/rejected": -1.0639781951904297,
      "logps/chosen": -287.1158447265625,
      "logps/rejected": -395.63287353515625,
      "loss": 0.2113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47406700253486633,
      "rewards/margins": 2.3456058502197266,
      "rewards/rejected": -1.8715391159057617,
      "step": 397
    },
    {
      "epoch": 2.6533333333333333,
      "grad_norm": 1.1522893860488106,
      "learning_rate": 9.503253824785133e-06,
      "logits/chosen": -0.8770285844802856,
      "logits/rejected": -0.9105543494224548,
      "logps/chosen": -318.13671875,
      "logps/rejected": -384.3551025390625,
      "loss": 0.1592,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6782847046852112,
      "rewards/margins": 3.711968421936035,
      "rewards/rejected": -3.0336837768554688,
      "step": 398
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.1898348090974913,
      "learning_rate": 9.460098841811601e-06,
      "logits/chosen": -1.0221993923187256,
      "logits/rejected": -1.0264209508895874,
      "logps/chosen": -329.19122314453125,
      "logps/rejected": -399.65252685546875,
      "loss": 0.048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6938596963882446,
      "rewards/margins": 4.4618096351623535,
      "rewards/rejected": -3.7679500579833984,
      "step": 399
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.6178574211098713,
      "learning_rate": 9.416953940787324e-06,
      "logits/chosen": -1.0510501861572266,
      "logits/rejected": -0.9703017473220825,
      "logps/chosen": -165.22640991210938,
      "logps/rejected": -326.11419677734375,
      "loss": 0.087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6702889204025269,
      "rewards/margins": 4.163488388061523,
      "rewards/rejected": -3.493199586868286,
      "step": 400
    },
    {
      "epoch": 2.6733333333333333,
      "grad_norm": 2.327330383282885,
      "learning_rate": 9.373819927386996e-06,
      "logits/chosen": -0.9207649230957031,
      "logits/rejected": -0.9690335988998413,
      "logps/chosen": -288.0085144042969,
      "logps/rejected": -360.2394104003906,
      "loss": 0.2458,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2732706367969513,
      "rewards/margins": 2.6781017780303955,
      "rewards/rejected": -2.4048311710357666,
      "step": 401
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.5220733012068854,
      "learning_rate": 9.330697607081995e-06,
      "logits/chosen": -1.0386543273925781,
      "logits/rejected": -0.9969691634178162,
      "logps/chosen": -153.49130249023438,
      "logps/rejected": -399.115966796875,
      "loss": 0.0874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5737031698226929,
      "rewards/margins": 4.80222749710083,
      "rewards/rejected": -4.228524208068848,
      "step": 402
    },
    {
      "epoch": 2.6866666666666665,
      "grad_norm": 1.9257208329138362,
      "learning_rate": 9.287587785125364e-06,
      "logits/chosen": -0.9611701369285583,
      "logits/rejected": -0.8130849003791809,
      "logps/chosen": -208.58535766601562,
      "logps/rejected": -368.5440368652344,
      "loss": 0.1194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40204280614852905,
      "rewards/margins": 3.6880786418914795,
      "rewards/rejected": -3.2860357761383057,
      "step": 403
    },
    {
      "epoch": 2.6933333333333334,
      "grad_norm": 2.54736519993159,
      "learning_rate": 9.244491266536742e-06,
      "logits/chosen": -0.7748993635177612,
      "logits/rejected": -0.9104601740837097,
      "logps/chosen": -279.0865478515625,
      "logps/rejected": -311.4823913574219,
      "loss": 0.2249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09304207563400269,
      "rewards/margins": 2.4161009788513184,
      "rewards/rejected": -2.323058605194092,
      "step": 404
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.3422792059196504,
      "learning_rate": 9.20140885608734e-06,
      "logits/chosen": -0.9096401333808899,
      "logits/rejected": -0.7322660088539124,
      "logps/chosen": -247.6950225830078,
      "logps/rejected": -479.19970703125,
      "loss": 0.0932,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4378790557384491,
      "rewards/margins": 4.499070644378662,
      "rewards/rejected": -4.061191558837891,
      "step": 405
    },
    {
      "epoch": 2.7066666666666666,
      "grad_norm": 2.5389082172176534,
      "learning_rate": 9.158341358284939e-06,
      "logits/chosen": -0.9238355755805969,
      "logits/rejected": -0.8363991975784302,
      "logps/chosen": -243.9571533203125,
      "logps/rejected": -338.591552734375,
      "loss": 0.2584,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4940490126609802,
      "rewards/margins": 2.2324676513671875,
      "rewards/rejected": -1.7384189367294312,
      "step": 406
    },
    {
      "epoch": 2.7133333333333334,
      "grad_norm": 1.1889183708993853,
      "learning_rate": 9.115289577358826e-06,
      "logits/chosen": -1.00239098072052,
      "logits/rejected": -1.0078614950180054,
      "logps/chosen": -304.5992736816406,
      "logps/rejected": -349.3891296386719,
      "loss": 0.1089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6640552282333374,
      "rewards/margins": 3.6219546794891357,
      "rewards/rejected": -2.957899808883667,
      "step": 407
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 2.3997013104857694,
      "learning_rate": 9.072254317244802e-06,
      "logits/chosen": -0.9546631574630737,
      "logits/rejected": -0.976894199848175,
      "logps/chosen": -257.74566650390625,
      "logps/rejected": -255.8689727783203,
      "loss": 0.2366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7311276197433472,
      "rewards/margins": 2.230529308319092,
      "rewards/rejected": -1.499401569366455,
      "step": 408
    },
    {
      "epoch": 2.7266666666666666,
      "grad_norm": 2.571263285274798,
      "learning_rate": 9.029236381570162e-06,
      "logits/chosen": -0.9276173710823059,
      "logits/rejected": -0.9864866733551025,
      "logps/chosen": -227.1956024169922,
      "logps/rejected": -258.8590087890625,
      "loss": 0.2938,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4201553761959076,
      "rewards/margins": 2.165410041809082,
      "rewards/rejected": -1.7452547550201416,
      "step": 409
    },
    {
      "epoch": 2.7333333333333334,
      "grad_norm": 2.6100589974995714,
      "learning_rate": 8.986236573638697e-06,
      "logits/chosen": -1.0845900774002075,
      "logits/rejected": -1.080655574798584,
      "logps/chosen": -254.36509704589844,
      "logps/rejected": -359.6160888671875,
      "loss": 0.2482,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.10475364327430725,
      "rewards/margins": 3.110454559326172,
      "rewards/rejected": -3.0057005882263184,
      "step": 410
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.328941867559846,
      "learning_rate": 8.94325569641568e-06,
      "logits/chosen": -0.7111591696739197,
      "logits/rejected": -0.8968753218650818,
      "logps/chosen": -210.22183227539062,
      "logps/rejected": -302.452392578125,
      "loss": 0.2112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4160265028476715,
      "rewards/margins": 2.642444372177124,
      "rewards/rejected": -2.2264180183410645,
      "step": 411
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 1.4218563875091041,
      "learning_rate": 8.900294552512878e-06,
      "logits/chosen": -0.9070506691932678,
      "logits/rejected": -0.9013416171073914,
      "logps/chosen": -298.815185546875,
      "logps/rejected": -426.854248046875,
      "loss": 0.1067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9640493392944336,
      "rewards/margins": 3.922219753265381,
      "rewards/rejected": -2.9581704139709473,
      "step": 412
    },
    {
      "epoch": 2.7533333333333334,
      "grad_norm": 1.7457087901022004,
      "learning_rate": 8.85735394417356e-06,
      "logits/chosen": -1.0514203310012817,
      "logits/rejected": -0.9958735108375549,
      "logps/chosen": -235.55892944335938,
      "logps/rejected": -495.3336181640625,
      "loss": 0.143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7310327291488647,
      "rewards/margins": 3.1777923107147217,
      "rewards/rejected": -2.4467597007751465,
      "step": 413
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.5636626686208261,
      "learning_rate": 8.81443467325753e-06,
      "logits/chosen": -1.0722488164901733,
      "logits/rejected": -0.9761641621589661,
      "logps/chosen": -156.19940185546875,
      "logps/rejected": -351.2476501464844,
      "loss": 0.0688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7004923224449158,
      "rewards/margins": 3.1501481533050537,
      "rewards/rejected": -2.449655771255493,
      "step": 414
    },
    {
      "epoch": 2.7666666666666666,
      "grad_norm": 2.1173953696818866,
      "learning_rate": 8.771537541226139e-06,
      "logits/chosen": -1.0309184789657593,
      "logits/rejected": -1.034263014793396,
      "logps/chosen": -132.14508056640625,
      "logps/rejected": -266.1148986816406,
      "loss": 0.2488,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45742499828338623,
      "rewards/margins": 2.924525260925293,
      "rewards/rejected": -2.467100143432617,
      "step": 415
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 1.4141003092563755,
      "learning_rate": 8.728663349127315e-06,
      "logits/chosen": -0.7901713252067566,
      "logits/rejected": -1.0030896663665771,
      "logps/chosen": -278.7335205078125,
      "logps/rejected": -222.7444610595703,
      "loss": 0.1622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8453558683395386,
      "rewards/margins": 3.0900044441223145,
      "rewards/rejected": -2.2446486949920654,
      "step": 416
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 2.381298046678634,
      "learning_rate": 8.68581289758063e-06,
      "logits/chosen": -0.929063618183136,
      "logits/rejected": -0.8832512497901917,
      "logps/chosen": -209.83843994140625,
      "logps/rejected": -381.673583984375,
      "loss": 0.1504,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6939891576766968,
      "rewards/margins": 3.227259874343872,
      "rewards/rejected": -2.5332705974578857,
      "step": 417
    },
    {
      "epoch": 2.7866666666666666,
      "grad_norm": 1.6467236472836209,
      "learning_rate": 8.642986986762315e-06,
      "logits/chosen": -0.9345959424972534,
      "logits/rejected": -1.0408138036727905,
      "logps/chosen": -152.12371826171875,
      "logps/rejected": -252.38723754882812,
      "loss": 0.1673,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.862220287322998,
      "rewards/margins": 3.3667092323303223,
      "rewards/rejected": -2.504488945007324,
      "step": 418
    },
    {
      "epoch": 2.7933333333333334,
      "grad_norm": 1.8818793299234646,
      "learning_rate": 8.600186416390343e-06,
      "logits/chosen": -0.8570245504379272,
      "logits/rejected": -0.9937168955802917,
      "logps/chosen": -378.2920837402344,
      "logps/rejected": -284.7091064453125,
      "loss": 0.1694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5926740765571594,
      "rewards/margins": 2.7547154426574707,
      "rewards/rejected": -2.162040948867798,
      "step": 419
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.238876822759625,
      "learning_rate": 8.55741198570949e-06,
      "logits/chosen": -0.7845361232757568,
      "logits/rejected": -0.8259207606315613,
      "logps/chosen": -237.1519012451172,
      "logps/rejected": -312.56231689453125,
      "loss": 0.1706,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.461296021938324,
      "rewards/margins": 3.1683526039123535,
      "rewards/rejected": -2.7070565223693848,
      "step": 420
    },
    {
      "epoch": 2.8066666666666666,
      "grad_norm": 1.2558847665073816,
      "learning_rate": 8.514664493476402e-06,
      "logits/chosen": -1.1014158725738525,
      "logits/rejected": -1.1020134687423706,
      "logps/chosen": -209.91329956054688,
      "logps/rejected": -263.38153076171875,
      "loss": 0.1218,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6481280326843262,
      "rewards/margins": 3.3836143016815186,
      "rewards/rejected": -2.7354860305786133,
      "step": 421
    },
    {
      "epoch": 2.8133333333333335,
      "grad_norm": 1.1866204869646524,
      "learning_rate": 8.471944737944687e-06,
      "logits/chosen": -0.9991598129272461,
      "logits/rejected": -1.0360409021377563,
      "logps/chosen": -222.24038696289062,
      "logps/rejected": -296.6458740234375,
      "loss": 0.0766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5657109022140503,
      "rewards/margins": 4.007547855377197,
      "rewards/rejected": -3.4418373107910156,
      "step": 422
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.8313474038785885,
      "learning_rate": 8.429253516850006e-06,
      "logits/chosen": -1.1277402639389038,
      "logits/rejected": -1.1096125841140747,
      "logps/chosen": -179.78875732421875,
      "logps/rejected": -250.21771240234375,
      "loss": 0.0725,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9080906510353088,
      "rewards/margins": 3.5872859954833984,
      "rewards/rejected": -2.6791954040527344,
      "step": 423
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 1.119654778681935,
      "learning_rate": 8.386591627395174e-06,
      "logits/chosen": -1.0020147562026978,
      "logits/rejected": -0.9834933280944824,
      "logps/chosen": -242.7220916748047,
      "logps/rejected": -426.616943359375,
      "loss": 0.0715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6889781951904297,
      "rewards/margins": 3.351534366607666,
      "rewards/rejected": -2.6625561714172363,
      "step": 424
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 1.5855477140640102,
      "learning_rate": 8.343959866235282e-06,
      "logits/chosen": -0.79055255651474,
      "logits/rejected": -0.9712201356887817,
      "logps/chosen": -414.987060546875,
      "logps/rejected": -373.3348083496094,
      "loss": 0.0913,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.901826798915863,
      "rewards/margins": 4.056148529052734,
      "rewards/rejected": -3.1543216705322266,
      "step": 425
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.9462011904707188,
      "learning_rate": 8.30135902946281e-06,
      "logits/chosen": -0.9810836911201477,
      "logits/rejected": -0.9122459888458252,
      "logps/chosen": -177.19931030273438,
      "logps/rejected": -358.23626708984375,
      "loss": 0.0449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6310042142868042,
      "rewards/margins": 4.267553329467773,
      "rewards/rejected": -3.6365487575531006,
      "step": 426
    },
    {
      "epoch": 2.8466666666666667,
      "grad_norm": 1.1887217811740978,
      "learning_rate": 8.25878991259276e-06,
      "logits/chosen": -0.7901370525360107,
      "logits/rejected": -1.0229986906051636,
      "logps/chosen": -458.1968994140625,
      "logps/rejected": -301.35614013671875,
      "loss": 0.1006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0124537944793701,
      "rewards/margins": 3.3624210357666016,
      "rewards/rejected": -2.3499674797058105,
      "step": 427
    },
    {
      "epoch": 2.8533333333333335,
      "grad_norm": 2.447180281457836,
      "learning_rate": 8.216253310547824e-06,
      "logits/chosen": -0.5687764883041382,
      "logits/rejected": -0.8878697752952576,
      "logps/chosen": -339.7289123535156,
      "logps/rejected": -292.1203308105469,
      "loss": 0.1982,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47393786907196045,
      "rewards/margins": 2.0858139991760254,
      "rewards/rejected": -1.6118762493133545,
      "step": 428
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5065690883464544,
      "learning_rate": 8.173750017643504e-06,
      "logits/chosen": -0.8701579570770264,
      "logits/rejected": -0.9803513288497925,
      "logps/chosen": -199.812255859375,
      "logps/rejected": -413.30224609375,
      "loss": 0.0286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7277772426605225,
      "rewards/margins": 4.469362258911133,
      "rewards/rejected": -3.7415850162506104,
      "step": 429
    },
    {
      "epoch": 2.8666666666666667,
      "grad_norm": 1.2725600981994358,
      "learning_rate": 8.1312808275733e-06,
      "logits/chosen": -1.0207293033599854,
      "logits/rejected": -1.0540896654129028,
      "logps/chosen": -142.5576934814453,
      "logps/rejected": -385.5304260253906,
      "loss": 0.051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4222002625465393,
      "rewards/margins": 3.753697156906128,
      "rewards/rejected": -3.3314971923828125,
      "step": 430
    },
    {
      "epoch": 2.873333333333333,
      "grad_norm": 2.129142762091633,
      "learning_rate": 8.0888465333939e-06,
      "logits/chosen": -0.9763611555099487,
      "logits/rejected": -1.0556546449661255,
      "logps/chosen": -220.168701171875,
      "logps/rejected": -226.15704345703125,
      "loss": 0.2194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6914367079734802,
      "rewards/margins": 2.3986423015594482,
      "rewards/rejected": -1.7072055339813232,
      "step": 431
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.1723871256458192,
      "learning_rate": 8.046447927510335e-06,
      "logits/chosen": -0.8809834122657776,
      "logits/rejected": -0.9632728099822998,
      "logps/chosen": -260.7187805175781,
      "logps/rejected": -302.88336181640625,
      "loss": 0.0835,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.529070258140564,
      "rewards/margins": 3.776076316833496,
      "rewards/rejected": -3.2470059394836426,
      "step": 432
    },
    {
      "epoch": 2.8866666666666667,
      "grad_norm": 1.687818285277604,
      "learning_rate": 8.004085801661227e-06,
      "logits/chosen": -0.953140914440155,
      "logits/rejected": -1.0093685388565063,
      "logps/chosen": -354.213134765625,
      "logps/rejected": -248.31027221679688,
      "loss": 0.1292,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4903690814971924,
      "rewards/margins": 3.0143418312072754,
      "rewards/rejected": -2.523972749710083,
      "step": 433
    },
    {
      "epoch": 2.8933333333333335,
      "grad_norm": 1.005004994014649,
      "learning_rate": 7.961760946903964e-06,
      "logits/chosen": -1.010575771331787,
      "logits/rejected": -0.9668616056442261,
      "logps/chosen": -256.66650390625,
      "logps/rejected": -348.0040283203125,
      "loss": 0.0612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3551578521728516,
      "rewards/margins": 3.4548487663269043,
      "rewards/rejected": -2.0996909141540527,
      "step": 434
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.5046789785046781,
      "learning_rate": 7.919474153599948e-06,
      "logits/chosen": -1.0691115856170654,
      "logits/rejected": -1.0684418678283691,
      "logps/chosen": -197.5460205078125,
      "logps/rejected": -326.19415283203125,
      "loss": 0.0861,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4616689682006836,
      "rewards/margins": 3.4040465354919434,
      "rewards/rejected": -2.9423775672912598,
      "step": 435
    },
    {
      "epoch": 2.9066666666666667,
      "grad_norm": 1.524851529132534,
      "learning_rate": 7.87722621139984e-06,
      "logits/chosen": -1.1609444618225098,
      "logits/rejected": -1.1416553258895874,
      "logps/chosen": -166.85165405273438,
      "logps/rejected": -238.60665893554688,
      "loss": 0.1975,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6258127093315125,
      "rewards/margins": 3.421293258666992,
      "rewards/rejected": -2.795480489730835,
      "step": 436
    },
    {
      "epoch": 2.913333333333333,
      "grad_norm": 0.6094526583754503,
      "learning_rate": 7.835017909228801e-06,
      "logits/chosen": -1.0279523134231567,
      "logits/rejected": -1.0445821285247803,
      "logps/chosen": -218.7528076171875,
      "logps/rejected": -278.43511962890625,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7276037335395813,
      "rewards/margins": 3.7755837440490723,
      "rewards/rejected": -3.047980308532715,
      "step": 437
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.959746824894726,
      "learning_rate": 7.792850035271768e-06,
      "logits/chosen": -0.9439099431037903,
      "logits/rejected": -1.011117935180664,
      "logps/chosen": -290.6341247558594,
      "logps/rejected": -296.53472900390625,
      "loss": 0.052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.870761513710022,
      "rewards/margins": 3.738567352294922,
      "rewards/rejected": -2.8678059577941895,
      "step": 438
    },
    {
      "epoch": 2.9266666666666667,
      "grad_norm": 2.194111342707566,
      "learning_rate": 7.750723376958735e-06,
      "logits/chosen": -1.0128288269042969,
      "logits/rejected": -1.1330405473709106,
      "logps/chosen": -337.25677490234375,
      "logps/rejected": -246.6821746826172,
      "loss": 0.1497,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8957396149635315,
      "rewards/margins": 3.361057758331299,
      "rewards/rejected": -2.465318202972412,
      "step": 439
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 1.4289560583578242,
      "learning_rate": 7.708638720950043e-06,
      "logits/chosen": -0.9012186527252197,
      "logits/rejected": -1.020687222480774,
      "logps/chosen": -281.168701171875,
      "logps/rejected": -315.0910949707031,
      "loss": 0.144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.795781135559082,
      "rewards/margins": 3.020669937133789,
      "rewards/rejected": -2.224888801574707,
      "step": 440
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.0264259561106615,
      "learning_rate": 7.666596853121702e-06,
      "logits/chosen": -1.0441226959228516,
      "logits/rejected": -1.0765548944473267,
      "logps/chosen": -217.774169921875,
      "logps/rejected": -295.84423828125,
      "loss": 0.0512,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31582438945770264,
      "rewards/margins": 3.9853506088256836,
      "rewards/rejected": -3.6695261001586914,
      "step": 441
    },
    {
      "epoch": 2.9466666666666668,
      "grad_norm": 1.3540109495962678,
      "learning_rate": 7.624598558550707e-06,
      "logits/chosen": -0.7924853563308716,
      "logits/rejected": -0.9591290354728699,
      "logps/chosen": -321.4985656738281,
      "logps/rejected": -353.5683898925781,
      "loss": 0.0569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7628164887428284,
      "rewards/margins": 3.9928016662597656,
      "rewards/rejected": -3.229985237121582,
      "step": 442
    },
    {
      "epoch": 2.953333333333333,
      "grad_norm": 1.335726135666158,
      "learning_rate": 7.5826446215003695e-06,
      "logits/chosen": -0.9089404940605164,
      "logits/rejected": -0.9920542240142822,
      "logps/chosen": -261.9559326171875,
      "logps/rejected": -345.91937255859375,
      "loss": 0.1121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6932961940765381,
      "rewards/margins": 3.2435402870178223,
      "rewards/rejected": -2.550243854522705,
      "step": 443
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.2456371941857225,
      "learning_rate": 7.5407358254056995e-06,
      "logits/chosen": -0.8949427008628845,
      "logits/rejected": -0.9447086453437805,
      "logps/chosen": -185.2909393310547,
      "logps/rejected": -285.3411865234375,
      "loss": 0.0741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4277511239051819,
      "rewards/margins": 3.5081515312194824,
      "rewards/rejected": -3.0804004669189453,
      "step": 444
    },
    {
      "epoch": 2.966666666666667,
      "grad_norm": 1.9440349382274986,
      "learning_rate": 7.4988729528587445e-06,
      "logits/chosen": -0.8774825930595398,
      "logits/rejected": -1.093194842338562,
      "logps/chosen": -319.3574523925781,
      "logps/rejected": -278.5577392578125,
      "loss": 0.1565,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.9252243041992188,
      "rewards/margins": 3.200620651245117,
      "rewards/rejected": -2.2753963470458984,
      "step": 445
    },
    {
      "epoch": 2.9733333333333336,
      "grad_norm": 2.0539450809004665,
      "learning_rate": 7.45705678559399e-06,
      "logits/chosen": -1.0863837003707886,
      "logits/rejected": -1.011483907699585,
      "logps/chosen": -148.1922149658203,
      "logps/rejected": -331.0424499511719,
      "loss": 0.1027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6377609968185425,
      "rewards/margins": 4.460396766662598,
      "rewards/rejected": -3.8226356506347656,
      "step": 446
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.8791534832183936,
      "learning_rate": 7.415288104473774e-06,
      "logits/chosen": -0.98452228307724,
      "logits/rejected": -0.9807568788528442,
      "logps/chosen": -208.03659057617188,
      "logps/rejected": -376.8779296875,
      "loss": 0.1125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19180458784103394,
      "rewards/margins": 3.931551933288574,
      "rewards/rejected": -3.7397472858428955,
      "step": 447
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 1.3957314335460898,
      "learning_rate": 7.373567689473683e-06,
      "logits/chosen": -1.149192214012146,
      "logits/rejected": -1.0289764404296875,
      "logps/chosen": -233.20211791992188,
      "logps/rejected": -348.65045166015625,
      "loss": 0.0804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24192595481872559,
      "rewards/margins": 3.612595796585083,
      "rewards/rejected": -3.3706698417663574,
      "step": 448
    },
    {
      "epoch": 2.993333333333333,
      "grad_norm": 1.7044780151435412,
      "learning_rate": 7.3318963196679904e-06,
      "logits/chosen": -0.8415835499763489,
      "logits/rejected": -1.0521411895751953,
      "logps/chosen": -239.9453125,
      "logps/rejected": -216.4369659423828,
      "loss": 0.2199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6494629383087158,
      "rewards/margins": 3.0952162742614746,
      "rewards/rejected": -2.445753574371338,
      "step": 449
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.415508047334867,
      "learning_rate": 7.290274773215131e-06,
      "logits/chosen": -0.9732718467712402,
      "logits/rejected": -0.9409324526786804,
      "logps/chosen": -190.34249877929688,
      "logps/rejected": -317.03955078125,
      "loss": 0.2075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6198958158493042,
      "rewards/margins": 2.693347454071045,
      "rewards/rejected": -2.0734517574310303,
      "step": 450
    },
    {
      "epoch": 3.006666666666667,
      "grad_norm": 1.505171998673311,
      "learning_rate": 7.248703827343142e-06,
      "logits/chosen": -0.8954468965530396,
      "logits/rejected": -1.0434902906417847,
      "logps/chosen": -326.5294189453125,
      "logps/rejected": -312.5806884765625,
      "loss": 0.1198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5994951128959656,
      "rewards/margins": 2.4704995155334473,
      "rewards/rejected": -1.871004343032837,
      "step": 451
    },
    {
      "epoch": 3.013333333333333,
      "grad_norm": 1.4014622034698319,
      "learning_rate": 7.207184258335163e-06,
      "logits/chosen": -1.1372871398925781,
      "logits/rejected": -1.0990550518035889,
      "logps/chosen": -206.36468505859375,
      "logps/rejected": -321.4429016113281,
      "loss": 0.1238,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39565542340278625,
      "rewards/margins": 3.142733573913574,
      "rewards/rejected": -2.7470781803131104,
      "step": 452
    },
    {
      "epoch": 3.02,
      "grad_norm": 1.1413340520251172,
      "learning_rate": 7.1657168415149396e-06,
      "logits/chosen": -1.0928325653076172,
      "logits/rejected": -0.952228844165802,
      "logps/chosen": -202.6590118408203,
      "logps/rejected": -423.25823974609375,
      "loss": 0.0564,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8064114451408386,
      "rewards/margins": 4.236926078796387,
      "rewards/rejected": -3.4305148124694824,
      "step": 453
    },
    {
      "epoch": 3.026666666666667,
      "grad_norm": 1.6497057334440006,
      "learning_rate": 7.124302351232337e-06,
      "logits/chosen": -0.8660423755645752,
      "logits/rejected": -0.894270658493042,
      "logps/chosen": -184.48785400390625,
      "logps/rejected": -256.5433349609375,
      "loss": 0.2003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4430272579193115,
      "rewards/margins": 2.9006335735321045,
      "rewards/rejected": -2.457606077194214,
      "step": 454
    },
    {
      "epoch": 3.033333333333333,
      "grad_norm": 1.665960170095713,
      "learning_rate": 7.0829415608489e-06,
      "logits/chosen": -0.8196699619293213,
      "logits/rejected": -0.9694680571556091,
      "logps/chosen": -286.78106689453125,
      "logps/rejected": -366.03302001953125,
      "loss": 0.1059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944878458976746,
      "rewards/margins": 3.341721773147583,
      "rewards/rejected": -2.7472338676452637,
      "step": 455
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.3587077904034641,
      "learning_rate": 7.041635242723386e-06,
      "logits/chosen": -1.0454678535461426,
      "logits/rejected": -1.0323748588562012,
      "logps/chosen": -186.95639038085938,
      "logps/rejected": -345.2589416503906,
      "loss": 0.1132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43699413537979126,
      "rewards/margins": 4.328882217407227,
      "rewards/rejected": -3.89188814163208,
      "step": 456
    },
    {
      "epoch": 3.046666666666667,
      "grad_norm": 1.4965776502535795,
      "learning_rate": 7.000384168197354e-06,
      "logits/chosen": -0.8437698483467102,
      "logits/rejected": -0.9441795945167542,
      "logps/chosen": -398.67999267578125,
      "logps/rejected": -305.46826171875,
      "loss": 0.12,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5500491857528687,
      "rewards/margins": 3.113118886947632,
      "rewards/rejected": -2.5630695819854736,
      "step": 457
    },
    {
      "epoch": 3.0533333333333332,
      "grad_norm": 0.1308485994599663,
      "learning_rate": 6.9591891075807705e-06,
      "logits/chosen": -1.1250461339950562,
      "logits/rejected": -0.9393574595451355,
      "logps/chosen": -150.69268798828125,
      "logps/rejected": -438.4393310546875,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6745874285697937,
      "rewards/margins": 5.9976911544799805,
      "rewards/rejected": -5.323103427886963,
      "step": 458
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.6624344559401693,
      "learning_rate": 6.918050830137608e-06,
      "logits/chosen": -0.8781996369361877,
      "logits/rejected": -0.9693660140037537,
      "logps/chosen": -249.81781005859375,
      "logps/rejected": -344.913330078125,
      "loss": 0.0393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43119704723358154,
      "rewards/margins": 4.6903605461120605,
      "rewards/rejected": -4.259162902832031,
      "step": 459
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 0.7183374796730739,
      "learning_rate": 6.876970104071483e-06,
      "logits/chosen": -0.9309561252593994,
      "logits/rejected": -0.931992769241333,
      "logps/chosen": -209.64512634277344,
      "logps/rejected": -410.97125244140625,
      "loss": 0.034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7625541090965271,
      "rewards/margins": 4.748249053955078,
      "rewards/rejected": -3.9856951236724854,
      "step": 460
    },
    {
      "epoch": 3.0733333333333333,
      "grad_norm": 1.4771776482189212,
      "learning_rate": 6.8359476965113295e-06,
      "logits/chosen": -0.9307462573051453,
      "logits/rejected": -0.9804039001464844,
      "logps/chosen": -244.0591583251953,
      "logps/rejected": -286.91064453125,
      "loss": 0.1253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1405048668384552,
      "rewards/margins": 3.503896713256836,
      "rewards/rejected": -3.363391876220703,
      "step": 461
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.268558597322906,
      "learning_rate": 6.7949843734970475e-06,
      "logits/chosen": -1.0144983530044556,
      "logits/rejected": -1.0948524475097656,
      "logps/chosen": -293.76422119140625,
      "logps/rejected": -255.6675262451172,
      "loss": 0.3455,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.14909881353378296,
      "rewards/margins": 2.457090377807617,
      "rewards/rejected": -2.3079915046691895,
      "step": 462
    },
    {
      "epoch": 3.086666666666667,
      "grad_norm": 2.8033690687601505,
      "learning_rate": 6.754080899965208e-06,
      "logits/chosen": -0.9358993768692017,
      "logits/rejected": -1.0458108186721802,
      "logps/chosen": -267.56732177734375,
      "logps/rejected": -255.0804443359375,
      "loss": 0.2134,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5992769002914429,
      "rewards/margins": 3.1074275970458984,
      "rewards/rejected": -2.508150577545166,
      "step": 463
    },
    {
      "epoch": 3.0933333333333333,
      "grad_norm": 1.1641325961520212,
      "learning_rate": 6.713238039734788e-06,
      "logits/chosen": -1.0074411630630493,
      "logits/rejected": -1.0771325826644897,
      "logps/chosen": -325.7277526855469,
      "logps/rejected": -332.9766540527344,
      "loss": 0.0664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2597194910049438,
      "rewards/margins": 4.053564548492432,
      "rewards/rejected": -2.7938451766967773,
      "step": 464
    },
    {
      "epoch": 3.1,
      "grad_norm": 1.294805875389762,
      "learning_rate": 6.67245655549287e-06,
      "logits/chosen": -0.9806922674179077,
      "logits/rejected": -1.0138938426971436,
      "logps/chosen": -268.4769592285156,
      "logps/rejected": -385.6051025390625,
      "loss": 0.0813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1000022888183594,
      "rewards/margins": 4.793936252593994,
      "rewards/rejected": -3.6939339637756348,
      "step": 465
    },
    {
      "epoch": 3.1066666666666665,
      "grad_norm": 2.1455723748891464,
      "learning_rate": 6.631737208780433e-06,
      "logits/chosen": -1.0222642421722412,
      "logits/rejected": -0.975836455821991,
      "logps/chosen": -177.99713134765625,
      "logps/rejected": -345.7386474609375,
      "loss": 0.1692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34704479575157166,
      "rewards/margins": 3.4106054306030273,
      "rewards/rejected": -3.0635604858398438,
      "step": 466
    },
    {
      "epoch": 3.1133333333333333,
      "grad_norm": 1.519435536329218,
      "learning_rate": 6.5910807599781135e-06,
      "logits/chosen": -0.9983019828796387,
      "logits/rejected": -0.948081374168396,
      "logps/chosen": -164.35760498046875,
      "logps/rejected": -328.6733093261719,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4480684995651245,
      "rewards/margins": 4.442504405975342,
      "rewards/rejected": -3.9944357872009277,
      "step": 467
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.7002282470019052,
      "learning_rate": 6.550487968292013e-06,
      "logits/chosen": -0.9079784154891968,
      "logits/rejected": -1.0458592176437378,
      "logps/chosen": -298.8531494140625,
      "logps/rejected": -218.23516845703125,
      "loss": 0.271,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 1.097403645515442,
      "rewards/margins": 2.07560396194458,
      "rewards/rejected": -0.9782004952430725,
      "step": 468
    },
    {
      "epoch": 3.1266666666666665,
      "grad_norm": 1.2801781800052856,
      "learning_rate": 6.509959591739522e-06,
      "logits/chosen": -0.9430997967720032,
      "logits/rejected": -1.033347249031067,
      "logps/chosen": -257.18145751953125,
      "logps/rejected": -316.6535949707031,
      "loss": 0.0702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6508781909942627,
      "rewards/margins": 3.3875465393066406,
      "rewards/rejected": -2.736668348312378,
      "step": 469
    },
    {
      "epoch": 3.1333333333333333,
      "grad_norm": 2.290588807448502,
      "learning_rate": 6.469496387135158e-06,
      "logits/chosen": -0.8107923269271851,
      "logits/rejected": -0.7344027757644653,
      "logps/chosen": -309.93072509765625,
      "logps/rejected": -352.60418701171875,
      "loss": 0.2303,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6842978596687317,
      "rewards/margins": 1.9757131338119507,
      "rewards/rejected": -1.2914153337478638,
      "step": 470
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.1650845949623483,
      "learning_rate": 6.429099110076436e-06,
      "logits/chosen": -1.0661495923995972,
      "logits/rejected": -1.1044707298278809,
      "logps/chosen": -216.61441040039062,
      "logps/rejected": -320.62847900390625,
      "loss": 0.083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39877456426620483,
      "rewards/margins": 3.990933895111084,
      "rewards/rejected": -3.5921592712402344,
      "step": 471
    },
    {
      "epoch": 3.1466666666666665,
      "grad_norm": 0.9725134258275123,
      "learning_rate": 6.388768514929768e-06,
      "logits/chosen": -0.9066020846366882,
      "logits/rejected": -1.029130220413208,
      "logps/chosen": -342.08831787109375,
      "logps/rejected": -325.4056396484375,
      "loss": 0.0644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.572517991065979,
      "rewards/margins": 3.8483786582946777,
      "rewards/rejected": -3.275860548019409,
      "step": 472
    },
    {
      "epoch": 3.1533333333333333,
      "grad_norm": 2.0706022239788813,
      "learning_rate": 6.3485053548163644e-06,
      "logits/chosen": -0.8619081974029541,
      "logits/rejected": -0.9956393837928772,
      "logps/chosen": -291.12396240234375,
      "logps/rejected": -344.2124328613281,
      "loss": 0.105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44817638397216797,
      "rewards/margins": 3.5969398021698,
      "rewards/rejected": -3.148763656616211,
      "step": 473
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.158654213560395,
      "learning_rate": 6.308310381598168e-06,
      "logits/chosen": -0.9885073304176331,
      "logits/rejected": -0.8707411289215088,
      "logps/chosen": -232.719970703125,
      "logps/rejected": -367.341796875,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8986992239952087,
      "rewards/margins": 3.714933395385742,
      "rewards/rejected": -2.8162341117858887,
      "step": 474
    },
    {
      "epoch": 3.1666666666666665,
      "grad_norm": 2.3253888943199716,
      "learning_rate": 6.2681843458638345e-06,
      "logits/chosen": -0.9637610912322998,
      "logits/rejected": -1.0343563556671143,
      "logps/chosen": -228.84609985351562,
      "logps/rejected": -245.41836547851562,
      "loss": 0.1977,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41890543699264526,
      "rewards/margins": 3.251943826675415,
      "rewards/rejected": -2.833038330078125,
      "step": 475
    },
    {
      "epoch": 3.1733333333333333,
      "grad_norm": 1.822585557203564,
      "learning_rate": 6.2281279969146855e-06,
      "logits/chosen": -0.9386951327323914,
      "logits/rejected": -0.9099481701850891,
      "logps/chosen": -236.45364379882812,
      "logps/rejected": -338.61712646484375,
      "loss": 0.1122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3977992832660675,
      "rewards/margins": 3.286590099334717,
      "rewards/rejected": -2.888791084289551,
      "step": 476
    },
    {
      "epoch": 3.18,
      "grad_norm": 1.2700259609272317,
      "learning_rate": 6.18814208275075e-06,
      "logits/chosen": -0.8575403690338135,
      "logits/rejected": -1.0901380777359009,
      "logps/chosen": -283.4534912109375,
      "logps/rejected": -256.8118896484375,
      "loss": 0.1129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8202441930770874,
      "rewards/margins": 3.8892037868499756,
      "rewards/rejected": -3.0689594745635986,
      "step": 477
    },
    {
      "epoch": 3.1866666666666665,
      "grad_norm": 1.9766571263516746,
      "learning_rate": 6.148227350056763e-06,
      "logits/chosen": -1.0278668403625488,
      "logits/rejected": -1.0727163553237915,
      "logps/chosen": -202.52667236328125,
      "logps/rejected": -271.378173828125,
      "loss": 0.1299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4324587285518646,
      "rewards/margins": 3.164318084716797,
      "rewards/rejected": -2.7318592071533203,
      "step": 478
    },
    {
      "epoch": 3.1933333333333334,
      "grad_norm": 1.6320165126750534,
      "learning_rate": 6.10838454418825e-06,
      "logits/chosen": -0.8487842679023743,
      "logits/rejected": -0.8503482341766357,
      "logps/chosen": -362.60711669921875,
      "logps/rejected": -398.74786376953125,
      "loss": 0.1167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7296854257583618,
      "rewards/margins": 3.1378331184387207,
      "rewards/rejected": -2.4081478118896484,
      "step": 479
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.9627746450280653,
      "learning_rate": 6.068614409157591e-06,
      "logits/chosen": -1.096614956855774,
      "logits/rejected": -1.1550850868225098,
      "logps/chosen": -261.8656005859375,
      "logps/rejected": -334.84197998046875,
      "loss": 0.0561,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5179116725921631,
      "rewards/margins": 3.844984531402588,
      "rewards/rejected": -3.327072858810425,
      "step": 480
    },
    {
      "epoch": 3.2066666666666666,
      "grad_norm": 2.572880259473776,
      "learning_rate": 6.0289176876201385e-06,
      "logits/chosen": -0.9788382649421692,
      "logits/rejected": -0.9403998851776123,
      "logps/chosen": -164.49586486816406,
      "logps/rejected": -386.70166015625,
      "loss": 0.1976,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03198099508881569,
      "rewards/margins": 3.122694253921509,
      "rewards/rejected": -3.0907135009765625,
      "step": 481
    },
    {
      "epoch": 3.2133333333333334,
      "grad_norm": 1.7101677682906065,
      "learning_rate": 5.989295120860334e-06,
      "logits/chosen": -0.9595001935958862,
      "logits/rejected": -1.013222098350525,
      "logps/chosen": -175.26611328125,
      "logps/rejected": -263.2503662109375,
      "loss": 0.1709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7308299541473389,
      "rewards/margins": 3.737807035446167,
      "rewards/rejected": -3.006977081298828,
      "step": 482
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.7080960292045693,
      "learning_rate": 5.94974744877789e-06,
      "logits/chosen": -1.2066659927368164,
      "logits/rejected": -1.043979525566101,
      "logps/chosen": -132.14181518554688,
      "logps/rejected": -415.76416015625,
      "loss": 0.0938,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08487427979707718,
      "rewards/margins": 3.937788248062134,
      "rewards/rejected": -3.8529136180877686,
      "step": 483
    },
    {
      "epoch": 3.2266666666666666,
      "grad_norm": 0.15743267576020387,
      "learning_rate": 5.910275409873942e-06,
      "logits/chosen": -1.0664432048797607,
      "logits/rejected": -1.0005608797073364,
      "logps/chosen": -153.9448699951172,
      "logps/rejected": -392.98956298828125,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37013116478919983,
      "rewards/margins": 5.327667236328125,
      "rewards/rejected": -4.957535743713379,
      "step": 484
    },
    {
      "epoch": 3.2333333333333334,
      "grad_norm": 1.7076787004470635,
      "learning_rate": 5.870879741237285e-06,
      "logits/chosen": -0.8859151005744934,
      "logits/rejected": -1.0063905715942383,
      "logps/chosen": -293.86712646484375,
      "logps/rejected": -334.6810302734375,
      "loss": 0.1061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6387114524841309,
      "rewards/margins": 3.7757411003112793,
      "rewards/rejected": -3.1370296478271484,
      "step": 485
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.1502003598558934,
      "learning_rate": 5.831561178530602e-06,
      "logits/chosen": -0.8225854635238647,
      "logits/rejected": -0.9299750328063965,
      "logps/chosen": -436.00250244140625,
      "logps/rejected": -356.23797607421875,
      "loss": 0.2307,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.975948691368103,
      "rewards/margins": 2.3401169776916504,
      "rewards/rejected": -1.364168405532837,
      "step": 486
    },
    {
      "epoch": 3.2466666666666666,
      "grad_norm": 1.8949674438457969,
      "learning_rate": 5.792320455976714e-06,
      "logits/chosen": -0.9673392176628113,
      "logits/rejected": -1.0438728332519531,
      "logps/chosen": -287.6850891113281,
      "logps/rejected": -294.5132751464844,
      "loss": 0.1078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4776715636253357,
      "rewards/margins": 3.253624439239502,
      "rewards/rejected": -2.7759528160095215,
      "step": 487
    },
    {
      "epoch": 3.2533333333333334,
      "grad_norm": 0.39688402150631275,
      "learning_rate": 5.753158306344882e-06,
      "logits/chosen": -0.8614728450775146,
      "logits/rejected": -1.092063069343567,
      "logps/chosen": -334.03521728515625,
      "logps/rejected": -300.0943908691406,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.092210292816162,
      "rewards/margins": 4.27589225769043,
      "rewards/rejected": -3.1836817264556885,
      "step": 488
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.9015159607507552,
      "learning_rate": 5.7140754609371255e-06,
      "logits/chosen": -0.8413945436477661,
      "logits/rejected": -0.9611708521842957,
      "logps/chosen": -184.01756286621094,
      "logps/rejected": -398.5062255859375,
      "loss": 0.1566,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.42252957820892334,
      "rewards/margins": 4.085245132446289,
      "rewards/rejected": -3.662715435028076,
      "step": 489
    },
    {
      "epoch": 3.2666666666666666,
      "grad_norm": 1.6271460374121434,
      "learning_rate": 5.675072649574551e-06,
      "logits/chosen": -1.028120517730713,
      "logits/rejected": -1.1204018592834473,
      "logps/chosen": -245.04132080078125,
      "logps/rejected": -304.4686279296875,
      "loss": 0.0715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32877135276794434,
      "rewards/margins": 4.39614725112915,
      "rewards/rejected": -4.067375659942627,
      "step": 490
    },
    {
      "epoch": 3.2733333333333334,
      "grad_norm": 2.3162434152426177,
      "learning_rate": 5.636150600583747e-06,
      "logits/chosen": -0.8559266328811646,
      "logits/rejected": -1.0773459672927856,
      "logps/chosen": -275.13836669921875,
      "logps/rejected": -295.0600280761719,
      "loss": 0.1246,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7368472814559937,
      "rewards/margins": 3.559426784515381,
      "rewards/rejected": -2.8225796222686768,
      "step": 491
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.8788077744311521,
      "learning_rate": 5.597310040783161e-06,
      "logits/chosen": -0.782217264175415,
      "logits/rejected": -1.0009602308273315,
      "logps/chosen": -303.008544921875,
      "logps/rejected": -433.018798828125,
      "loss": 0.0756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4759994149208069,
      "rewards/margins": 3.629075527191162,
      "rewards/rejected": -3.153076171875,
      "step": 492
    },
    {
      "epoch": 3.2866666666666666,
      "grad_norm": 1.8044145385934471,
      "learning_rate": 5.558551695469532e-06,
      "logits/chosen": -0.7463628649711609,
      "logits/rejected": -0.8941215872764587,
      "logps/chosen": -229.74716186523438,
      "logps/rejected": -316.94866943359375,
      "loss": 0.2039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5967209935188293,
      "rewards/margins": 3.257532835006714,
      "rewards/rejected": -2.66081166267395,
      "step": 493
    },
    {
      "epoch": 3.2933333333333334,
      "grad_norm": 1.2538902780816883,
      "learning_rate": 5.519876288404367e-06,
      "logits/chosen": -0.9012690782546997,
      "logits/rejected": -1.0608221292495728,
      "logps/chosen": -306.1047668457031,
      "logps/rejected": -363.91754150390625,
      "loss": 0.0612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8803908228874207,
      "rewards/margins": 4.935695171356201,
      "rewards/rejected": -4.055304527282715,
      "step": 494
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.9189801006706713,
      "learning_rate": 5.481284541800391e-06,
      "logits/chosen": -0.9856454133987427,
      "logits/rejected": -1.0136946439743042,
      "logps/chosen": -189.44374084472656,
      "logps/rejected": -348.6243896484375,
      "loss": 0.1262,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5382557511329651,
      "rewards/margins": 4.772942543029785,
      "rewards/rejected": -4.234686851501465,
      "step": 495
    },
    {
      "epoch": 3.3066666666666666,
      "grad_norm": 0.31222355058797746,
      "learning_rate": 5.44277717630809e-06,
      "logits/chosen": -1.0058943033218384,
      "logits/rejected": -1.0786209106445312,
      "logps/chosen": -313.7363586425781,
      "logps/rejected": -346.5152282714844,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.311687707901001,
      "rewards/margins": 4.4121503829956055,
      "rewards/rejected": -3.1004624366760254,
      "step": 496
    },
    {
      "epoch": 3.3133333333333335,
      "grad_norm": 1.9422813607673208,
      "learning_rate": 5.404354911002243e-06,
      "logits/chosen": -0.916793167591095,
      "logits/rejected": -1.1241527795791626,
      "logps/chosen": -174.73092651367188,
      "logps/rejected": -219.62582397460938,
      "loss": 0.231,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.677944540977478,
      "rewards/margins": 3.276041030883789,
      "rewards/rejected": -2.5980966091156006,
      "step": 497
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.401529356943356,
      "learning_rate": 5.3660184633684895e-06,
      "logits/chosen": -1.0219920873641968,
      "logits/rejected": -1.1732097864151,
      "logps/chosen": -443.642333984375,
      "logps/rejected": -247.798828125,
      "loss": 0.5002,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0562673956155777,
      "rewards/margins": 2.3607115745544434,
      "rewards/rejected": -2.3044443130493164,
      "step": 498
    },
    {
      "epoch": 3.3266666666666667,
      "grad_norm": 0.8518940691307468,
      "learning_rate": 5.3277685492899345e-06,
      "logits/chosen": -0.8708686232566833,
      "logits/rejected": -0.9712153673171997,
      "logps/chosen": -352.1627197265625,
      "logps/rejected": -363.8167724609375,
      "loss": 0.038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1117496490478516,
      "rewards/margins": 4.533029556274414,
      "rewards/rejected": -3.4212796688079834,
      "step": 499
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.20333543294333303,
      "learning_rate": 5.289605883033793e-06,
      "logits/chosen": -1.0757957696914673,
      "logits/rejected": -0.8899349570274353,
      "logps/chosen": -135.16085815429688,
      "logps/rejected": -382.69818115234375,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24993017315864563,
      "rewards/margins": 4.981203556060791,
      "rewards/rejected": -4.731273651123047,
      "step": 500
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.3017971729769986,
      "learning_rate": 5.251531177238029e-06,
      "logits/chosen": -0.7147606015205383,
      "logits/rejected": -0.9340819120407104,
      "logps/chosen": -349.6588134765625,
      "logps/rejected": -246.84921264648438,
      "loss": 0.1559,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8118658661842346,
      "rewards/margins": 2.723905563354492,
      "rewards/rejected": -1.9120397567749023,
      "step": 501
    },
    {
      "epoch": 3.3466666666666667,
      "grad_norm": 0.7715685834679578,
      "learning_rate": 5.213545142898061e-06,
      "logits/chosen": -0.9442683458328247,
      "logits/rejected": -1.1341091394424438,
      "logps/chosen": -321.76507568359375,
      "logps/rejected": -363.02618408203125,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4970618188381195,
      "rewards/margins": 4.664775848388672,
      "rewards/rejected": -4.1677141189575195,
      "step": 502
    },
    {
      "epoch": 3.3533333333333335,
      "grad_norm": 1.8198423638039254,
      "learning_rate": 5.175648489353493e-06,
      "logits/chosen": -0.8774457573890686,
      "logits/rejected": -1.057834506034851,
      "logps/chosen": -337.53863525390625,
      "logps/rejected": -255.4501953125,
      "loss": 0.1434,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7695289254188538,
      "rewards/margins": 3.182880401611328,
      "rewards/rejected": -2.413351535797119,
      "step": 503
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.5944902533457288,
      "learning_rate": 5.137841924274851e-06,
      "logits/chosen": -0.8889576196670532,
      "logits/rejected": -0.9372969269752502,
      "logps/chosen": -300.0392761230469,
      "logps/rejected": -319.05926513671875,
      "loss": 0.1009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5645172595977783,
      "rewards/margins": 3.182079553604126,
      "rewards/rejected": -2.6175622940063477,
      "step": 504
    },
    {
      "epoch": 3.3666666666666667,
      "grad_norm": 2.4913730546157926,
      "learning_rate": 5.100126153650379e-06,
      "logits/chosen": -0.9360241889953613,
      "logits/rejected": -1.132392406463623,
      "logps/chosen": -304.9928894042969,
      "logps/rejected": -258.45184326171875,
      "loss": 0.16,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7676132321357727,
      "rewards/margins": 3.4297854900360107,
      "rewards/rejected": -2.662172317504883,
      "step": 505
    },
    {
      "epoch": 3.3733333333333335,
      "grad_norm": 2.3850183501427358,
      "learning_rate": 5.0625018817728496e-06,
      "logits/chosen": -0.8382411003112793,
      "logits/rejected": -1.0289250612258911,
      "logps/chosen": -306.4400634765625,
      "logps/rejected": -314.3037109375,
      "loss": 0.1779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5366706252098083,
      "rewards/margins": 3.843566417694092,
      "rewards/rejected": -3.3068957328796387,
      "step": 506
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.7488742963379758,
      "learning_rate": 5.024969811226419e-06,
      "logits/chosen": -0.9087539911270142,
      "logits/rejected": -0.9794799089431763,
      "logps/chosen": -221.03878784179688,
      "logps/rejected": -323.84722900390625,
      "loss": 0.0373,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.793170154094696,
      "rewards/margins": 3.8703675270080566,
      "rewards/rejected": -3.077197551727295,
      "step": 507
    },
    {
      "epoch": 3.3866666666666667,
      "grad_norm": 3.310835366071232,
      "learning_rate": 4.98753064287351e-06,
      "logits/chosen": -0.8117639422416687,
      "logits/rejected": -0.7911534309387207,
      "logps/chosen": -319.41290283203125,
      "logps/rejected": -545.6727905273438,
      "loss": 0.2582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5206198692321777,
      "rewards/margins": 2.4445667266845703,
      "rewards/rejected": -1.9239468574523926,
      "step": 508
    },
    {
      "epoch": 3.3933333333333335,
      "grad_norm": 0.4866519294291734,
      "learning_rate": 4.950185075841706e-06,
      "logits/chosen": -0.9451343417167664,
      "logits/rejected": -0.9241777062416077,
      "logps/chosen": -306.6429748535156,
      "logps/rejected": -341.588134765625,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6653866171836853,
      "rewards/margins": 3.870957851409912,
      "rewards/rejected": -3.205571174621582,
      "step": 509
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.509645451737459,
      "learning_rate": 4.912933807510714e-06,
      "logits/chosen": -1.0170388221740723,
      "logits/rejected": -1.0260599851608276,
      "logps/chosen": -165.47183227539062,
      "logps/rejected": -339.8372802734375,
      "loss": 0.1639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4944447875022888,
      "rewards/margins": 3.534759998321533,
      "rewards/rejected": -3.0403153896331787,
      "step": 510
    },
    {
      "epoch": 3.4066666666666667,
      "grad_norm": 2.9774186312353597,
      "learning_rate": 4.875777533499339e-06,
      "logits/chosen": -0.8237065672874451,
      "logits/rejected": -0.9406818747520447,
      "logps/chosen": -257.5295104980469,
      "logps/rejected": -253.2210693359375,
      "loss": 0.3464,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3320246636867523,
      "rewards/margins": 1.8246937990188599,
      "rewards/rejected": -1.4926689863204956,
      "step": 511
    },
    {
      "epoch": 3.413333333333333,
      "grad_norm": 1.1972976854521649,
      "learning_rate": 4.838716947652485e-06,
      "logits/chosen": -0.8552139401435852,
      "logits/rejected": -0.9265148043632507,
      "logps/chosen": -244.95901489257812,
      "logps/rejected": -280.65692138671875,
      "loss": 0.157,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 1.066701889038086,
      "rewards/margins": 3.630751132965088,
      "rewards/rejected": -2.564049005508423,
      "step": 512
    },
    {
      "epoch": 3.42,
      "grad_norm": 1.6515075154747052,
      "learning_rate": 4.801752742028214e-06,
      "logits/chosen": -0.8522107005119324,
      "logits/rejected": -0.9369789958000183,
      "logps/chosen": -302.9122314453125,
      "logps/rejected": -287.1016540527344,
      "loss": 0.1155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8773934841156006,
      "rewards/margins": 3.73964524269104,
      "rewards/rejected": -2.8622519969940186,
      "step": 513
    },
    {
      "epoch": 3.4266666666666667,
      "grad_norm": 1.770490508460496,
      "learning_rate": 4.7648856068848e-06,
      "logits/chosen": -0.7812088131904602,
      "logits/rejected": -1.028702974319458,
      "logps/chosen": -302.5416259765625,
      "logps/rejected": -296.8285827636719,
      "loss": 0.2237,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 1.011486291885376,
      "rewards/margins": 2.8591978549957275,
      "rewards/rejected": -1.8477113246917725,
      "step": 514
    },
    {
      "epoch": 3.4333333333333336,
      "grad_norm": 1.7859785660955891,
      "learning_rate": 4.728116230667859e-06,
      "logits/chosen": -0.9011495113372803,
      "logits/rejected": -0.9840399622917175,
      "logps/chosen": -251.58328247070312,
      "logps/rejected": -246.27120971679688,
      "loss": 0.1418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6717238426208496,
      "rewards/margins": 2.9558725357055664,
      "rewards/rejected": -2.284148931503296,
      "step": 515
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.766834490255256,
      "learning_rate": 4.691445299997491e-06,
      "logits/chosen": -0.8246774673461914,
      "logits/rejected": -0.9746973514556885,
      "logps/chosen": -286.8217468261719,
      "logps/rejected": -322.65692138671875,
      "loss": 0.1564,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3242771625518799,
      "rewards/margins": 3.7207260131835938,
      "rewards/rejected": -3.396448850631714,
      "step": 516
    },
    {
      "epoch": 3.4466666666666668,
      "grad_norm": 2.321091440893647,
      "learning_rate": 4.654873499655449e-06,
      "logits/chosen": -0.9733248949050903,
      "logits/rejected": -1.0264798402786255,
      "logps/chosen": -339.322021484375,
      "logps/rejected": -336.8620910644531,
      "loss": 0.1164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7557263374328613,
      "rewards/margins": 3.5987377166748047,
      "rewards/rejected": -2.8430113792419434,
      "step": 517
    },
    {
      "epoch": 3.453333333333333,
      "grad_norm": 1.7970063534700207,
      "learning_rate": 4.618401512572351e-06,
      "logits/chosen": -0.9689009785652161,
      "logits/rejected": -1.0204185247421265,
      "logps/chosen": -291.10919189453125,
      "logps/rejected": -343.3330078125,
      "loss": 0.1515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.643143355846405,
      "rewards/margins": 3.139336347579956,
      "rewards/rejected": -2.4961931705474854,
      "step": 518
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.499100904914961,
      "learning_rate": 4.582030019814948e-06,
      "logits/chosen": -0.9884114861488342,
      "logits/rejected": -0.8458830118179321,
      "logps/chosen": -178.51815795898438,
      "logps/rejected": -403.3360900878906,
      "loss": 0.1254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035707876086235046,
      "rewards/margins": 4.643301963806152,
      "rewards/rejected": -4.6075944900512695,
      "step": 519
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 0.3173521173746115,
      "learning_rate": 4.5457597005733774e-06,
      "logits/chosen": -0.9918069839477539,
      "logits/rejected": -0.941882848739624,
      "logps/chosen": -229.05938720703125,
      "logps/rejected": -422.9341735839844,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7108984589576721,
      "rewards/margins": 5.539457321166992,
      "rewards/rejected": -4.828558921813965,
      "step": 520
    },
    {
      "epoch": 3.473333333333333,
      "grad_norm": 3.335452757018051,
      "learning_rate": 4.5095912321484946e-06,
      "logits/chosen": -0.8404392004013062,
      "logits/rejected": -0.8915374875068665,
      "logps/chosen": -140.806640625,
      "logps/rejected": -303.90313720703125,
      "loss": 0.3132,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.04711231589317322,
      "rewards/margins": 2.050543785095215,
      "rewards/rejected": -2.09765625,
      "step": 521
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.1775009509149132,
      "learning_rate": 4.4735252899392335e-06,
      "logits/chosen": -0.9249439835548401,
      "logits/rejected": -1.0003955364227295,
      "logps/chosen": -321.93756103515625,
      "logps/rejected": -325.2901916503906,
      "loss": 0.1667,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8622919917106628,
      "rewards/margins": 3.5879130363464355,
      "rewards/rejected": -2.725621223449707,
      "step": 522
    },
    {
      "epoch": 3.486666666666667,
      "grad_norm": 2.442415025964592,
      "learning_rate": 4.437562547429971e-06,
      "logits/chosen": -1.002040147781372,
      "logits/rejected": -0.9659637212753296,
      "logps/chosen": -254.68031311035156,
      "logps/rejected": -292.10211181640625,
      "loss": 0.2082,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.27482008934020996,
      "rewards/margins": 3.2016196250915527,
      "rewards/rejected": -2.9267995357513428,
      "step": 523
    },
    {
      "epoch": 3.493333333333333,
      "grad_norm": 1.2058257962992884,
      "learning_rate": 4.4017036761779785e-06,
      "logits/chosen": -1.0290344953536987,
      "logits/rejected": -0.9909016489982605,
      "logps/chosen": -160.21041870117188,
      "logps/rejected": -281.55340576171875,
      "loss": 0.1211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46429336071014404,
      "rewards/margins": 3.662095308303833,
      "rewards/rejected": -3.1978020668029785,
      "step": 524
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.9427364022026165,
      "learning_rate": 4.365949345800856e-06,
      "logits/chosen": -1.056484341621399,
      "logits/rejected": -1.133375644683838,
      "logps/chosen": -195.18936157226562,
      "logps/rejected": -261.92083740234375,
      "loss": 0.0696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.678160548210144,
      "rewards/margins": 3.9456679821014404,
      "rewards/rejected": -3.267507553100586,
      "step": 525
    },
    {
      "epoch": 3.506666666666667,
      "grad_norm": 2.3488456772364614,
      "learning_rate": 4.3303002239640424e-06,
      "logits/chosen": -0.8696707487106323,
      "logits/rejected": -1.0616750717163086,
      "logps/chosen": -212.55618286132812,
      "logps/rejected": -302.3265075683594,
      "loss": 0.1591,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3582879602909088,
      "rewards/margins": 2.673386573791504,
      "rewards/rejected": -2.315098762512207,
      "step": 526
    },
    {
      "epoch": 3.513333333333333,
      "grad_norm": 2.0167851620795236,
      "learning_rate": 4.294756976368351e-06,
      "logits/chosen": -1.0453928709030151,
      "logits/rejected": -1.0490679740905762,
      "logps/chosen": -222.34133911132812,
      "logps/rejected": -343.0526123046875,
      "loss": 0.138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6789544820785522,
      "rewards/margins": 4.041913986206055,
      "rewards/rejected": -3.362959384918213,
      "step": 527
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.5365975096001554,
      "learning_rate": 4.259320266737522e-06,
      "logits/chosen": -0.8184866309165955,
      "logits/rejected": -1.0271555185317993,
      "logps/chosen": -403.555908203125,
      "logps/rejected": -309.0271911621094,
      "loss": 0.1144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0759462118148804,
      "rewards/margins": 2.846773147583008,
      "rewards/rejected": -1.770827054977417,
      "step": 528
    },
    {
      "epoch": 3.5266666666666664,
      "grad_norm": 2.51614668276333,
      "learning_rate": 4.223990756805841e-06,
      "logits/chosen": -1.0092207193374634,
      "logits/rejected": -1.0239465236663818,
      "logps/chosen": -200.17298889160156,
      "logps/rejected": -325.68743896484375,
      "loss": 0.1977,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3560633361339569,
      "rewards/margins": 3.9557230472564697,
      "rewards/rejected": -3.5996599197387695,
      "step": 529
    },
    {
      "epoch": 3.533333333333333,
      "grad_norm": 1.0064434836941225,
      "learning_rate": 4.1887691063057865e-06,
      "logits/chosen": -0.9623708724975586,
      "logits/rejected": -1.0841383934020996,
      "logps/chosen": -206.8891143798828,
      "logps/rejected": -329.6969299316406,
      "loss": 0.0571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45673462748527527,
      "rewards/margins": 3.9489850997924805,
      "rewards/rejected": -3.492250442504883,
      "step": 530
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.3282710275592096,
      "learning_rate": 4.153655972955695e-06,
      "logits/chosen": -1.031765103340149,
      "logits/rejected": -1.0703125,
      "logps/chosen": -160.13180541992188,
      "logps/rejected": -329.52655029296875,
      "loss": 0.0856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5862684845924377,
      "rewards/margins": 4.522557258605957,
      "rewards/rejected": -3.936288833618164,
      "step": 531
    },
    {
      "epoch": 3.546666666666667,
      "grad_norm": 1.1540157795592487,
      "learning_rate": 4.118652012447486e-06,
      "logits/chosen": -1.091902256011963,
      "logits/rejected": -0.970497190952301,
      "logps/chosen": -134.22296142578125,
      "logps/rejected": -385.8769836425781,
      "loss": 0.0501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.530219316482544,
      "rewards/margins": 5.2879719734191895,
      "rewards/rejected": -4.757752895355225,
      "step": 532
    },
    {
      "epoch": 3.5533333333333332,
      "grad_norm": 2.956195667888589,
      "learning_rate": 4.0837578784344225e-06,
      "logits/chosen": -0.7952547073364258,
      "logits/rejected": -0.9673970341682434,
      "logps/chosen": -366.86053466796875,
      "logps/rejected": -352.37921142578125,
      "loss": 0.1716,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03388503938913345,
      "rewards/margins": 2.796123743057251,
      "rewards/rejected": -2.7622385025024414,
      "step": 533
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.1973891326774333,
      "learning_rate": 4.048974222518905e-06,
      "logits/chosen": -0.9152091145515442,
      "logits/rejected": -0.8851057887077332,
      "logps/chosen": -330.09063720703125,
      "logps/rejected": -428.76739501953125,
      "loss": 0.0574,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5984672904014587,
      "rewards/margins": 4.414132595062256,
      "rewards/rejected": -3.8156652450561523,
      "step": 534
    },
    {
      "epoch": 3.5666666666666664,
      "grad_norm": 1.8967682206643919,
      "learning_rate": 4.01430169424029e-06,
      "logits/chosen": -0.9827492833137512,
      "logits/rejected": -0.949210524559021,
      "logps/chosen": -291.508056640625,
      "logps/rejected": -345.45355224609375,
      "loss": 0.1936,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6705008745193481,
      "rewards/margins": 3.483269214630127,
      "rewards/rejected": -2.8127684593200684,
      "step": 535
    },
    {
      "epoch": 3.5733333333333333,
      "grad_norm": 1.823058582412992,
      "learning_rate": 3.97974094106278e-06,
      "logits/chosen": -0.758449912071228,
      "logits/rejected": -0.9917551279067993,
      "logps/chosen": -244.86026000976562,
      "logps/rejected": -243.47647094726562,
      "loss": 0.1627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6111262440681458,
      "rewards/margins": 3.3975114822387695,
      "rewards/rejected": -2.7863850593566895,
      "step": 536
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.9820590794708597,
      "learning_rate": 3.945292608363312e-06,
      "logits/chosen": -0.923869788646698,
      "logits/rejected": -0.960872232913971,
      "logps/chosen": -227.01641845703125,
      "logps/rejected": -360.9635314941406,
      "loss": 0.3123,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4719000458717346,
      "rewards/margins": 2.3736581802368164,
      "rewards/rejected": -1.9017581939697266,
      "step": 537
    },
    {
      "epoch": 3.586666666666667,
      "grad_norm": 1.5034156692749954,
      "learning_rate": 3.9109573394195336e-06,
      "logits/chosen": -0.9796037077903748,
      "logits/rejected": -1.0221242904663086,
      "logps/chosen": -209.0139617919922,
      "logps/rejected": -312.4727783203125,
      "loss": 0.1338,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6002733111381531,
      "rewards/margins": 3.968295097351074,
      "rewards/rejected": -3.3680214881896973,
      "step": 538
    },
    {
      "epoch": 3.5933333333333333,
      "grad_norm": 2.2663182743516854,
      "learning_rate": 3.876735775397759e-06,
      "logits/chosen": -1.0084394216537476,
      "logits/rejected": -1.1137837171554565,
      "logps/chosen": -331.66571044921875,
      "logps/rejected": -280.08453369140625,
      "loss": 0.1621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5780370831489563,
      "rewards/margins": 3.1653904914855957,
      "rewards/rejected": -2.587353229522705,
      "step": 539
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.5327951848318806,
      "learning_rate": 3.842628555341018e-06,
      "logits/chosen": -0.9590632319450378,
      "logits/rejected": -1.0032744407653809,
      "logps/chosen": -273.31805419921875,
      "logps/rejected": -330.0019226074219,
      "loss": 0.0782,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6368526220321655,
      "rewards/margins": 3.531280279159546,
      "rewards/rejected": -2.89442777633667,
      "step": 540
    },
    {
      "epoch": 3.6066666666666665,
      "grad_norm": 1.8445257074514356,
      "learning_rate": 3.8086363161571194e-06,
      "logits/chosen": -0.829208493232727,
      "logits/rejected": -0.9359570145606995,
      "logps/chosen": -394.90234375,
      "logps/rejected": -446.6155700683594,
      "loss": 0.1208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49940428137779236,
      "rewards/margins": 3.14986252784729,
      "rewards/rejected": -2.650458335876465,
      "step": 541
    },
    {
      "epoch": 3.6133333333333333,
      "grad_norm": 1.7749898560999757,
      "learning_rate": 3.7747596926067485e-06,
      "logits/chosen": -0.9849259853363037,
      "logits/rejected": -1.0131572484970093,
      "logps/chosen": -225.4471435546875,
      "logps/rejected": -265.340087890625,
      "loss": 0.1544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6400572061538696,
      "rewards/margins": 3.186431884765625,
      "rewards/rejected": -2.546374797821045,
      "step": 542
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.17815712547053683,
      "learning_rate": 3.740999317291618e-06,
      "logits/chosen": -1.0721925497055054,
      "logits/rejected": -1.0699619054794312,
      "logps/chosen": -168.6785888671875,
      "logps/rejected": -333.3790283203125,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8088029623031616,
      "rewards/margins": 5.60881233215332,
      "rewards/rejected": -4.800009727478027,
      "step": 543
    },
    {
      "epoch": 3.626666666666667,
      "grad_norm": 1.0979688206155975,
      "learning_rate": 3.7073558206426673e-06,
      "logits/chosen": -1.0670952796936035,
      "logits/rejected": -1.0671981573104858,
      "logps/chosen": -293.4625244140625,
      "logps/rejected": -339.8507385253906,
      "loss": 0.1138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8796830177307129,
      "rewards/margins": 4.195294380187988,
      "rewards/rejected": -3.3156116008758545,
      "step": 544
    },
    {
      "epoch": 3.6333333333333333,
      "grad_norm": 2.931524489184506,
      "learning_rate": 3.6738298309082665e-06,
      "logits/chosen": -0.9806073307991028,
      "logits/rejected": -1.0562021732330322,
      "logps/chosen": -207.24197387695312,
      "logps/rejected": -222.1419219970703,
      "loss": 0.196,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.8058534264564514,
      "rewards/margins": 3.016718864440918,
      "rewards/rejected": -2.2108654975891113,
      "step": 545
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.9429206343956276,
      "learning_rate": 3.6404219741425084e-06,
      "logits/chosen": -1.1105103492736816,
      "logits/rejected": -1.0108246803283691,
      "logps/chosen": -223.01162719726562,
      "logps/rejected": -371.55535888671875,
      "loss": 0.1812,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3385716676712036,
      "rewards/margins": 3.4920618534088135,
      "rewards/rejected": -3.1534903049468994,
      "step": 546
    },
    {
      "epoch": 3.6466666666666665,
      "grad_norm": 1.058329250047471,
      "learning_rate": 3.6071328741934985e-06,
      "logits/chosen": -0.9542216658592224,
      "logits/rejected": -1.0677993297576904,
      "logps/chosen": -229.86410522460938,
      "logps/rejected": -300.80816650390625,
      "loss": 0.0371,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1732899397611618,
      "rewards/margins": 4.2505974769592285,
      "rewards/rejected": -4.07730770111084,
      "step": 547
    },
    {
      "epoch": 3.6533333333333333,
      "grad_norm": 1.5370845574553074,
      "learning_rate": 3.5739631526917152e-06,
      "logits/chosen": -0.9210789799690247,
      "logits/rejected": -0.8209366798400879,
      "logps/chosen": -261.10333251953125,
      "logps/rejected": -482.6154479980469,
      "loss": 0.0506,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7670285701751709,
      "rewards/margins": 3.8166255950927734,
      "rewards/rejected": -3.0495967864990234,
      "step": 548
    },
    {
      "epoch": 3.66,
      "grad_norm": 1.2152743542335365,
      "learning_rate": 3.540913429038407e-06,
      "logits/chosen": -1.0349478721618652,
      "logits/rejected": -1.1133109331130981,
      "logps/chosen": -241.24615478515625,
      "logps/rejected": -310.8829345703125,
      "loss": 0.0868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8721250295639038,
      "rewards/margins": 4.543483734130859,
      "rewards/rejected": -3.671358585357666,
      "step": 549
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 1.8388519529581688,
      "learning_rate": 3.507984320394012e-06,
      "logits/chosen": -0.8796799182891846,
      "logits/rejected": -0.9211522936820984,
      "logps/chosen": -246.46841430664062,
      "logps/rejected": -342.55792236328125,
      "loss": 0.117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5000709295272827,
      "rewards/margins": 3.6348657608032227,
      "rewards/rejected": -3.1347949504852295,
      "step": 550
    },
    {
      "epoch": 3.6733333333333333,
      "grad_norm": 2.3059932824307454,
      "learning_rate": 3.47517644166664e-06,
      "logits/chosen": -0.6709166765213013,
      "logits/rejected": -0.6507917046546936,
      "logps/chosen": -287.92626953125,
      "logps/rejected": -270.0653381347656,
      "loss": 0.203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7369711399078369,
      "rewards/margins": 2.2042384147644043,
      "rewards/rejected": -1.4672672748565674,
      "step": 551
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.2161741178546661,
      "learning_rate": 3.442490405500598e-06,
      "logits/chosen": -0.9143760204315186,
      "logits/rejected": -0.9849827885627747,
      "logps/chosen": -231.78475952148438,
      "logps/rejected": -388.1130676269531,
      "loss": 0.044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5959029793739319,
      "rewards/margins": 4.8475871086120605,
      "rewards/rejected": -4.251684188842773,
      "step": 552
    },
    {
      "epoch": 3.6866666666666665,
      "grad_norm": 0.1273117209449532,
      "learning_rate": 3.4099268222649373e-06,
      "logits/chosen": -1.0533714294433594,
      "logits/rejected": -1.1293429136276245,
      "logps/chosen": -216.02093505859375,
      "logps/rejected": -313.73529052734375,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9734823703765869,
      "rewards/margins": 5.702803611755371,
      "rewards/rejected": -4.729321002960205,
      "step": 553
    },
    {
      "epoch": 3.6933333333333334,
      "grad_norm": 0.7242135254507899,
      "learning_rate": 3.3774863000420545e-06,
      "logits/chosen": -1.0561234951019287,
      "logits/rejected": -1.0282808542251587,
      "logps/chosen": -250.5293426513672,
      "logps/rejected": -436.9945983886719,
      "loss": 0.0228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5793187618255615,
      "rewards/margins": 4.878077507019043,
      "rewards/rejected": -4.2987589836120605,
      "step": 554
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.446346638177198,
      "learning_rate": 3.3451694446163553e-06,
      "logits/chosen": -1.1012719869613647,
      "logits/rejected": -1.0544042587280273,
      "logps/chosen": -259.3954772949219,
      "logps/rejected": -446.6435852050781,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.523884654045105,
      "rewards/margins": 5.825772285461426,
      "rewards/rejected": -5.301887512207031,
      "step": 555
    },
    {
      "epoch": 3.7066666666666666,
      "grad_norm": 0.29636076258921146,
      "learning_rate": 3.3129768594629186e-06,
      "logits/chosen": -1.0649257898330688,
      "logits/rejected": -0.8628281950950623,
      "logps/chosen": -132.50486755371094,
      "logps/rejected": -473.2630310058594,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.129350945353508,
      "rewards/margins": 5.920978546142578,
      "rewards/rejected": -5.791627883911133,
      "step": 556
    },
    {
      "epoch": 3.7133333333333334,
      "grad_norm": 1.485332942848451,
      "learning_rate": 3.2809091457362464e-06,
      "logits/chosen": -0.9827002882957458,
      "logits/rejected": -1.0285335779190063,
      "logps/chosen": -170.06588745117188,
      "logps/rejected": -421.849609375,
      "loss": 0.0699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2180750072002411,
      "rewards/margins": 4.891751289367676,
      "rewards/rejected": -4.673676490783691,
      "step": 557
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 2.3510684891707183,
      "learning_rate": 3.248966902259024e-06,
      "logits/chosen": -0.858982503414154,
      "logits/rejected": -0.9433344602584839,
      "logps/chosen": -231.0343780517578,
      "logps/rejected": -508.3374328613281,
      "loss": 0.1674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31456366181373596,
      "rewards/margins": 3.481827735900879,
      "rewards/rejected": -3.167263984680176,
      "step": 558
    },
    {
      "epoch": 3.7266666666666666,
      "grad_norm": 2.143772122905676,
      "learning_rate": 3.2171507255109457e-06,
      "logits/chosen": -0.8327908515930176,
      "logits/rejected": -1.0227092504501343,
      "logps/chosen": -335.9454650878906,
      "logps/rejected": -313.02838134765625,
      "loss": 0.1783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7933800220489502,
      "rewards/margins": 2.819340705871582,
      "rewards/rejected": -2.025960683822632,
      "step": 559
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 2.045914635787606,
      "learning_rate": 3.185461209617571e-06,
      "logits/chosen": -1.120155930519104,
      "logits/rejected": -1.071671962738037,
      "logps/chosen": -138.56005859375,
      "logps/rejected": -350.86517333984375,
      "loss": 0.1785,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3653739094734192,
      "rewards/margins": 4.270404815673828,
      "rewards/rejected": -3.905031204223633,
      "step": 560
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.2844696065767462,
      "learning_rate": 3.153898946339241e-06,
      "logits/chosen": -1.0330841541290283,
      "logits/rejected": -0.9827936887741089,
      "logps/chosen": -287.5976257324219,
      "logps/rejected": -375.66107177734375,
      "loss": 0.0744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.074965476989746,
      "rewards/margins": 4.637634754180908,
      "rewards/rejected": -3.562669277191162,
      "step": 561
    },
    {
      "epoch": 3.7466666666666666,
      "grad_norm": 1.8264497433360303,
      "learning_rate": 3.122464525060013e-06,
      "logits/chosen": -0.7827312350273132,
      "logits/rejected": -0.8996053338050842,
      "logps/chosen": -406.7416076660156,
      "logps/rejected": -433.00958251953125,
      "loss": 0.1473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0030643939971924,
      "rewards/margins": 3.0660438537597656,
      "rewards/rejected": -2.062979221343994,
      "step": 562
    },
    {
      "epoch": 3.7533333333333334,
      "grad_norm": 1.8780145571411597,
      "learning_rate": 3.0911585327766658e-06,
      "logits/chosen": -1.1145665645599365,
      "logits/rejected": -1.0007789134979248,
      "logps/chosen": -251.51828002929688,
      "logps/rejected": -451.6181945800781,
      "loss": 0.0827,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08608382940292358,
      "rewards/margins": 3.534782886505127,
      "rewards/rejected": -3.4486992359161377,
      "step": 563
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.7760325531338832,
      "learning_rate": 3.059981554087732e-06,
      "logits/chosen": -0.9022453427314758,
      "logits/rejected": -0.9001989364624023,
      "logps/chosen": -332.34979248046875,
      "logps/rejected": -466.00653076171875,
      "loss": 0.101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7099157571792603,
      "rewards/margins": 4.712590217590332,
      "rewards/rejected": -4.002674102783203,
      "step": 564
    },
    {
      "epoch": 3.7666666666666666,
      "grad_norm": 0.27146252880430904,
      "learning_rate": 3.0289341711825817e-06,
      "logits/chosen": -1.1455438137054443,
      "logits/rejected": -0.9168698787689209,
      "logps/chosen": -145.94781494140625,
      "logps/rejected": -431.2264099121094,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2905961573123932,
      "rewards/margins": 5.576443672180176,
      "rewards/rejected": -5.2858476638793945,
      "step": 565
    },
    {
      "epoch": 3.7733333333333334,
      "grad_norm": 0.6746055430627611,
      "learning_rate": 2.998016963830562e-06,
      "logits/chosen": -0.8876722455024719,
      "logits/rejected": -1.0583642721176147,
      "logps/chosen": -254.09890747070312,
      "logps/rejected": -435.85845947265625,
      "loss": 0.0275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7686167359352112,
      "rewards/margins": 4.683631420135498,
      "rewards/rejected": -3.9150149822235107,
      "step": 566
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 1.0778522422853913,
      "learning_rate": 2.96723050937015e-06,
      "logits/chosen": -1.0292272567749023,
      "logits/rejected": -1.0948759317398071,
      "logps/chosen": -200.073486328125,
      "logps/rejected": -329.55859375,
      "loss": 0.0376,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6826843023300171,
      "rewards/margins": 5.265517711639404,
      "rewards/rejected": -4.582833766937256,
      "step": 567
    },
    {
      "epoch": 3.7866666666666666,
      "grad_norm": 1.2447885116898951,
      "learning_rate": 2.9365753826981947e-06,
      "logits/chosen": -0.9109272956848145,
      "logits/rejected": -1.059492588043213,
      "logps/chosen": -287.0498352050781,
      "logps/rejected": -340.2859191894531,
      "loss": 0.0717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9594589471817017,
      "rewards/margins": 4.886971473693848,
      "rewards/rejected": -3.9275128841400146,
      "step": 568
    },
    {
      "epoch": 3.7933333333333334,
      "grad_norm": 0.41606474752049755,
      "learning_rate": 2.9060521562591625e-06,
      "logits/chosen": -1.123468041419983,
      "logits/rejected": -1.072222113609314,
      "logps/chosen": -138.22018432617188,
      "logps/rejected": -388.9379577636719,
      "loss": 0.0949,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.48600879311561584,
      "rewards/margins": 5.444148540496826,
      "rewards/rejected": -4.9581403732299805,
      "step": 569
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.656208181752989,
      "learning_rate": 2.875661400034452e-06,
      "logits/chosen": -0.886021077632904,
      "logits/rejected": -1.0837563276290894,
      "logps/chosen": -302.97491455078125,
      "logps/rejected": -405.9954528808594,
      "loss": 0.1383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43080201745033264,
      "rewards/margins": 3.8715739250183105,
      "rewards/rejected": -3.44077205657959,
      "step": 570
    },
    {
      "epoch": 3.8066666666666666,
      "grad_norm": 0.6894950313638056,
      "learning_rate": 2.8454036815317643e-06,
      "logits/chosen": -1.0689398050308228,
      "logits/rejected": -0.9948061108589172,
      "logps/chosen": -150.96157836914062,
      "logps/rejected": -384.884521484375,
      "loss": 0.0409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.643739640712738,
      "rewards/margins": 6.178703784942627,
      "rewards/rejected": -5.534964084625244,
      "step": 571
    },
    {
      "epoch": 3.8133333333333335,
      "grad_norm": 1.221449625260848,
      "learning_rate": 2.8152795657744882e-06,
      "logits/chosen": -1.1547082662582397,
      "logits/rejected": -1.095539927482605,
      "logps/chosen": -168.79981994628906,
      "logps/rejected": -283.31939697265625,
      "loss": 0.0712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.645017147064209,
      "rewards/margins": 4.337582588195801,
      "rewards/rejected": -3.6925652027130127,
      "step": 572
    },
    {
      "epoch": 3.82,
      "grad_norm": 1.10439310211216,
      "learning_rate": 2.78528961529115e-06,
      "logits/chosen": -1.1186788082122803,
      "logits/rejected": -1.1251349449157715,
      "logps/chosen": -264.9281005859375,
      "logps/rejected": -310.27313232421875,
      "loss": 0.0792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0705485343933105,
      "rewards/margins": 3.748751640319824,
      "rewards/rejected": -2.6782031059265137,
      "step": 573
    },
    {
      "epoch": 3.8266666666666667,
      "grad_norm": 1.807646732099181,
      "learning_rate": 2.7554343901049295e-06,
      "logits/chosen": -0.9625694751739502,
      "logits/rejected": -0.9634937047958374,
      "logps/chosen": -288.3426513671875,
      "logps/rejected": -379.337890625,
      "loss": 0.1228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.840743899345398,
      "rewards/margins": 3.7898550033569336,
      "rewards/rejected": -2.949110984802246,
      "step": 574
    },
    {
      "epoch": 3.8333333333333335,
      "grad_norm": 1.5565907698895671,
      "learning_rate": 2.7257144477231756e-06,
      "logits/chosen": -1.0369607210159302,
      "logits/rejected": -1.0115314722061157,
      "logps/chosen": -292.65313720703125,
      "logps/rejected": -482.4051513671875,
      "loss": 0.0727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7766312956809998,
      "rewards/margins": 5.103278160095215,
      "rewards/rejected": -4.32664680480957,
      "step": 575
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.2662080434342167,
      "learning_rate": 2.696130343127007e-06,
      "logits/chosen": -0.9256225228309631,
      "logits/rejected": -1.064780592918396,
      "logps/chosen": -275.8321228027344,
      "logps/rejected": -403.25640869140625,
      "loss": 0.0568,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2950083613395691,
      "rewards/margins": 5.093196868896484,
      "rewards/rejected": -4.798188209533691,
      "step": 576
    },
    {
      "epoch": 3.8466666666666667,
      "grad_norm": 1.4374144984815431,
      "learning_rate": 2.666682628760958e-06,
      "logits/chosen": -0.9381484389305115,
      "logits/rejected": -0.9689655900001526,
      "logps/chosen": -297.33251953125,
      "logps/rejected": -441.6382141113281,
      "loss": 0.1067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5923070907592773,
      "rewards/margins": 3.8283207416534424,
      "rewards/rejected": -3.236013650894165,
      "step": 577
    },
    {
      "epoch": 3.8533333333333335,
      "grad_norm": 6.205075665918619,
      "learning_rate": 2.6373718545226444e-06,
      "logits/chosen": -1.0096503496170044,
      "logits/rejected": -1.1106232404708862,
      "logps/chosen": -349.193115234375,
      "logps/rejected": -358.2134704589844,
      "loss": 0.452,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.1927693784236908,
      "rewards/margins": 3.3495898246765137,
      "rewards/rejected": -3.15682053565979,
      "step": 578
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.1968676940015093,
      "learning_rate": 2.6081985677525124e-06,
      "logits/chosen": -1.0174344778060913,
      "logits/rejected": -0.8842834830284119,
      "logps/chosen": -194.99966430664062,
      "logps/rejected": -518.7906494140625,
      "loss": 0.1285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5649683475494385,
      "rewards/margins": 4.23844051361084,
      "rewards/rejected": -3.6734724044799805,
      "step": 579
    },
    {
      "epoch": 3.8666666666666667,
      "grad_norm": 1.8606534137292574,
      "learning_rate": 2.5791633132236027e-06,
      "logits/chosen": -1.0574781894683838,
      "logits/rejected": -1.0719165802001953,
      "logps/chosen": -223.1478271484375,
      "logps/rejected": -344.6837158203125,
      "loss": 0.1833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.569772481918335,
      "rewards/margins": 3.6307151317596436,
      "rewards/rejected": -3.0609426498413086,
      "step": 580
    },
    {
      "epoch": 3.873333333333333,
      "grad_norm": 1.533517987424708,
      "learning_rate": 2.550266633131382e-06,
      "logits/chosen": -0.8748918175697327,
      "logits/rejected": -1.0867069959640503,
      "logps/chosen": -294.7095947265625,
      "logps/rejected": -234.75416564941406,
      "loss": 0.1506,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5670559406280518,
      "rewards/margins": 3.358555793762207,
      "rewards/rejected": -2.791499614715576,
      "step": 581
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.4677647886492079,
      "learning_rate": 2.521509067083631e-06,
      "logits/chosen": -1.0774204730987549,
      "logits/rejected": -1.0799777507781982,
      "logps/chosen": -201.88241577148438,
      "logps/rejected": -332.7372741699219,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47253382205963135,
      "rewards/margins": 4.987620830535889,
      "rewards/rejected": -4.515087127685547,
      "step": 582
    },
    {
      "epoch": 3.8866666666666667,
      "grad_norm": 2.600286680702414,
      "learning_rate": 2.4928911520903466e-06,
      "logits/chosen": -0.8454621434211731,
      "logits/rejected": -0.9392555356025696,
      "logps/chosen": -265.3154296875,
      "logps/rejected": -430.16339111328125,
      "loss": 0.1392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23766353726387024,
      "rewards/margins": 3.0888335704803467,
      "rewards/rejected": -2.851170063018799,
      "step": 583
    },
    {
      "epoch": 3.8933333333333335,
      "grad_norm": 2.204662571042231,
      "learning_rate": 2.4644134225537265e-06,
      "logits/chosen": -0.8833484053611755,
      "logits/rejected": -0.9080398082733154,
      "logps/chosen": -297.662841796875,
      "logps/rejected": -287.6295166015625,
      "loss": 0.1222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0412994623184204,
      "rewards/margins": 3.5541391372680664,
      "rewards/rejected": -2.5128397941589355,
      "step": 584
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.015404740948186,
      "learning_rate": 2.4360764102581947e-06,
      "logits/chosen": -0.9917547702789307,
      "logits/rejected": -1.1258180141448975,
      "logps/chosen": -319.1322326660156,
      "logps/rejected": -255.3404998779297,
      "loss": 0.1981,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7090402841567993,
      "rewards/margins": 3.157987356185913,
      "rewards/rejected": -2.4489471912384033,
      "step": 585
    },
    {
      "epoch": 3.9066666666666667,
      "grad_norm": 1.9708977745870826,
      "learning_rate": 2.4078806443604595e-06,
      "logits/chosen": -1.139424204826355,
      "logits/rejected": -0.9065005779266357,
      "logps/chosen": -147.1319580078125,
      "logps/rejected": -379.5198974609375,
      "loss": 0.143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1162133738398552,
      "rewards/margins": 4.7011003494262695,
      "rewards/rejected": -4.5848870277404785,
      "step": 586
    },
    {
      "epoch": 3.913333333333333,
      "grad_norm": 0.5330311704041674,
      "learning_rate": 2.379826651379632e-06,
      "logits/chosen": -1.008034586906433,
      "logits/rejected": -1.095126986503601,
      "logps/chosen": -221.36001586914062,
      "logps/rejected": -338.3680419921875,
      "loss": 0.0147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45942097902297974,
      "rewards/margins": 5.378176689147949,
      "rewards/rejected": -4.918755531311035,
      "step": 587
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.2173469297956,
      "learning_rate": 2.351914955187412e-06,
      "logits/chosen": -0.9262346029281616,
      "logits/rejected": -1.0472702980041504,
      "logps/chosen": -222.9056854248047,
      "logps/rejected": -297.1717529296875,
      "loss": 0.16,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49849459528923035,
      "rewards/margins": 3.9589571952819824,
      "rewards/rejected": -3.460462808609009,
      "step": 588
    },
    {
      "epoch": 3.9266666666666667,
      "grad_norm": 3.0706159524223327,
      "learning_rate": 2.3241460769982814e-06,
      "logits/chosen": -0.8109334707260132,
      "logits/rejected": -0.911116361618042,
      "logps/chosen": -358.95465087890625,
      "logps/rejected": -356.90130615234375,
      "loss": 0.3145,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2395269274711609,
      "rewards/margins": 1.735595703125,
      "rewards/rejected": -1.4960687160491943,
      "step": 589
    },
    {
      "epoch": 3.9333333333333336,
      "grad_norm": 0.8416778409486796,
      "learning_rate": 2.2965205353597866e-06,
      "logits/chosen": -1.169155478477478,
      "logits/rejected": -1.1464952230453491,
      "logps/chosen": -166.43292236328125,
      "logps/rejected": -406.9123229980469,
      "loss": 0.029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6906418204307556,
      "rewards/margins": 6.013102054595947,
      "rewards/rejected": -5.322460651397705,
      "step": 590
    },
    {
      "epoch": 3.94,
      "grad_norm": 1.2914402619744818,
      "learning_rate": 2.269038846142847e-06,
      "logits/chosen": -1.0924780368804932,
      "logits/rejected": -1.0625108480453491,
      "logps/chosen": -196.8141632080078,
      "logps/rejected": -379.25567626953125,
      "loss": 0.0508,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6447372436523438,
      "rewards/margins": 4.871695041656494,
      "rewards/rejected": -4.22695779800415,
      "step": 591
    },
    {
      "epoch": 3.9466666666666668,
      "grad_norm": 0.9187433099827511,
      "learning_rate": 2.241701522532136e-06,
      "logits/chosen": -0.8673610687255859,
      "logits/rejected": -0.7073847055435181,
      "logps/chosen": -275.4809265136719,
      "logps/rejected": -481.3661193847656,
      "loss": 0.0391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9933979511260986,
      "rewards/margins": 5.391811370849609,
      "rewards/rejected": -4.398413181304932,
      "step": 592
    },
    {
      "epoch": 3.953333333333333,
      "grad_norm": 1.4024897847339064,
      "learning_rate": 2.214509075016478e-06,
      "logits/chosen": -1.024600863456726,
      "logits/rejected": -0.9975024461746216,
      "logps/chosen": -161.9544677734375,
      "logps/rejected": -414.026123046875,
      "loss": 0.0564,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09142155945301056,
      "rewards/margins": 5.63364315032959,
      "rewards/rejected": -5.542222023010254,
      "step": 593
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.1494037948577613,
      "learning_rate": 2.1874620113793286e-06,
      "logits/chosen": -0.8741443753242493,
      "logits/rejected": -0.8540981411933899,
      "logps/chosen": -191.8533935546875,
      "logps/rejected": -402.18817138671875,
      "loss": 0.0969,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07290080934762955,
      "rewards/margins": 4.30883264541626,
      "rewards/rejected": -4.235931396484375,
      "step": 594
    },
    {
      "epoch": 3.966666666666667,
      "grad_norm": 1.3188331035445247,
      "learning_rate": 2.160560836689286e-06,
      "logits/chosen": -0.9235345125198364,
      "logits/rejected": -1.0129765272140503,
      "logps/chosen": -239.3283233642578,
      "logps/rejected": -388.1044006347656,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5467619299888611,
      "rewards/margins": 4.15138578414917,
      "rewards/rejected": -3.604623794555664,
      "step": 595
    },
    {
      "epoch": 3.9733333333333336,
      "grad_norm": 1.6195592028592725,
      "learning_rate": 2.1338060532906734e-06,
      "logits/chosen": -1.1593098640441895,
      "logits/rejected": -1.1478933095932007,
      "logps/chosen": -161.1734619140625,
      "logps/rejected": -377.5544128417969,
      "loss": 0.0522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15825922787189484,
      "rewards/margins": 5.3842549324035645,
      "rewards/rejected": -5.225996017456055,
      "step": 596
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.8163616872263775,
      "learning_rate": 2.107198160794136e-06,
      "logits/chosen": -0.7511513233184814,
      "logits/rejected": -1.0978233814239502,
      "logps/chosen": -280.3851318359375,
      "logps/rejected": -223.84219360351562,
      "loss": 0.1323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48299741744995117,
      "rewards/margins": 3.1907730102539062,
      "rewards/rejected": -2.707775831222534,
      "step": 597
    },
    {
      "epoch": 3.986666666666667,
      "grad_norm": 1.6699061699736646,
      "learning_rate": 2.080737656067325e-06,
      "logits/chosen": -1.121826410293579,
      "logits/rejected": -1.0590317249298096,
      "logps/chosen": -184.1695556640625,
      "logps/rejected": -435.02825927734375,
      "loss": 0.1301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13629940152168274,
      "rewards/margins": 5.457282066345215,
      "rewards/rejected": -5.593581199645996,
      "step": 598
    },
    {
      "epoch": 3.993333333333333,
      "grad_norm": 2.078238692077688,
      "learning_rate": 2.054425033225628e-06,
      "logits/chosen": -1.1186518669128418,
      "logits/rejected": -1.029673457145691,
      "logps/chosen": -213.2249755859375,
      "logps/rejected": -369.97265625,
      "loss": 0.106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15584103763103485,
      "rewards/margins": 3.8185930252075195,
      "rewards/rejected": -3.6627516746520996,
      "step": 599
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.712302180517267,
      "learning_rate": 2.028260783622914e-06,
      "logits/chosen": -0.9377808570861816,
      "logits/rejected": -0.94708251953125,
      "logps/chosen": -305.0679626464844,
      "logps/rejected": -343.25592041015625,
      "loss": 0.2045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4614812433719635,
      "rewards/margins": 3.2603158950805664,
      "rewards/rejected": -2.798834800720215,
      "step": 600
    },
    {
      "epoch": 4.006666666666667,
      "grad_norm": 2.549210583284737,
      "learning_rate": 2.002245395842394e-06,
      "logits/chosen": -0.8357599377632141,
      "logits/rejected": -0.9702840447425842,
      "logps/chosen": -329.94305419921875,
      "logps/rejected": -395.23382568359375,
      "loss": 0.2369,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.4749646484851837,
      "rewards/margins": 3.387557029724121,
      "rewards/rejected": -2.9125921726226807,
      "step": 601
    },
    {
      "epoch": 4.013333333333334,
      "grad_norm": 1.2641536024387134,
      "learning_rate": 1.9763793556874655e-06,
      "logits/chosen": -0.9410436749458313,
      "logits/rejected": -1.1099522113800049,
      "logps/chosen": -288.45672607421875,
      "logps/rejected": -357.0387878417969,
      "loss": 0.0837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6211189031600952,
      "rewards/margins": 4.346540927886963,
      "rewards/rejected": -3.725421905517578,
      "step": 602
    },
    {
      "epoch": 4.02,
      "grad_norm": 2.255954069982175,
      "learning_rate": 1.950663146172657e-06,
      "logits/chosen": -0.8122484683990479,
      "logits/rejected": -1.0422495603561401,
      "logps/chosen": -273.2752990722656,
      "logps/rejected": -338.29730224609375,
      "loss": 0.1029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14480465650558472,
      "rewards/margins": 3.928684949874878,
      "rewards/rejected": -3.7838797569274902,
      "step": 603
    },
    {
      "epoch": 4.026666666666666,
      "grad_norm": 0.7957451982943539,
      "learning_rate": 1.9250972475146092e-06,
      "logits/chosen": -0.9494253993034363,
      "logits/rejected": -1.003317952156067,
      "logps/chosen": -298.29461669921875,
      "logps/rejected": -366.85009765625,
      "loss": 0.0403,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5701608657836914,
      "rewards/margins": 4.037878513336182,
      "rewards/rejected": -3.4677176475524902,
      "step": 604
    },
    {
      "epoch": 4.033333333333333,
      "grad_norm": 1.9267435203830354,
      "learning_rate": 1.8996821371231022e-06,
      "logits/chosen": -1.1513687372207642,
      "logits/rejected": -1.0668867826461792,
      "logps/chosen": -129.13381958007812,
      "logps/rejected": -317.02294921875,
      "loss": 0.1109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5146811008453369,
      "rewards/margins": 4.140072822570801,
      "rewards/rejected": -3.625391721725464,
      "step": 605
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.56716184531797,
      "learning_rate": 1.874418289592137e-06,
      "logits/chosen": -0.8267109990119934,
      "logits/rejected": -1.049668550491333,
      "logps/chosen": -466.3114318847656,
      "logps/rejected": -333.0467529296875,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1505696773529053,
      "rewards/margins": 3.6236751079559326,
      "rewards/rejected": -2.4731051921844482,
      "step": 606
    },
    {
      "epoch": 4.046666666666667,
      "grad_norm": 1.6207986218315735,
      "learning_rate": 1.849306176691088e-06,
      "logits/chosen": -0.945412278175354,
      "logits/rejected": -1.127711296081543,
      "logps/chosen": -282.864501953125,
      "logps/rejected": -229.51620483398438,
      "loss": 0.1051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6943464279174805,
      "rewards/margins": 3.475858688354492,
      "rewards/rejected": -2.7815122604370117,
      "step": 607
    },
    {
      "epoch": 4.053333333333334,
      "grad_norm": 2.904207065325007,
      "learning_rate": 1.8243462673558755e-06,
      "logits/chosen": -1.00048828125,
      "logits/rejected": -1.064661979675293,
      "logps/chosen": -176.951416015625,
      "logps/rejected": -234.61923217773438,
      "loss": 0.2426,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.17347939312458038,
      "rewards/margins": 3.450340747833252,
      "rewards/rejected": -3.2768614292144775,
      "step": 608
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.3518663627076992,
      "learning_rate": 1.799539027680216e-06,
      "logits/chosen": -0.9631236791610718,
      "logits/rejected": -0.9446903467178345,
      "logps/chosen": -242.51113891601562,
      "logps/rejected": -395.1832275390625,
      "loss": 0.074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4490121603012085,
      "rewards/margins": 5.084192276000977,
      "rewards/rejected": -4.6351799964904785,
      "step": 609
    },
    {
      "epoch": 4.066666666666666,
      "grad_norm": 1.9844490097542071,
      "learning_rate": 1.7748849209069286e-06,
      "logits/chosen": -1.0425798892974854,
      "logits/rejected": -0.9902100563049316,
      "logps/chosen": -249.5286865234375,
      "logps/rejected": -449.3487548828125,
      "loss": 0.1057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6993722915649414,
      "rewards/margins": 3.9700756072998047,
      "rewards/rejected": -3.2707035541534424,
      "step": 610
    },
    {
      "epoch": 4.073333333333333,
      "grad_norm": 1.571980212351575,
      "learning_rate": 1.7503844074192655e-06,
      "logits/chosen": -1.0537527799606323,
      "logits/rejected": -0.9984183311462402,
      "logps/chosen": -162.43251037597656,
      "logps/rejected": -374.9006652832031,
      "loss": 0.102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2752755880355835,
      "rewards/margins": 4.768072128295898,
      "rewards/rejected": -4.492796897888184,
      "step": 611
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.0826847568039653,
      "learning_rate": 1.7260379447323327e-06,
      "logits/chosen": -1.131248116493225,
      "logits/rejected": -1.003354787826538,
      "logps/chosen": -199.25619506835938,
      "logps/rejected": -357.1378173828125,
      "loss": 0.0671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.562250018119812,
      "rewards/margins": 4.9015913009643555,
      "rewards/rejected": -4.339341640472412,
      "step": 612
    },
    {
      "epoch": 4.086666666666667,
      "grad_norm": 1.5942007437196375,
      "learning_rate": 1.7018459874845327e-06,
      "logits/chosen": -0.9650384783744812,
      "logits/rejected": -1.0115586519241333,
      "logps/chosen": -233.6165008544922,
      "logps/rejected": -360.2840270996094,
      "loss": 0.0746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9592628479003906,
      "rewards/margins": 4.637548446655273,
      "rewards/rejected": -3.678285598754883,
      "step": 613
    },
    {
      "epoch": 4.093333333333334,
      "grad_norm": 1.1228293033980707,
      "learning_rate": 1.6778089874290793e-06,
      "logits/chosen": -0.735600471496582,
      "logits/rejected": -0.8980225920677185,
      "logps/chosen": -300.5013427734375,
      "logps/rejected": -313.99005126953125,
      "loss": 0.0849,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6172858476638794,
      "rewards/margins": 3.208315849304199,
      "rewards/rejected": -2.5910301208496094,
      "step": 614
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.1730442241059804,
      "learning_rate": 1.6539273934255728e-06,
      "logits/chosen": -0.8496610522270203,
      "logits/rejected": -0.9888730645179749,
      "logps/chosen": -426.4102783203125,
      "logps/rejected": -328.03192138671875,
      "loss": 0.2943,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6420037150382996,
      "rewards/margins": 1.731126308441162,
      "rewards/rejected": -1.0891227722167969,
      "step": 615
    },
    {
      "epoch": 4.1066666666666665,
      "grad_norm": 1.0811040327738448,
      "learning_rate": 1.6302016514316e-06,
      "logits/chosen": -0.9683435559272766,
      "logits/rejected": -0.9943140745162964,
      "logps/chosen": -365.6275634765625,
      "logps/rejected": -388.45648193359375,
      "loss": 0.0476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8241937160491943,
      "rewards/margins": 4.404604911804199,
      "rewards/rejected": -3.580411195755005,
      "step": 616
    },
    {
      "epoch": 4.113333333333333,
      "grad_norm": 1.9115345356760243,
      "learning_rate": 1.6066322044944126e-06,
      "logits/chosen": -1.015672206878662,
      "logits/rejected": -0.9799829125404358,
      "logps/chosen": -271.21087646484375,
      "logps/rejected": -411.8382263183594,
      "loss": 0.0824,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6817224621772766,
      "rewards/margins": 4.022193908691406,
      "rewards/rejected": -3.3404715061187744,
      "step": 617
    },
    {
      "epoch": 4.12,
      "grad_norm": 2.3360986558317807,
      "learning_rate": 1.583219492742667e-06,
      "logits/chosen": -1.0514452457427979,
      "logits/rejected": -1.0899310111999512,
      "logps/chosen": -187.10890197753906,
      "logps/rejected": -323.220947265625,
      "loss": 0.1962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33439451456069946,
      "rewards/margins": 4.1240034103393555,
      "rewards/rejected": -3.7896087169647217,
      "step": 618
    },
    {
      "epoch": 4.126666666666667,
      "grad_norm": 1.614564989867657,
      "learning_rate": 1.5599639533781853e-06,
      "logits/chosen": -0.9206262230873108,
      "logits/rejected": -1.0088454484939575,
      "logps/chosen": -323.50811767578125,
      "logps/rejected": -256.5987854003906,
      "loss": 0.1642,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4685570299625397,
      "rewards/margins": 3.0272328853607178,
      "rewards/rejected": -2.558675765991211,
      "step": 619
    },
    {
      "epoch": 4.133333333333334,
      "grad_norm": 1.2357564029083974,
      "learning_rate": 1.5368660206678031e-06,
      "logits/chosen": -1.0459263324737549,
      "logits/rejected": -1.0380685329437256,
      "logps/chosen": -333.1127014160156,
      "logps/rejected": -407.1658020019531,
      "loss": 0.0541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49294501543045044,
      "rewards/margins": 4.34212589263916,
      "rewards/rejected": -3.8491811752319336,
      "step": 620
    },
    {
      "epoch": 4.14,
      "grad_norm": 6.230085460388967,
      "learning_rate": 1.5139261259352589e-06,
      "logits/chosen": -0.8617516756057739,
      "logits/rejected": -0.9653915166854858,
      "logps/chosen": -348.6598815917969,
      "logps/rejected": -572.1068725585938,
      "loss": 0.4559,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.44530564546585083,
      "rewards/margins": 3.9446473121643066,
      "rewards/rejected": -3.4993414878845215,
      "step": 621
    },
    {
      "epoch": 4.1466666666666665,
      "grad_norm": 1.6599043352068739,
      "learning_rate": 1.4911446975531329e-06,
      "logits/chosen": -1.0889514684677124,
      "logits/rejected": -1.0712743997573853,
      "logps/chosen": -193.52081298828125,
      "logps/rejected": -351.9704895019531,
      "loss": 0.1364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2406722903251648,
      "rewards/margins": 4.454836845397949,
      "rewards/rejected": -4.214164733886719,
      "step": 622
    },
    {
      "epoch": 4.153333333333333,
      "grad_norm": 1.8416081935638982,
      "learning_rate": 1.4685221609348632e-06,
      "logits/chosen": -0.8424835801124573,
      "logits/rejected": -0.964109480381012,
      "logps/chosen": -346.60821533203125,
      "logps/rejected": -388.4207458496094,
      "loss": 0.1224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5071347951889038,
      "rewards/margins": 3.720663547515869,
      "rewards/rejected": -3.213528633117676,
      "step": 623
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.1754176458856596,
      "learning_rate": 1.4460589385267843e-06,
      "logits/chosen": -1.0953633785247803,
      "logits/rejected": -0.8573343753814697,
      "logps/chosen": -132.10125732421875,
      "logps/rejected": -426.23760986328125,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4170305132865906,
      "rewards/margins": 6.240680694580078,
      "rewards/rejected": -5.823649883270264,
      "step": 624
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 1.5039758443211493,
      "learning_rate": 1.4237554498002425e-06,
      "logits/chosen": -1.0122252702713013,
      "logits/rejected": -1.1516979932785034,
      "logps/chosen": -209.14642333984375,
      "logps/rejected": -178.00640869140625,
      "loss": 0.2177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.660114049911499,
      "rewards/margins": 2.917106866836548,
      "rewards/rejected": -2.256992816925049,
      "step": 625
    },
    {
      "epoch": 4.173333333333334,
      "grad_norm": 2.612184759221406,
      "learning_rate": 1.4016121112437787e-06,
      "logits/chosen": -1.0270081758499146,
      "logits/rejected": -0.9281229972839355,
      "logps/chosen": -163.8184051513672,
      "logps/rejected": -439.20074462890625,
      "loss": 0.1384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04411967098712921,
      "rewards/margins": 3.6753334999084473,
      "rewards/rejected": -3.631213665008545,
      "step": 626
    },
    {
      "epoch": 4.18,
      "grad_norm": 1.8629036126830891,
      "learning_rate": 1.3796293363553259e-06,
      "logits/chosen": -0.9688724875450134,
      "logits/rejected": -0.9115641713142395,
      "logps/chosen": -199.28189086914062,
      "logps/rejected": -417.36297607421875,
      "loss": 0.0679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5600955486297607,
      "rewards/margins": 5.429444313049316,
      "rewards/rejected": -4.869349002838135,
      "step": 627
    },
    {
      "epoch": 4.1866666666666665,
      "grad_norm": 1.2676609758711925,
      "learning_rate": 1.3578075356345044e-06,
      "logits/chosen": -1.0545268058776855,
      "logits/rejected": -1.0676934719085693,
      "logps/chosen": -177.06060791015625,
      "logps/rejected": -300.5015869140625,
      "loss": 0.1059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34784749150276184,
      "rewards/margins": 4.3826470375061035,
      "rewards/rejected": -4.034799575805664,
      "step": 628
    },
    {
      "epoch": 4.193333333333333,
      "grad_norm": 2.2844130652474695,
      "learning_rate": 1.3361471165749563e-06,
      "logits/chosen": -1.0264232158660889,
      "logits/rejected": -1.0549248456954956,
      "logps/chosen": -200.65252685546875,
      "logps/rejected": -341.42181396484375,
      "loss": 0.1372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32312148809432983,
      "rewards/margins": 4.644319534301758,
      "rewards/rejected": -4.321198463439941,
      "step": 629
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.4141719206736938,
      "learning_rate": 1.3146484836567263e-06,
      "logits/chosen": -0.9534333348274231,
      "logits/rejected": -0.8425220251083374,
      "logps/chosen": -240.74026489257812,
      "logps/rejected": -551.7000122070312,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31828826665878296,
      "rewards/margins": 4.356367111206055,
      "rewards/rejected": -4.038078308105469,
      "step": 630
    },
    {
      "epoch": 4.206666666666667,
      "grad_norm": 1.1189392867402987,
      "learning_rate": 1.2933120383387132e-06,
      "logits/chosen": -1.0158350467681885,
      "logits/rejected": -1.0452042818069458,
      "logps/chosen": -302.526611328125,
      "logps/rejected": -400.8536071777344,
      "loss": 0.0603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6490730047225952,
      "rewards/margins": 4.224363327026367,
      "rewards/rejected": -3.5752902030944824,
      "step": 631
    },
    {
      "epoch": 4.213333333333333,
      "grad_norm": 0.26872238471958615,
      "learning_rate": 1.2721381790511832e-06,
      "logits/chosen": -1.1340242624282837,
      "logits/rejected": -1.0437041521072388,
      "logps/chosen": -167.89230346679688,
      "logps/rejected": -409.6568603515625,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30216720700263977,
      "rewards/margins": 5.923576831817627,
      "rewards/rejected": -5.621409893035889,
      "step": 632
    },
    {
      "epoch": 4.22,
      "grad_norm": 1.2838859425211104,
      "learning_rate": 1.2511273011883096e-06,
      "logits/chosen": -1.0111346244812012,
      "logits/rejected": -1.0108340978622437,
      "logps/chosen": -279.69232177734375,
      "logps/rejected": -359.66766357421875,
      "loss": 0.0678,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4101264178752899,
      "rewards/margins": 4.527498722076416,
      "rewards/rejected": -4.117372512817383,
      "step": 633
    },
    {
      "epoch": 4.226666666666667,
      "grad_norm": 1.0134451140271523,
      "learning_rate": 1.2302797971008085e-06,
      "logits/chosen": -1.0896421670913696,
      "logits/rejected": -1.0118169784545898,
      "logps/chosen": -192.93939208984375,
      "logps/rejected": -342.4705810546875,
      "loss": 0.0424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6270419359207153,
      "rewards/margins": 5.022395133972168,
      "rewards/rejected": -4.395353317260742,
      "step": 634
    },
    {
      "epoch": 4.233333333333333,
      "grad_norm": 1.8453492809380145,
      "learning_rate": 1.2095960560886e-06,
      "logits/chosen": -1.0925577878952026,
      "logits/rejected": -1.054996371269226,
      "logps/chosen": -190.15365600585938,
      "logps/rejected": -333.3982238769531,
      "loss": 0.1413,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.6550060510635376,
      "rewards/margins": 3.6473917961120605,
      "rewards/rejected": -2.9923861026763916,
      "step": 635
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.3327670318403655,
      "learning_rate": 1.1890764643935393e-06,
      "logits/chosen": -0.632942259311676,
      "logits/rejected": -1.0180017948150635,
      "logps/chosen": -359.5119323730469,
      "logps/rejected": -228.66268920898438,
      "loss": 0.1917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26308539509773254,
      "rewards/margins": 2.20280122756958,
      "rewards/rejected": -1.93971586227417,
      "step": 636
    },
    {
      "epoch": 4.246666666666667,
      "grad_norm": 2.121680528046586,
      "learning_rate": 1.168721405192218e-06,
      "logits/chosen": -0.9704635143280029,
      "logits/rejected": -1.020140528678894,
      "logps/chosen": -359.72210693359375,
      "logps/rejected": -368.77496337890625,
      "loss": 0.1454,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.4851413369178772,
      "rewards/margins": 3.59735369682312,
      "rewards/rejected": -3.1122124195098877,
      "step": 637
    },
    {
      "epoch": 4.253333333333333,
      "grad_norm": 1.8507044610791592,
      "learning_rate": 1.1485312585887887e-06,
      "logits/chosen": -0.9670556783676147,
      "logits/rejected": -0.983721911907196,
      "logps/chosen": -272.78045654296875,
      "logps/rejected": -475.22772216796875,
      "loss": 0.1242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2989742159843445,
      "rewards/margins": 4.660297870635986,
      "rewards/rejected": -4.361323356628418,
      "step": 638
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.9686746567991469,
      "learning_rate": 1.1285064016078784e-06,
      "logits/chosen": -0.8318328261375427,
      "logits/rejected": -0.9828910231590271,
      "logps/chosen": -264.9646301269531,
      "logps/rejected": -371.947509765625,
      "loss": 0.0397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7765864133834839,
      "rewards/margins": 5.0284247398376465,
      "rewards/rejected": -4.251838684082031,
      "step": 639
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 2.2040447723008905,
      "learning_rate": 1.1086472081875488e-06,
      "logits/chosen": -0.8795393705368042,
      "logits/rejected": -1.060670018196106,
      "logps/chosen": -249.14479064941406,
      "logps/rejected": -274.4041442871094,
      "loss": 0.1911,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5336060523986816,
      "rewards/margins": 3.470646381378174,
      "rewards/rejected": -2.9370405673980713,
      "step": 640
    },
    {
      "epoch": 4.273333333333333,
      "grad_norm": 0.28453338215849716,
      "learning_rate": 1.0889540491723106e-06,
      "logits/chosen": -0.9459443688392639,
      "logits/rejected": -0.9482123851776123,
      "logps/chosen": -243.20468139648438,
      "logps/rejected": -378.08917236328125,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8279769420623779,
      "rewards/margins": 5.009661674499512,
      "rewards/rejected": -4.181684494018555,
      "step": 641
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.9984759592171035,
      "learning_rate": 1.0694272923061933e-06,
      "logits/chosen": -1.1128785610198975,
      "logits/rejected": -1.168522834777832,
      "logps/chosen": -191.40341186523438,
      "logps/rejected": -327.3077392578125,
      "loss": 0.1875,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.2530926764011383,
      "rewards/margins": 4.620201587677002,
      "rewards/rejected": -4.3671088218688965,
      "step": 642
    },
    {
      "epoch": 4.286666666666667,
      "grad_norm": 2.985703736740949,
      "learning_rate": 1.0500673022258923e-06,
      "logits/chosen": -1.1430325508117676,
      "logits/rejected": -1.1134077310562134,
      "logps/chosen": -144.6497802734375,
      "logps/rejected": -337.16015625,
      "loss": 0.1285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4383866488933563,
      "rewards/margins": 3.957282304763794,
      "rewards/rejected": -3.5188961029052734,
      "step": 643
    },
    {
      "epoch": 4.293333333333333,
      "grad_norm": 0.6496960479482259,
      "learning_rate": 1.030874440453944e-06,
      "logits/chosen": -0.9498090147972107,
      "logits/rejected": -1.0419306755065918,
      "logps/chosen": -307.54766845703125,
      "logps/rejected": -450.7884521484375,
      "loss": 0.0331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5466073751449585,
      "rewards/margins": 4.845519065856934,
      "rewards/rejected": -4.298911094665527,
      "step": 644
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.7107711084009325,
      "learning_rate": 1.0118490653919855e-06,
      "logits/chosen": -0.9727873206138611,
      "logits/rejected": -0.9771808385848999,
      "logps/chosen": -249.81040954589844,
      "logps/rejected": -404.814208984375,
      "loss": 0.1655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39304620027542114,
      "rewards/margins": 3.3793277740478516,
      "rewards/rejected": -2.9862818717956543,
      "step": 645
    },
    {
      "epoch": 4.306666666666667,
      "grad_norm": 1.0117581039492505,
      "learning_rate": 9.92991532314057e-07,
      "logits/chosen": -1.0252039432525635,
      "logits/rejected": -1.0856099128723145,
      "logps/chosen": -265.252197265625,
      "logps/rejected": -265.30035400390625,
      "loss": 0.0715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8299275636672974,
      "rewards/margins": 4.42511510848999,
      "rewards/rejected": -3.5951874256134033,
      "step": 646
    },
    {
      "epoch": 4.3133333333333335,
      "grad_norm": 2.3519029339204236,
      "learning_rate": 9.743021933599695e-07,
      "logits/chosen": -1.0411577224731445,
      "logits/rejected": -1.0724881887435913,
      "logps/chosen": -203.24276733398438,
      "logps/rejected": -358.2577209472656,
      "loss": 0.2343,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.011757727712392807,
      "rewards/margins": 4.423085689544678,
      "rewards/rejected": -4.43484354019165,
      "step": 647
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.5080037366330021,
      "learning_rate": 9.557813975287266e-07,
      "logits/chosen": -1.0274348258972168,
      "logits/rejected": -1.0800807476043701,
      "logps/chosen": -161.11538696289062,
      "logps/rejected": -337.4106750488281,
      "loss": 0.0805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38390594720840454,
      "rewards/margins": 4.6451239585876465,
      "rewards/rejected": -4.2612175941467285,
      "step": 648
    },
    {
      "epoch": 4.326666666666666,
      "grad_norm": 1.0417342291220206,
      "learning_rate": 9.374294906720083e-07,
      "logits/chosen": -1.0106195211410522,
      "logits/rejected": -1.0714869499206543,
      "logps/chosen": -190.1214141845703,
      "logps/rejected": -294.8800354003906,
      "loss": 0.0564,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7905104160308838,
      "rewards/margins": 4.773816108703613,
      "rewards/rejected": -3.9833056926727295,
      "step": 649
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 2.5558402817362924,
      "learning_rate": 9.192468154877187e-07,
      "logits/chosen": -0.8786693215370178,
      "logits/rejected": -0.9617934823036194,
      "logps/chosen": -211.8116455078125,
      "logps/rejected": -345.32122802734375,
      "loss": 0.2295,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1408120095729828,
      "rewards/margins": 3.0842554569244385,
      "rewards/rejected": -2.9434432983398438,
      "step": 650
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.3661660535645478,
      "learning_rate": 9.012337115135772e-07,
      "logits/chosen": -1.1375463008880615,
      "logits/rejected": -0.958635687828064,
      "logps/chosen": -208.26902770996094,
      "logps/rejected": -456.57208251953125,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7672247290611267,
      "rewards/margins": 5.9255523681640625,
      "rewards/rejected": -5.158327579498291,
      "step": 651
    },
    {
      "epoch": 4.346666666666667,
      "grad_norm": 2.052840414311858,
      "learning_rate": 8.833905151207833e-07,
      "logits/chosen": -0.7425009608268738,
      "logits/rejected": -0.932124137878418,
      "logps/chosen": -266.5763244628906,
      "logps/rejected": -314.29962158203125,
      "loss": 0.1481,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3281186819076538,
      "rewards/margins": 3.3173253536224365,
      "rewards/rejected": -2.989206552505493,
      "step": 652
    },
    {
      "epoch": 4.3533333333333335,
      "grad_norm": 1.6833386150440914,
      "learning_rate": 8.657175595077317e-07,
      "logits/chosen": -0.9832528829574585,
      "logits/rejected": -1.1464354991912842,
      "logps/chosen": -251.9607696533203,
      "logps/rejected": -285.1187438964844,
      "loss": 0.1145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06917322427034378,
      "rewards/margins": 3.530170202255249,
      "rewards/rejected": -3.5993432998657227,
      "step": 653
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.1580889229011098,
      "learning_rate": 8.482151746937983e-07,
      "logits/chosen": -0.9829301238059998,
      "logits/rejected": -1.0076850652694702,
      "logps/chosen": -264.2371520996094,
      "logps/rejected": -378.37152099609375,
      "loss": 0.1001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4909251630306244,
      "rewards/margins": 4.431108474731445,
      "rewards/rejected": -3.940183401107788,
      "step": 654
    },
    {
      "epoch": 4.366666666666666,
      "grad_norm": 1.153753782206212,
      "learning_rate": 8.308836875131665e-07,
      "logits/chosen": -1.0501641035079956,
      "logits/rejected": -1.1172703504562378,
      "logps/chosen": -230.08201599121094,
      "logps/rejected": -349.343994140625,
      "loss": 0.062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4495503604412079,
      "rewards/margins": 4.586285591125488,
      "rewards/rejected": -4.136734962463379,
      "step": 655
    },
    {
      "epoch": 4.373333333333333,
      "grad_norm": 2.8723244864259794,
      "learning_rate": 8.137234216087353e-07,
      "logits/chosen": -0.8245174288749695,
      "logits/rejected": -1.0164462327957153,
      "logps/chosen": -341.888427734375,
      "logps/rejected": -321.7726745605469,
      "loss": 0.1743,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.23346388339996338,
      "rewards/margins": 3.5510127544403076,
      "rewards/rejected": -3.3175487518310547,
      "step": 656
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.3175703386064814,
      "learning_rate": 7.967346974260626e-07,
      "logits/chosen": -0.9537734389305115,
      "logits/rejected": -1.0198041200637817,
      "logps/chosen": -261.54339599609375,
      "logps/rejected": -353.6308288574219,
      "loss": 0.0669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8263421058654785,
      "rewards/margins": 4.505164623260498,
      "rewards/rejected": -3.6788227558135986,
      "step": 657
    },
    {
      "epoch": 4.386666666666667,
      "grad_norm": 1.2118438282302615,
      "learning_rate": 7.799178322073941e-07,
      "logits/chosen": -1.1169416904449463,
      "logits/rejected": -1.1765177249908447,
      "logps/chosen": -191.28704833984375,
      "logps/rejected": -232.22154235839844,
      "loss": 0.1324,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.550674557685852,
      "rewards/margins": 3.646684169769287,
      "rewards/rejected": -3.0960094928741455,
      "step": 658
    },
    {
      "epoch": 4.3933333333333335,
      "grad_norm": 1.4072139403222526,
      "learning_rate": 7.632731399857329e-07,
      "logits/chosen": -0.9897578954696655,
      "logits/rejected": -0.8812900185585022,
      "logps/chosen": -198.73924255371094,
      "logps/rejected": -384.60552978515625,
      "loss": 0.0741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39699846506118774,
      "rewards/margins": 4.571828842163086,
      "rewards/rejected": -4.174830436706543,
      "step": 659
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.8215058962118933,
      "learning_rate": 7.468009315789748e-07,
      "logits/chosen": -1.0579755306243896,
      "logits/rejected": -0.9435127973556519,
      "logps/chosen": -175.95204162597656,
      "logps/rejected": -417.8290710449219,
      "loss": 0.1007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2518801987171173,
      "rewards/margins": 3.652848243713379,
      "rewards/rejected": -3.400968074798584,
      "step": 660
    },
    {
      "epoch": 4.406666666666666,
      "grad_norm": 1.8235602487077618,
      "learning_rate": 7.305015145841055e-07,
      "logits/chosen": -0.9162260890007019,
      "logits/rejected": -0.9452723264694214,
      "logps/chosen": -294.91455078125,
      "logps/rejected": -366.7773132324219,
      "loss": 0.1215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5484082698822021,
      "rewards/margins": 3.3659000396728516,
      "rewards/rejected": -2.8174917697906494,
      "step": 661
    },
    {
      "epoch": 4.413333333333333,
      "grad_norm": 1.865542784753109,
      "learning_rate": 7.143751933714583e-07,
      "logits/chosen": -1.0272830724716187,
      "logits/rejected": -0.9938216209411621,
      "logps/chosen": -279.91912841796875,
      "logps/rejected": -427.2768249511719,
      "loss": 0.0953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19312752783298492,
      "rewards/margins": 4.607979774475098,
      "rewards/rejected": -4.801107406616211,
      "step": 662
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.21627658409098097,
      "learning_rate": 6.984222690790277e-07,
      "logits/chosen": -1.0293197631835938,
      "logits/rejected": -0.9757888317108154,
      "logps/chosen": -176.66465759277344,
      "logps/rejected": -410.468505859375,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04284285008907318,
      "rewards/margins": 5.161410331726074,
      "rewards/rejected": -5.204253196716309,
      "step": 663
    },
    {
      "epoch": 4.426666666666667,
      "grad_norm": 0.8810187151260084,
      "learning_rate": 6.826430396068451e-07,
      "logits/chosen": -1.0999642610549927,
      "logits/rejected": -0.9241397380828857,
      "logps/chosen": -215.26028442382812,
      "logps/rejected": -373.29107666015625,
      "loss": 0.0344,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5940042734146118,
      "rewards/margins": 5.1170854568481445,
      "rewards/rejected": -4.523081302642822,
      "step": 664
    },
    {
      "epoch": 4.433333333333334,
      "grad_norm": 1.8598743697777549,
      "learning_rate": 6.67037799611423e-07,
      "logits/chosen": -0.662399411201477,
      "logits/rejected": -0.9019617438316345,
      "logps/chosen": -477.70159912109375,
      "logps/rejected": -379.9141845703125,
      "loss": 0.085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1447882652282715,
      "rewards/margins": 3.4694361686706543,
      "rewards/rejected": -2.324647903442383,
      "step": 665
    },
    {
      "epoch": 4.44,
      "grad_norm": 2.2078368750520494,
      "learning_rate": 6.516068405002441e-07,
      "logits/chosen": -0.881475567817688,
      "logits/rejected": -1.0678894519805908,
      "logps/chosen": -241.8048095703125,
      "logps/rejected": -269.6764831542969,
      "loss": 0.1285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34095141291618347,
      "rewards/margins": 3.2726945877075195,
      "rewards/rejected": -2.9317429065704346,
      "step": 666
    },
    {
      "epoch": 4.446666666666666,
      "grad_norm": 3.3368863402418834,
      "learning_rate": 6.363504504263207e-07,
      "logits/chosen": -1.1086708307266235,
      "logits/rejected": -1.0265008211135864,
      "logps/chosen": -215.22940063476562,
      "logps/rejected": -336.80908203125,
      "loss": 0.2061,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.1730569452047348,
      "rewards/margins": 3.792646884918213,
      "rewards/rejected": -3.6195900440216064,
      "step": 667
    },
    {
      "epoch": 4.453333333333333,
      "grad_norm": 1.493280140548155,
      "learning_rate": 6.212689142828232e-07,
      "logits/chosen": -0.8656613826751709,
      "logits/rejected": -0.8882724642753601,
      "logps/chosen": -275.9356994628906,
      "logps/rejected": -478.5135803222656,
      "loss": 0.0598,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27068787813186646,
      "rewards/margins": 5.3994140625,
      "rewards/rejected": -5.128726482391357,
      "step": 668
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.29748457516023785,
      "learning_rate": 6.063625136977447e-07,
      "logits/chosen": -1.151518702507019,
      "logits/rejected": -1.1340595483779907,
      "logps/chosen": -219.405029296875,
      "logps/rejected": -356.2817077636719,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6303097009658813,
      "rewards/margins": 5.416952133178711,
      "rewards/rejected": -4.786642074584961,
      "step": 669
    },
    {
      "epoch": 4.466666666666667,
      "grad_norm": 1.280272227038663,
      "learning_rate": 5.916315270286588e-07,
      "logits/chosen": -1.1497806310653687,
      "logits/rejected": -1.0980079174041748,
      "logps/chosen": -210.04835510253906,
      "logps/rejected": -305.71173095703125,
      "loss": 0.0559,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13550469279289246,
      "rewards/margins": 4.473386764526367,
      "rewards/rejected": -4.337882041931152,
      "step": 670
    },
    {
      "epoch": 4.473333333333334,
      "grad_norm": 0.649125228554171,
      "learning_rate": 5.770762293575083e-07,
      "logits/chosen": -0.956670880317688,
      "logits/rejected": -0.975896418094635,
      "logps/chosen": -278.30804443359375,
      "logps/rejected": -373.6712646484375,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.767857551574707,
      "rewards/margins": 5.107848644256592,
      "rewards/rejected": -4.339991092681885,
      "step": 671
    },
    {
      "epoch": 4.48,
      "grad_norm": 2.2758858727064317,
      "learning_rate": 5.626968924854714e-07,
      "logits/chosen": -0.7597765326499939,
      "logits/rejected": -0.934245765209198,
      "logps/chosen": -395.49420166015625,
      "logps/rejected": -358.864990234375,
      "loss": 0.2811,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21109476685523987,
      "rewards/margins": 1.8187097311019897,
      "rewards/rejected": -1.6076149940490723,
      "step": 672
    },
    {
      "epoch": 4.486666666666666,
      "grad_norm": 2.406232164985649,
      "learning_rate": 5.484937849278937e-07,
      "logits/chosen": -0.7181745767593384,
      "logits/rejected": -0.9144014716148376,
      "logps/chosen": -305.09368896484375,
      "logps/rejected": -289.72833251953125,
      "loss": 0.2245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5617689490318298,
      "rewards/margins": 1.925038456916809,
      "rewards/rejected": -1.363269329071045,
      "step": 673
    },
    {
      "epoch": 4.493333333333333,
      "grad_norm": 2.424581086460962,
      "learning_rate": 5.344671719092664e-07,
      "logits/chosen": -0.9461824893951416,
      "logits/rejected": -1.0445042848587036,
      "logps/chosen": -237.979248046875,
      "logps/rejected": -319.1380920410156,
      "loss": 0.1563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36154788732528687,
      "rewards/margins": 3.3710262775421143,
      "rewards/rejected": -3.0094783306121826,
      "step": 674
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.8811700392043635,
      "learning_rate": 5.206173153582705e-07,
      "logits/chosen": -0.9631562829017639,
      "logits/rejected": -0.8917224407196045,
      "logps/chosen": -224.72137451171875,
      "logps/rejected": -302.9478454589844,
      "loss": 0.1633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40078070759773254,
      "rewards/margins": 3.928877115249634,
      "rewards/rejected": -3.5280964374542236,
      "step": 675
    },
    {
      "epoch": 4.506666666666667,
      "grad_norm": 5.109334869693798,
      "learning_rate": 5.069444739029006e-07,
      "logits/chosen": -1.156534194946289,
      "logits/rejected": -1.1947129964828491,
      "logps/chosen": -179.9077911376953,
      "logps/rejected": -285.1882019042969,
      "loss": 0.3465,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.1797541081905365,
      "rewards/margins": 3.4811811447143555,
      "rewards/rejected": -3.660935401916504,
      "step": 676
    },
    {
      "epoch": 4.513333333333334,
      "grad_norm": 2.2256796709569824,
      "learning_rate": 4.934489028656164e-07,
      "logits/chosen": -0.9045329689979553,
      "logits/rejected": -1.1063464879989624,
      "logps/chosen": -336.7953796386719,
      "logps/rejected": -245.84938049316406,
      "loss": 0.2226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4921276569366455,
      "rewards/margins": 2.7319226264953613,
      "rewards/rejected": -2.239794969558716,
      "step": 677
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.7723417552044558,
      "learning_rate": 4.801308542585892e-07,
      "logits/chosen": -0.9935095906257629,
      "logits/rejected": -0.9353812336921692,
      "logps/chosen": -183.00985717773438,
      "logps/rejected": -325.09124755859375,
      "loss": 0.1282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3147144019603729,
      "rewards/margins": 4.071327209472656,
      "rewards/rejected": -3.756612777709961,
      "step": 678
    },
    {
      "epoch": 4.526666666666666,
      "grad_norm": 1.9255033528534755,
      "learning_rate": 4.669905767789884e-07,
      "logits/chosen": -0.888137936592102,
      "logits/rejected": -1.1143808364868164,
      "logps/chosen": -306.4512634277344,
      "logps/rejected": -307.82763671875,
      "loss": 0.1297,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13994437456130981,
      "rewards/margins": 3.6921374797821045,
      "rewards/rejected": -3.8320820331573486,
      "step": 679
    },
    {
      "epoch": 4.533333333333333,
      "grad_norm": 0.53103358404634,
      "learning_rate": 4.54028315804339e-07,
      "logits/chosen": -0.8756752014160156,
      "logits/rejected": -1.1122556924819946,
      "logps/chosen": -301.5333251953125,
      "logps/rejected": -319.3582763671875,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8014838099479675,
      "rewards/margins": 4.616132736206055,
      "rewards/rejected": -3.8146488666534424,
      "step": 680
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.1010431832147463,
      "learning_rate": 4.4124431338794403e-07,
      "logits/chosen": -0.6851564049720764,
      "logits/rejected": -0.7041743993759155,
      "logps/chosen": -542.129150390625,
      "logps/rejected": -569.84033203125,
      "loss": 0.1125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9519745111465454,
      "rewards/margins": 2.8836655616760254,
      "rewards/rejected": -1.9316911697387695,
      "step": 681
    },
    {
      "epoch": 4.546666666666667,
      "grad_norm": 1.1137077719135766,
      "learning_rate": 4.2863880825435687e-07,
      "logits/chosen": -1.0226571559906006,
      "logits/rejected": -1.0876291990280151,
      "logps/chosen": -311.83154296875,
      "logps/rejected": -290.2528381347656,
      "loss": 0.0868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8126964569091797,
      "rewards/margins": 4.100707054138184,
      "rewards/rejected": -3.288010597229004,
      "step": 682
    },
    {
      "epoch": 4.553333333333334,
      "grad_norm": 2.023134422433505,
      "learning_rate": 4.162120357949284e-07,
      "logits/chosen": -0.8480364680290222,
      "logits/rejected": -1.0114480257034302,
      "logps/chosen": -362.85455322265625,
      "logps/rejected": -279.81719970703125,
      "loss": 0.1546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7716360092163086,
      "rewards/margins": 3.2785120010375977,
      "rewards/rejected": -2.506875991821289,
      "step": 683
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.9233612888338592,
      "learning_rate": 4.039642280634104e-07,
      "logits/chosen": -1.0316585302352905,
      "logits/rejected": -1.0808311700820923,
      "logps/chosen": -213.50839233398438,
      "logps/rejected": -268.42254638671875,
      "loss": 0.11,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6114218831062317,
      "rewards/margins": 3.940492868423462,
      "rewards/rejected": -3.329070806503296,
      "step": 684
    },
    {
      "epoch": 4.566666666666666,
      "grad_norm": 0.8638924208838359,
      "learning_rate": 3.9189561377162343e-07,
      "logits/chosen": -0.9012805819511414,
      "logits/rejected": -0.9180031418800354,
      "logps/chosen": -228.1464080810547,
      "logps/rejected": -373.47393798828125,
      "loss": 0.0416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44295158982276917,
      "rewards/margins": 4.140606880187988,
      "rewards/rejected": -3.697655200958252,
      "step": 685
    },
    {
      "epoch": 4.573333333333333,
      "grad_norm": 1.0810675891633592,
      "learning_rate": 3.800064182851804e-07,
      "logits/chosen": -1.120719075202942,
      "logits/rejected": -1.0778106451034546,
      "logps/chosen": -176.210205078125,
      "logps/rejected": -366.79345703125,
      "loss": 0.059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31549012660980225,
      "rewards/margins": 4.916186809539795,
      "rewards/rejected": -4.600696563720703,
      "step": 686
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.198137274068845,
      "learning_rate": 3.682968636192863e-07,
      "logits/chosen": -1.0618826150894165,
      "logits/rejected": -1.1324386596679688,
      "logps/chosen": -307.7878723144531,
      "logps/rejected": -318.2658996582031,
      "loss": 0.0596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5762555599212646,
      "rewards/margins": 4.1539530754089355,
      "rewards/rejected": -3.577697277069092,
      "step": 687
    },
    {
      "epoch": 4.586666666666667,
      "grad_norm": 2.7827408470254826,
      "learning_rate": 3.567671684345875e-07,
      "logits/chosen": -0.8353539109230042,
      "logits/rejected": -1.0781233310699463,
      "logps/chosen": -283.9857177734375,
      "logps/rejected": -257.53680419921875,
      "loss": 0.2645,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.29469382762908936,
      "rewards/margins": 2.9393796920776367,
      "rewards/rejected": -2.644685745239258,
      "step": 688
    },
    {
      "epoch": 4.593333333333334,
      "grad_norm": 1.5289197044969602,
      "learning_rate": 3.4541754803308567e-07,
      "logits/chosen": -1.1072065830230713,
      "logits/rejected": -1.0431827306747437,
      "logps/chosen": -154.93348693847656,
      "logps/rejected": -345.2240905761719,
      "loss": 0.0728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3481467068195343,
      "rewards/margins": 5.245147228240967,
      "rewards/rejected": -4.897000312805176,
      "step": 689
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.074907172431265,
      "learning_rate": 3.342482143541281e-07,
      "logits/chosen": -0.9405832290649414,
      "logits/rejected": -0.9922149181365967,
      "logps/chosen": -388.59552001953125,
      "logps/rejected": -364.7393798828125,
      "loss": 0.0607,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.281866192817688,
      "rewards/margins": 4.124991416931152,
      "rewards/rejected": -3.843125343322754,
      "step": 690
    },
    {
      "epoch": 4.6066666666666665,
      "grad_norm": 1.0069037783658026,
      "learning_rate": 3.23259375970435e-07,
      "logits/chosen": -1.0255061388015747,
      "logits/rejected": -1.0069202184677124,
      "logps/chosen": -193.94430541992188,
      "logps/rejected": -432.1719970703125,
      "loss": 0.0419,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29632800817489624,
      "rewards/margins": 5.532991886138916,
      "rewards/rejected": -5.236663818359375,
      "step": 691
    },
    {
      "epoch": 4.613333333333333,
      "grad_norm": 0.9886684337783664,
      "learning_rate": 3.124512380842204e-07,
      "logits/chosen": -0.960204005241394,
      "logits/rejected": -0.9743989109992981,
      "logps/chosen": -227.70240783691406,
      "logps/rejected": -389.97821044921875,
      "loss": 0.0444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5735692977905273,
      "rewards/margins": 4.489692687988281,
      "rewards/rejected": -3.916123867034912,
      "step": 692
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.7864060584541207,
      "learning_rate": 3.0182400252334656e-07,
      "logits/chosen": -1.11262047290802,
      "logits/rejected": -1.1452558040618896,
      "logps/chosen": -191.26864624023438,
      "logps/rejected": -384.00225830078125,
      "loss": 0.0351,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6533404588699341,
      "rewards/margins": 5.588366508483887,
      "rewards/rejected": -4.935026168823242,
      "step": 693
    },
    {
      "epoch": 4.626666666666667,
      "grad_norm": 1.5137840180232636,
      "learning_rate": 2.9137786773756114e-07,
      "logits/chosen": -1.116454839706421,
      "logits/rejected": -0.9945472478866577,
      "logps/chosen": -280.57720947265625,
      "logps/rejected": -475.93597412109375,
      "loss": 0.0628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5678388476371765,
      "rewards/margins": 5.138027191162109,
      "rewards/rejected": -4.570188045501709,
      "step": 694
    },
    {
      "epoch": 4.633333333333333,
      "grad_norm": 1.5387125924565797,
      "learning_rate": 2.811130287947972e-07,
      "logits/chosen": -0.8511016368865967,
      "logits/rejected": -1.0441254377365112,
      "logps/chosen": -237.2269744873047,
      "logps/rejected": -301.46929931640625,
      "loss": 0.0967,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48281562328338623,
      "rewards/margins": 3.564620018005371,
      "rewards/rejected": -3.0818042755126953,
      "step": 695
    },
    {
      "epoch": 4.64,
      "grad_norm": 1.9117293481879873,
      "learning_rate": 2.710296773775167e-07,
      "logits/chosen": -1.0826101303100586,
      "logits/rejected": -1.1034122705459595,
      "logps/chosen": -194.9263916015625,
      "logps/rejected": -393.26129150390625,
      "loss": 0.0605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47694242000579834,
      "rewards/margins": 4.616211891174316,
      "rewards/rejected": -4.1392693519592285,
      "step": 696
    },
    {
      "epoch": 4.6466666666666665,
      "grad_norm": 1.3406235007964602,
      "learning_rate": 2.61128001779144e-07,
      "logits/chosen": -1.0355743169784546,
      "logits/rejected": -1.069364309310913,
      "logps/chosen": -337.6773681640625,
      "logps/rejected": -435.446044921875,
      "loss": 0.0547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6975380778312683,
      "rewards/margins": 4.226325988769531,
      "rewards/rejected": -3.5287880897521973,
      "step": 697
    },
    {
      "epoch": 4.653333333333333,
      "grad_norm": 1.4132815570314325,
      "learning_rate": 2.514081869005458e-07,
      "logits/chosen": -0.9153978228569031,
      "logits/rejected": -1.0343701839447021,
      "logps/chosen": -329.6092834472656,
      "logps/rejected": -365.67205810546875,
      "loss": 0.0682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7426998615264893,
      "rewards/margins": 4.870007038116455,
      "rewards/rejected": -4.127306938171387,
      "step": 698
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.7369461933382526,
      "learning_rate": 2.418704142465722e-07,
      "logits/chosen": -0.9467041492462158,
      "logits/rejected": -1.0065912008285522,
      "logps/chosen": -251.29776000976562,
      "logps/rejected": -310.7799377441406,
      "loss": 0.1528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6745494604110718,
      "rewards/margins": 4.460705757141113,
      "rewards/rejected": -3.78615665435791,
      "step": 699
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 1.7664348804122558,
      "learning_rate": 2.325148619226758e-07,
      "logits/chosen": -0.9654425382614136,
      "logits/rejected": -1.0104057788848877,
      "logps/chosen": -248.9813232421875,
      "logps/rejected": -449.5504150390625,
      "loss": 0.0954,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45254284143447876,
      "rewards/margins": 4.383143424987793,
      "rewards/rejected": -3.930600643157959,
      "step": 700
    },
    {
      "epoch": 4.673333333333334,
      "grad_norm": 1.0944327267204004,
      "learning_rate": 2.2334170463158223e-07,
      "logits/chosen": -0.8120108842849731,
      "logits/rejected": -1.0307550430297852,
      "logps/chosen": -347.9803466796875,
      "logps/rejected": -271.69854736328125,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43790650367736816,
      "rewards/margins": 3.839282512664795,
      "rewards/rejected": -3.401376247406006,
      "step": 701
    },
    {
      "epoch": 4.68,
      "grad_norm": 1.744401559822279,
      "learning_rate": 2.1435111367002826e-07,
      "logits/chosen": -0.9609230160713196,
      "logits/rejected": -1.154889464378357,
      "logps/chosen": -309.8420715332031,
      "logps/rejected": -336.9044189453125,
      "loss": 0.1142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6879864931106567,
      "rewards/margins": 4.778359413146973,
      "rewards/rejected": -4.0903730392456055,
      "step": 702
    },
    {
      "epoch": 4.6866666666666665,
      "grad_norm": 1.5192713968848943,
      "learning_rate": 2.055432569255622e-07,
      "logits/chosen": -1.0519145727157593,
      "logits/rejected": -0.9336754083633423,
      "logps/chosen": -270.82037353515625,
      "logps/rejected": -396.62371826171875,
      "loss": 0.1115,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7145527601242065,
      "rewards/margins": 4.445128440856934,
      "rewards/rejected": -3.7305760383605957,
      "step": 703
    },
    {
      "epoch": 4.693333333333333,
      "grad_norm": 1.706773542072784,
      "learning_rate": 1.9691829887340864e-07,
      "logits/chosen": -0.9111692309379578,
      "logits/rejected": -0.932311475276947,
      "logps/chosen": -249.54139709472656,
      "logps/rejected": -413.8453674316406,
      "loss": 0.148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8112255334854126,
      "rewards/margins": 3.471339225769043,
      "rewards/rejected": -2.66011381149292,
      "step": 704
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.0663087122540058,
      "learning_rate": 1.8847640057339966e-07,
      "logits/chosen": -0.7373263239860535,
      "logits/rejected": -0.9030197262763977,
      "logps/chosen": -345.21759033203125,
      "logps/rejected": -395.4393310546875,
      "loss": 0.0632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41580337285995483,
      "rewards/margins": 4.016225337982178,
      "rewards/rejected": -3.600421905517578,
      "step": 705
    },
    {
      "epoch": 4.706666666666667,
      "grad_norm": 1.2051844619501406,
      "learning_rate": 1.802177196669619e-07,
      "logits/chosen": -1.0947760343551636,
      "logits/rejected": -1.0916019678115845,
      "logps/chosen": -299.64227294921875,
      "logps/rejected": -338.502197265625,
      "loss": 0.0632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6287833452224731,
      "rewards/margins": 4.782087326049805,
      "rewards/rejected": -4.153304100036621,
      "step": 706
    },
    {
      "epoch": 4.713333333333333,
      "grad_norm": 2.0023266848500394,
      "learning_rate": 1.7214241037418312e-07,
      "logits/chosen": -1.1329213380813599,
      "logits/rejected": -1.152020812034607,
      "logps/chosen": -219.51797485351562,
      "logps/rejected": -335.9915771484375,
      "loss": 0.1904,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10842780768871307,
      "rewards/margins": 3.9647397994995117,
      "rewards/rejected": -3.8563120365142822,
      "step": 707
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.14668336703667031,
      "learning_rate": 1.6425062349091914e-07,
      "logits/chosen": -0.9890159368515015,
      "logits/rejected": -1.0703535079956055,
      "logps/chosen": -212.5064239501953,
      "logps/rejected": -536.5506591796875,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7294934391975403,
      "rewards/margins": 6.573951721191406,
      "rewards/rejected": -5.84445858001709,
      "step": 708
    },
    {
      "epoch": 4.726666666666667,
      "grad_norm": 1.698621412495342,
      "learning_rate": 1.5654250638598601e-07,
      "logits/chosen": -1.03026282787323,
      "logits/rejected": -0.9352344870567322,
      "logps/chosen": -152.07763671875,
      "logps/rejected": -393.15740966796875,
      "loss": 0.0855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2852441966533661,
      "rewards/margins": 4.281302452087402,
      "rewards/rejected": -3.9960579872131348,
      "step": 709
    },
    {
      "epoch": 4.733333333333333,
      "grad_norm": 1.8991542765988898,
      "learning_rate": 1.4901820299840997e-07,
      "logits/chosen": -1.023714303970337,
      "logits/rejected": -1.0132349729537964,
      "logps/chosen": -192.3830108642578,
      "logps/rejected": -360.9248962402344,
      "loss": 0.1722,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.14523032307624817,
      "rewards/margins": 3.9719700813293457,
      "rewards/rejected": -3.826739549636841,
      "step": 710
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.8564925316698231,
      "learning_rate": 1.4167785383472855e-07,
      "logits/chosen": -0.9540999531745911,
      "logits/rejected": -0.9785588979721069,
      "logps/chosen": -216.22927856445312,
      "logps/rejected": -448.694580078125,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5332509279251099,
      "rewards/margins": 5.526077747344971,
      "rewards/rejected": -4.99282693862915,
      "step": 711
    },
    {
      "epoch": 4.746666666666667,
      "grad_norm": 0.44084864818144653,
      "learning_rate": 1.345215959663837e-07,
      "logits/chosen": -1.094941258430481,
      "logits/rejected": -0.9899632930755615,
      "logps/chosen": -196.36700439453125,
      "logps/rejected": -496.6524963378906,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1879306137561798,
      "rewards/margins": 5.373316287994385,
      "rewards/rejected": -5.5612473487854,
      "step": 712
    },
    {
      "epoch": 4.753333333333333,
      "grad_norm": 1.228033168164617,
      "learning_rate": 1.2754956302714617e-07,
      "logits/chosen": -1.0560097694396973,
      "logits/rejected": -1.0398646593093872,
      "logps/chosen": -189.0537872314453,
      "logps/rejected": -392.1207275390625,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014194309711456299,
      "rewards/margins": 5.061552047729492,
      "rewards/rejected": -5.047357559204102,
      "step": 713
    },
    {
      "epoch": 4.76,
      "grad_norm": 2.0162129099225674,
      "learning_rate": 1.207618852106285e-07,
      "logits/chosen": -0.9517574906349182,
      "logits/rejected": -1.1646819114685059,
      "logps/chosen": -272.1679992675781,
      "logps/rejected": -272.0618896484375,
      "loss": 0.0991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5372415781021118,
      "rewards/margins": 3.235419273376465,
      "rewards/rejected": -2.6981775760650635,
      "step": 714
    },
    {
      "epoch": 4.766666666666667,
      "grad_norm": 2.073431005518041,
      "learning_rate": 1.1415868926785256e-07,
      "logits/chosen": -0.9835641384124756,
      "logits/rejected": -0.9400555491447449,
      "logps/chosen": -140.76715087890625,
      "logps/rejected": -385.2798156738281,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3943769335746765,
      "rewards/margins": 4.818197250366211,
      "rewards/rejected": -4.423820495605469,
      "step": 715
    },
    {
      "epoch": 4.773333333333333,
      "grad_norm": 1.8933549827806493,
      "learning_rate": 1.0774009850488154e-07,
      "logits/chosen": -1.0440969467163086,
      "logits/rejected": -1.0377379655838013,
      "logps/chosen": -315.99835205078125,
      "logps/rejected": -387.5281982421875,
      "loss": 0.098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49423936009407043,
      "rewards/margins": 3.7378287315368652,
      "rewards/rejected": -3.243589401245117,
      "step": 716
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.8585812660397156,
      "learning_rate": 1.0150623278051719e-07,
      "logits/chosen": -1.0553539991378784,
      "logits/rejected": -1.1368992328643799,
      "logps/chosen": -228.53041076660156,
      "logps/rejected": -243.93145751953125,
      "loss": 0.1405,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.5099085569381714,
      "rewards/margins": 4.0060858726501465,
      "rewards/rejected": -3.4961774349212646,
      "step": 717
    },
    {
      "epoch": 4.786666666666667,
      "grad_norm": 1.4983770809781285,
      "learning_rate": 9.545720850406504e-08,
      "logits/chosen": -0.7469499707221985,
      "logits/rejected": -0.9335339665412903,
      "logps/chosen": -574.0552978515625,
      "logps/rejected": -513.0987548828125,
      "loss": 0.1131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9098158478736877,
      "rewards/margins": 3.613184690475464,
      "rewards/rejected": -2.703368663787842,
      "step": 718
    },
    {
      "epoch": 4.793333333333333,
      "grad_norm": 1.5853408668366875,
      "learning_rate": 8.959313863315388e-08,
      "logits/chosen": -0.9255666732788086,
      "logits/rejected": -1.0506300926208496,
      "logps/chosen": -312.6466064453125,
      "logps/rejected": -246.89637756347656,
      "loss": 0.1407,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8079268336296082,
      "rewards/margins": 3.693819284439087,
      "rewards/rejected": -2.885892391204834,
      "step": 719
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.9428203370151067,
      "learning_rate": 8.391413267163418e-08,
      "logits/chosen": -1.1430811882019043,
      "logits/rejected": -1.1378827095031738,
      "logps/chosen": -158.63221740722656,
      "logps/rejected": -355.38995361328125,
      "loss": 0.1633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.209091454744339,
      "rewards/margins": 4.1949567794799805,
      "rewards/rejected": -3.985865592956543,
      "step": 720
    },
    {
      "epoch": 4.806666666666667,
      "grad_norm": 1.3973790430668558,
      "learning_rate": 7.842029666752627e-08,
      "logits/chosen": -0.8147385120391846,
      "logits/rejected": -0.946525514125824,
      "logps/chosen": -239.3634033203125,
      "logps/rejected": -427.943603515625,
      "loss": 0.0629,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3768741190433502,
      "rewards/margins": 4.675469398498535,
      "rewards/rejected": -4.298595428466797,
      "step": 721
    },
    {
      "epoch": 4.8133333333333335,
      "grad_norm": 1.4854086238577358,
      "learning_rate": 7.311173321104648e-08,
      "logits/chosen": -0.8472681045532227,
      "logits/rejected": -1.1009962558746338,
      "logps/chosen": -378.2604675292969,
      "logps/rejected": -229.39208984375,
      "loss": 0.1228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7358918786048889,
      "rewards/margins": 2.914975166320801,
      "rewards/rejected": -2.1790833473205566,
      "step": 722
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.1948704619007708,
      "learning_rate": 6.79885414326864e-08,
      "logits/chosen": -0.8454886078834534,
      "logits/rejected": -1.0677915811538696,
      "logps/chosen": -355.87615966796875,
      "logps/rejected": -324.765625,
      "loss": 0.0506,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3481183052062988,
      "rewards/margins": 4.1895318031311035,
      "rewards/rejected": -2.8414134979248047,
      "step": 723
    },
    {
      "epoch": 4.826666666666666,
      "grad_norm": 1.6455934406040373,
      "learning_rate": 6.305081700136328e-08,
      "logits/chosen": -0.928824782371521,
      "logits/rejected": -1.1172804832458496,
      "logps/chosen": -285.68475341796875,
      "logps/rejected": -295.61627197265625,
      "loss": 0.173,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.32670915126800537,
      "rewards/margins": 3.297722339630127,
      "rewards/rejected": -2.971013069152832,
      "step": 724
    },
    {
      "epoch": 4.833333333333333,
      "grad_norm": 0.8260511666353345,
      "learning_rate": 5.8298652122634747e-08,
      "logits/chosen": -1.1781266927719116,
      "logits/rejected": -1.0973122119903564,
      "logps/chosen": -190.5950469970703,
      "logps/rejected": -375.97540283203125,
      "loss": 0.031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7216076850891113,
      "rewards/margins": 4.642268180847168,
      "rewards/rejected": -3.9206604957580566,
      "step": 725
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.7423211290233598,
      "learning_rate": 5.373213553697576e-08,
      "logits/chosen": -1.0458186864852905,
      "logits/rejected": -1.0614943504333496,
      "logps/chosen": -290.8288879394531,
      "logps/rejected": -343.28924560546875,
      "loss": 0.0948,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8404781818389893,
      "rewards/margins": 4.024209022521973,
      "rewards/rejected": -3.1837308406829834,
      "step": 726
    },
    {
      "epoch": 4.846666666666667,
      "grad_norm": 0.5440198206937108,
      "learning_rate": 4.935135251811995e-08,
      "logits/chosen": -0.9906684756278992,
      "logits/rejected": -0.9752503633499146,
      "logps/chosen": -210.8692626953125,
      "logps/rejected": -381.2408142089844,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.500067949295044,
      "rewards/margins": 5.447730541229248,
      "rewards/rejected": -4.947662830352783,
      "step": 727
    },
    {
      "epoch": 4.8533333333333335,
      "grad_norm": 2.011331050512839,
      "learning_rate": 4.515638487147311e-08,
      "logits/chosen": -0.9164159893989563,
      "logits/rejected": -1.0330955982208252,
      "logps/chosen": -364.7147216796875,
      "logps/rejected": -337.368896484375,
      "loss": 0.179,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5514745712280273,
      "rewards/margins": 2.8490405082702637,
      "rewards/rejected": -2.2975659370422363,
      "step": 728
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.34815275977042215,
      "learning_rate": 4.1147310932578845e-08,
      "logits/chosen": -1.0798004865646362,
      "logits/rejected": -1.0683059692382812,
      "logps/chosen": -239.75205993652344,
      "logps/rejected": -314.3333435058594,
      "loss": 0.017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0955809354782104,
      "rewards/margins": 5.053029537200928,
      "rewards/rejected": -3.9574484825134277,
      "step": 729
    },
    {
      "epoch": 4.866666666666667,
      "grad_norm": 1.6943764629519518,
      "learning_rate": 3.732420556565752e-08,
      "logits/chosen": -0.8541900515556335,
      "logits/rejected": -0.8865861892700195,
      "logps/chosen": -284.5777587890625,
      "logps/rejected": -330.3495788574219,
      "loss": 0.1082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.661224365234375,
      "rewards/margins": 3.7096328735351562,
      "rewards/rejected": -3.0484085083007812,
      "step": 730
    },
    {
      "epoch": 4.873333333333333,
      "grad_norm": 1.3806707747103737,
      "learning_rate": 3.368714016221186e-08,
      "logits/chosen": -1.1028072834014893,
      "logits/rejected": -0.9742189049720764,
      "logps/chosen": -263.04119873046875,
      "logps/rejected": -479.6099853515625,
      "loss": 0.0657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.515315055847168,
      "rewards/margins": 3.8144941329956055,
      "rewards/rejected": -3.2991790771484375,
      "step": 731
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.4993791884967647,
      "learning_rate": 3.023618263968797e-08,
      "logits/chosen": -1.0428460836410522,
      "logits/rejected": -1.0473575592041016,
      "logps/chosen": -313.29742431640625,
      "logps/rejected": -405.11895751953125,
      "loss": 0.055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6884507536888123,
      "rewards/margins": 4.285750865936279,
      "rewards/rejected": -3.5973002910614014,
      "step": 732
    },
    {
      "epoch": 4.886666666666667,
      "grad_norm": 0.2065521941593427,
      "learning_rate": 2.6971397440214154e-08,
      "logits/chosen": -1.1215912103652954,
      "logits/rejected": -0.9772838354110718,
      "logps/chosen": -138.02020263671875,
      "logps/rejected": -414.546630859375,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42301085591316223,
      "rewards/margins": 6.005144119262695,
      "rewards/rejected": -5.5821332931518555,
      "step": 733
    },
    {
      "epoch": 4.8933333333333335,
      "grad_norm": 0.43667453139383655,
      "learning_rate": 2.3892845529390753e-08,
      "logits/chosen": -1.072124719619751,
      "logits/rejected": -0.9810437560081482,
      "logps/chosen": -154.54025268554688,
      "logps/rejected": -420.87103271484375,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22643597424030304,
      "rewards/margins": 5.660599231719971,
      "rewards/rejected": -5.4341630935668945,
      "step": 734
    },
    {
      "epoch": 4.9,
      "grad_norm": 3.76747105091822,
      "learning_rate": 2.100058439515551e-08,
      "logits/chosen": -1.0275871753692627,
      "logits/rejected": -1.055166244506836,
      "logps/chosen": -219.76055908203125,
      "logps/rejected": -257.35736083984375,
      "loss": 0.3136,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.15890268981456757,
      "rewards/margins": 2.5279908180236816,
      "rewards/rejected": -2.6868934631347656,
      "step": 735
    },
    {
      "epoch": 4.906666666666666,
      "grad_norm": 1.8504515586517654,
      "learning_rate": 1.8294668046708874e-08,
      "logits/chosen": -1.068268060684204,
      "logits/rejected": -1.1051188707351685,
      "logps/chosen": -191.70220947265625,
      "logps/rejected": -293.8299560546875,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26708894968032837,
      "rewards/margins": 3.4022250175476074,
      "rewards/rejected": -3.135136365890503,
      "step": 736
    },
    {
      "epoch": 4.913333333333333,
      "grad_norm": 2.232952385291829,
      "learning_rate": 1.577514701350591e-08,
      "logits/chosen": -0.7729138731956482,
      "logits/rejected": -0.9803957343101501,
      "logps/chosen": -231.79823303222656,
      "logps/rejected": -335.39642333984375,
      "loss": 0.1233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46933713555336,
      "rewards/margins": 3.832486391067505,
      "rewards/rejected": -3.3631491661071777,
      "step": 737
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.029908191878651,
      "learning_rate": 1.3442068344312609e-08,
      "logits/chosen": -0.9375731348991394,
      "logits/rejected": -0.9436306357383728,
      "logps/chosen": -233.86729431152344,
      "logps/rejected": -359.5155029296875,
      "loss": 0.2015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28424185514450073,
      "rewards/margins": 3.1009292602539062,
      "rewards/rejected": -2.8166873455047607,
      "step": 738
    },
    {
      "epoch": 4.926666666666667,
      "grad_norm": 2.8884732872597905,
      "learning_rate": 1.129547560632771e-08,
      "logits/chosen": -0.9253882765769958,
      "logits/rejected": -1.0276869535446167,
      "logps/chosen": -341.20819091796875,
      "logps/rejected": -304.305908203125,
      "loss": 0.2265,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.7381190657615662,
      "rewards/margins": 2.8815739154815674,
      "rewards/rejected": -2.1434547901153564,
      "step": 739
    },
    {
      "epoch": 4.933333333333334,
      "grad_norm": 2.5621178504883924,
      "learning_rate": 9.335408884366682e-09,
      "logits/chosen": -0.9390775561332703,
      "logits/rejected": -0.9805793762207031,
      "logps/chosen": -289.5318603515625,
      "logps/rejected": -381.4702453613281,
      "loss": 0.1614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19662228226661682,
      "rewards/margins": 3.3408877849578857,
      "rewards/rejected": -3.1442651748657227,
      "step": 740
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 2.732103112409852,
      "learning_rate": 7.561904780116758e-09,
      "logits/chosen": -0.925834059715271,
      "logits/rejected": -1.0515321493148804,
      "logps/chosen": -240.5380859375,
      "logps/rejected": -249.51869201660156,
      "loss": 0.2365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2526772618293762,
      "rewards/margins": 2.6478404998779297,
      "rewards/rejected": -2.3951635360717773,
      "step": 741
    },
    {
      "epoch": 4.946666666666666,
      "grad_norm": 1.6349390956489245,
      "learning_rate": 5.97499641145416e-09,
      "logits/chosen": -1.1221060752868652,
      "logits/rejected": -1.0257145166397095,
      "logps/chosen": -161.86135864257812,
      "logps/rejected": -440.4836120605469,
      "loss": 0.0639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13617996871471405,
      "rewards/margins": 5.867370128631592,
      "rewards/rejected": -6.003550052642822,
      "step": 742
    },
    {
      "epoch": 4.953333333333333,
      "grad_norm": 0.8994073360162593,
      "learning_rate": 4.574713411816811e-09,
      "logits/chosen": -1.035717248916626,
      "logits/rejected": -1.0985453128814697,
      "logps/chosen": -284.5089111328125,
      "logps/rejected": -304.411865234375,
      "loss": 0.0877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6237801313400269,
      "rewards/margins": 4.326502799987793,
      "rewards/rejected": -3.7027227878570557,
      "step": 743
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.859058807465023,
      "learning_rate": 3.361081929664778e-09,
      "logits/chosen": -1.0845894813537598,
      "logits/rejected": -1.0849860906600952,
      "logps/chosen": -225.70162963867188,
      "logps/rejected": -384.4393310546875,
      "loss": 0.0539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6753905415534973,
      "rewards/margins": 5.079338073730469,
      "rewards/rejected": -4.403947830200195,
      "step": 744
    },
    {
      "epoch": 4.966666666666667,
      "grad_norm": 2.362049128384061,
      "learning_rate": 2.3341246279806606e-09,
      "logits/chosen": -0.8983891606330872,
      "logits/rejected": -1.051816701889038,
      "logps/chosen": -262.31683349609375,
      "logps/rejected": -305.8646240234375,
      "loss": 0.1346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06587415933609009,
      "rewards/margins": 3.9891726970672607,
      "rewards/rejected": -4.055047035217285,
      "step": 745
    },
    {
      "epoch": 4.973333333333334,
      "grad_norm": 2.2469036201277772,
      "learning_rate": 1.493860683851045e-09,
      "logits/chosen": -1.0276129245758057,
      "logits/rejected": -1.0564687252044678,
      "logps/chosen": -298.08428955078125,
      "logps/rejected": -319.5089111328125,
      "loss": 0.1539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6138432025909424,
      "rewards/margins": 2.943068504333496,
      "rewards/rejected": -2.3292250633239746,
      "step": 746
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.887066037140959,
      "learning_rate": 8.403057881067877e-10,
      "logits/chosen": -0.9655344486236572,
      "logits/rejected": -0.9367717504501343,
      "logps/chosen": -195.03707885742188,
      "logps/rejected": -396.95672607421875,
      "loss": 0.0998,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09265229105949402,
      "rewards/margins": 4.080351829528809,
      "rewards/rejected": -4.173004150390625,
      "step": 747
    },
    {
      "epoch": 4.986666666666666,
      "grad_norm": 1.206004375690221,
      "learning_rate": 3.7347214503435927e-10,
      "logits/chosen": -1.0648781061172485,
      "logits/rejected": -1.0757715702056885,
      "logps/chosen": -233.57650756835938,
      "logps/rejected": -407.84649658203125,
      "loss": 0.0956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16132983565330505,
      "rewards/margins": 4.453131198883057,
      "rewards/rejected": -4.2918009757995605,
      "step": 748
    },
    {
      "epoch": 4.993333333333333,
      "grad_norm": 2.6570365190103225,
      "learning_rate": 9.33684721426964e-11,
      "logits/chosen": -1.1667104959487915,
      "logits/rejected": -1.115548014640808,
      "logps/chosen": -186.811767578125,
      "logps/rejected": -347.5445556640625,
      "loss": 0.1695,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.506339430809021,
      "rewards/margins": 4.144162178039551,
      "rewards/rejected": -3.6378231048583984,
      "step": 749
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.9582113944974253,
      "learning_rate": 0.0,
      "logits/chosen": -1.134397029876709,
      "logits/rejected": -0.9160717129707336,
      "logps/chosen": -121.66693115234375,
      "logps/rejected": -448.7796630859375,
      "loss": 0.0592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20954620838165283,
      "rewards/margins": 5.22718620300293,
      "rewards/rejected": -5.436732769012451,
      "step": 750
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 150,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
